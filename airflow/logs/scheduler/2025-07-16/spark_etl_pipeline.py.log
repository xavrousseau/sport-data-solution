[2025-07-16T06:47:43.334+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:47:43.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.369+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:47:43.567+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.567+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:47:43.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.256 seconds
[2025-07-16T06:48:13.960+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:13.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:48:13.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:13.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:13.991+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:14.018+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:14.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:48:14.030+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:14.030+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:48:14.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T06:48:44.611+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:48:44.614+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.663+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.707+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.706+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:48:44.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.719+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:48:44.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.134 seconds
[2025-07-16T06:49:14.856+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:49:14.861+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:14.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.919+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:14.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:49:15.002+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:15.002+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:49:15.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.206 seconds
[2025-07-16T06:49:45.648+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:49:45.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.676+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:49:45.710+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.710+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:49:45.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T06:50:16.211+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:50:16.214+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.266+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:50:16.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.278+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:50:16.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T06:50:46.367+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:50:46.370+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.396+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.419+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.419+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:50:46.430+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.430+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:50:46.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T06:51:17.073+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:51:17.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.091+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:51:17.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:51:17.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T06:51:47.776+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:51:47.778+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.790+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.810+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:51:47.821+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.821+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:51:47.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T06:52:18.562+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:52:18.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.583+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.604+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:52:18.617+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.617+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:52:18.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T06:52:49.247+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:52:49.250+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.261+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:52:49.294+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.294+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:52:49.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T06:53:19.882+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:53:19.884+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.901+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:53:19.936+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.936+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:53:19.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T06:53:50.534+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:53:50.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.550+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.569+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:53:50.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.580+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:53:50.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T06:54:21.467+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:54:21.469+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.487+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.509+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.509+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:54:21.520+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.520+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:54:21.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T06:54:51.961+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:51.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:54:51.964+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:51.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:51.990+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:52.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:52.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:54:52.025+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:52.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:54:52.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T06:55:22.950+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:55:22.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:22.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.964+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.985+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:22.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:55:23.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:23.001+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:55:23.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T06:55:53.560+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:55:53.563+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.577+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.598+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.598+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:55:53.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:55:53.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T06:56:24.504+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:56:24.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.640+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:56:24.652+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.652+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:56:24.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.177 seconds
[2025-07-16T06:56:54.990+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:54.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:56:54.993+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:54.993+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:55.004+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:55.023+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:55.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:56:55.035+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:55.035+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:56:55.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T06:57:25.390+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:57:25.392+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.406+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:57:25.438+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.438+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:57:25.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T06:57:55.952+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:55.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:57:55.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:55.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:55.978+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:56.000+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:56.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:57:56.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:56.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:57:56.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T06:58:26.228+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:58:26.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:58:26.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.283+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:58:26.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T06:58:56.549+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:58:56.552+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.552+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.565+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.585+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:58:56.598+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.598+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:58:56.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T06:59:26.924+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:59:26.927+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.952+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.975+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.975+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:59:26.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.987+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:59:27.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T06:59:57.455+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:59:57.460+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.609+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.633+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.632+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:59:57.645+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.645+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:59:57.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.224 seconds
[2025-07-16T07:00:28.169+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:00:28.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.187+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:00:28.140+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.140+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:00:28.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:00:58.269+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:00:58.271+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.299+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.320+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:00:58.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:00:58.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:01:28.497+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:01:28.500+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.519+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.544+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.544+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:01:28.556+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.556+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:01:28.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T07:01:58.749+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:01:58.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.778+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.800+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.800+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:01:58.812+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.812+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:01:58.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:02:29.147+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:02:29.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.163+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.185+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:02:29.197+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.197+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:02:29.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:02:59.754+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:02:59.756+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.771+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.791+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:02:59.803+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.802+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:02:59.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:03:30.033+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:03:30.037+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.066+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:03:30.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:03:30.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T07:04:00.333+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:04:00.336+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.353+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.372+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:04:00.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.384+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:04:00.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:04:30.829+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:04:30.831+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.845+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:04:30.878+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.878+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:04:30.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:05:01.067+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:05:01.070+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.081+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.100+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.100+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:05:01.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.111+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:05:01.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T07:05:31.306+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:05:31.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.328+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.349+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:05:31.362+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.362+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:05:31.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.165 seconds
[2025-07-16T07:06:01.637+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:06:01.640+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.653+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.672+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:06:01.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.684+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:06:01.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:06:31.805+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:06:31.808+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.831+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.852+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:06:31.863+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.863+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:06:31.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:07:01.979+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:01.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:07:01.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:01.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:02.000+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:02.020+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:02.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:07:02.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:02.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:07:02.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:07:32.198+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:07:32.200+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.230+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.250+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:07:32.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.262+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:07:32.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:08:02.524+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:08:02.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.540+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.561+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:08:02.573+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.573+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:08:02.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:08:32.803+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:08:32.806+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.832+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.856+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.856+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:08:32.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.867+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:08:32.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:09:03.146+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:09:03.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.178+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.203+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:09:03.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.215+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:09:03.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:09:33.366+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:09:33.369+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.395+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.421+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:09:33.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.433+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:09:33.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T07:10:04.436+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:10:04.439+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.480+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:10:04.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.492+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:10:04.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T07:10:34.597+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:10:34.600+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.650+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:10:34.661+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.661+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:10:34.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:11:05.215+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:11:05.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.234+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.254+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.254+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:11:05.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.265+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:11:05.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:11:35.337+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:11:35.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.351+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:11:35.381+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.381+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:11:35.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:12:05.492+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:12:05.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.508+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.528+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:12:05.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.539+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:12:05.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:12:35.650+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:12:35.653+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.664+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:12:35.695+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.695+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:12:35.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T07:13:05.955+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:05.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:13:05.958+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:05.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:05.978+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:06.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:06.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:13:06.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:06.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:13:06.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:13:36.166+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:13:36.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.205+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.226+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:13:36.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:13:36.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T07:14:06.454+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:14:06.458+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.493+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.513+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.513+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:14:06.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.524+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:14:06.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T07:14:36.698+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:14:36.701+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.701+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.717+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:14:36.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.751+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:14:36.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:15:07.015+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:15:07.017+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.066+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.066+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:15:07.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.076+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:15:07.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:15:37.147+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:15:37.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.173+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.196+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.196+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:15:37.207+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.207+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:15:37.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:16:07.862+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:16:07.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.878+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:16:07.909+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.909+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:16:07.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:16:38.424+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:16:38.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.440+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.463+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:16:38.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:16:38.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:17:08.889+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:17:08.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.904+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:17:08.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:17:08.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T07:17:39.063+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:17:39.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.084+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.105+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:17:39.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.117+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:17:39.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:18:09.633+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:18:09.640+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.751+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.775+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:18:09.786+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.786+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:18:09.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.184 seconds
[2025-07-16T07:18:40.565+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:18:40.568+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.594+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:18:40.626+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.626+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:18:40.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:19:10.694+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:19:10.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.696+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.710+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.730+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.730+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:19:10.741+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.741+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:19:10.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:19:41.047+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:19:41.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.050+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.074+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.098+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:19:41.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.109+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:19:41.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:20:11.279+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:20:11.290+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.306+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:20:11.341+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.341+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:20:11.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:20:42.157+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:20:42.160+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.182+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.203+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:20:42.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.213+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:20:42.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:21:12.391+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:21:12.396+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.425+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.446+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.445+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:21:12.456+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.456+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:21:12.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T07:21:43.230+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:21:43.233+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.250+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:21:43.285+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.285+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:21:43.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:22:13.611+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:22:13.616+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.638+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.660+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:22:13.671+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.671+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:22:13.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:22:43.909+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:22:43.911+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.933+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:22:43.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:22:43.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:23:14.253+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:23:14.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.342+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:23:14.357+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.357+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:23:14.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.136 seconds
[2025-07-16T07:23:45.136+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:23:45.140+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.168+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.195+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:23:45.206+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.206+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:23:45.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:24:15.348+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:24:15.351+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.377+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.398+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.398+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:24:15.409+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.409+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:24:15.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:24:45.984+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:45.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:24:45.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:45.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:46.011+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:46.033+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:46.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:24:46.044+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:46.043+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:24:46.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:25:16.612+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:25:16.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.631+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.652+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:25:16.664+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.663+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:25:16.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:25:46.995+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:46.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:25:46.997+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:46.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:47.020+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:47.046+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:47.046+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:25:47.058+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:47.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:25:47.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:26:17.222+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:26:17.229+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.274+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:26:17.310+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.310+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:26:17.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.122 seconds
[2025-07-16T07:26:47.743+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:26:47.746+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.746+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.765+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:26:47.805+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.805+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:26:47.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:27:18.473+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:27:18.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.491+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.512+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:27:18.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.524+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:27:18.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:27:49.465+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:27:49.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.484+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.503+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:27:49.514+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.514+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:27:49.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:28:19.985+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:19.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:28:19.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:19.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:20.010+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:20.034+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:20.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:28:20.045+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:20.045+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:28:20.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:28:50.698+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:28:50.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.823+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:28:50.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.859+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:28:50.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.195 seconds
[2025-07-16T07:29:21.643+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:29:21.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.669+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.689+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:29:21.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.699+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:29:21.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:29:52.210+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:29:52.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.234+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.254+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.254+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:29:52.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.264+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:29:52.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:30:22.908+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:30:22.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.922+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.942+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:30:22.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.952+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:30:22.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T07:30:53.602+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:30:53.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.633+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.655+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.655+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:30:53.665+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.665+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:30:53.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:31:24.580+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:31:24.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.609+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.630+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:31:24.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.641+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:31:24.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:31:55.504+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:31:55.506+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.525+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.549+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.549+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:31:55.560+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.560+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:31:55.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:32:26.580+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:32:26.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.602+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:32:26.635+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.634+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:32:26.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:32:57.405+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:32:57.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:32:57.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:32:57.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.128 seconds
[2025-07-16T07:33:28.542+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:33:28.546+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.678+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:33:28.715+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.715+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:33:28.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.203 seconds
[2025-07-16T07:33:59.025+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:33:59.033+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.082+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:33:59.123+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:33:59.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.125 seconds
[2025-07-16T07:34:29.240+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:34:29.244+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.270+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:34:29.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.303+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:34:29.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:35:00.220+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:35:00.222+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.240+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:35:00.274+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.274+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:35:00.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:35:31.016+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:35:31.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.039+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.059+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:35:31.069+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.069+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:35:31.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:36:01.134+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:36:01.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.152+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:36:01.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.182+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:36:01.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:36:32.158+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:36:32.162+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:36:32.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:36:32.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T07:37:02.286+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:37:02.289+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.324+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:37:02.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.335+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:37:02.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:37:33.226+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:37:33.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:37:33.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.274+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:37:33.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:38:04.045+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:38:04.047+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.059+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.079+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:38:04.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.090+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:38:04.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:38:34.835+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:38:34.837+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.849+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.869+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:38:34.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.880+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:38:34.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:39:05.671+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:39:05.673+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.691+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.713+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:39:05.725+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.725+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:39:05.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:39:36.489+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:39:36.491+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.504+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.524+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:39:36.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:39:36.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:40:07.389+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:40:07.391+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.403+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:40:07.435+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.435+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:40:07.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:40:37.946+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:40:37.949+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:37.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.977+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:37.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:40:38.010+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:38.010+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:40:38.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:41:08.834+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:41:08.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:41:08.878+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.878+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:41:08.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:41:39.407+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:41:39.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.463+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:41:39.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:41:39.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:42:10.396+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:42:10.399+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.399+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.440+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:42:10.452+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.451+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:42:10.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:42:41.050+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:42:41.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:42:41.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.110+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:42:41.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:43:12.102+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:43:12.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:43:12.162+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.162+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:43:12.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:43:42.861+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:43:42.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.876+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.897+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.896+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:43:42.907+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:43:42.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:44:13.747+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:44:13.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.771+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.792+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:44:13.803+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.803+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:44:13.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:44:44.645+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:44:44.647+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.662+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:44:44.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.696+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:44:44.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:45:15.620+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:45:15.623+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.622+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.643+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.667+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:45:15.679+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.679+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:45:15.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:45:46.456+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:45:46.459+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.476+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.496+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.496+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:45:46.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:45:46.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:46:17.186+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:46:17.189+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.208+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.234+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.234+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:46:17.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.248+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:46:17.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-16T07:46:48.267+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:46:48.270+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.270+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:46:48.334+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.334+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:46:48.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:47:18.559+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:47:18.561+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.586+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.607+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:47:18.621+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.621+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:47:18.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:47:49.443+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:47:49.447+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.475+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.497+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:47:49.509+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.509+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:47:49.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:48:20.344+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:48:20.346+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.359+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.380+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.380+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:48:20.392+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.392+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:48:20.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:48:50.867+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:48:50.875+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.894+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:48:50.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.930+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:48:50.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T07:49:21.497+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:49:21.500+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.527+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.551+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.551+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:49:21.563+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.563+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:49:21.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T07:49:52.155+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:49:52.157+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.172+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:49:52.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.205+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:49:52.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:50:22.944+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:50:22.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.961+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:50:22.992+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.992+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:50:23.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:50:53.517+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:50:53.519+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.538+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.559+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:50:53.572+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.572+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:50:53.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:51:24.111+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:51:24.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:51:24.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.163+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:51:24.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:51:54.816+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:51:54.819+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.834+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.855+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:51:54.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.866+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:51:54.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:52:25.546+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:52:25.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.563+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.587+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:52:25.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.599+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:52:25.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:52:56.339+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:52:56.341+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.353+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.377+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:52:56.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.390+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:52:56.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:53:27.286+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:53:27.288+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.308+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.330+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:53:27.343+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.343+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:53:27.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T07:53:58.083+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:53:58.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.111+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:53:58.145+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.145+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:53:58.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:54:28.975+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:28.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:54:28.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:28.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:29.002+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:29.023+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:29.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:54:29.034+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:29.034+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:54:29.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:55:00.129+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:55:00.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.167+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:55:00.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.182+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:55:00.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:55:30.977+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:30.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:55:30.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:30.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:31.019+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:31.042+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:31.042+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:55:31.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:31.053+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:55:31.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T07:56:01.210+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:56:01.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.225+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.244+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:56:01.256+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.256+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:56:01.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:56:31.869+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:56:31.872+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.895+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.917+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.916+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:56:31.928+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.928+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:56:31.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:57:02.538+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:57:02.541+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.541+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.560+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.582+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:57:02.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.594+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:57:02.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:57:33.294+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:57:33.296+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.319+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:57:33.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.350+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:57:33.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:58:03.421+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:58:03.424+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.424+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:58:03.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.478+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:58:03.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:58:34.188+0000] {processor.py:161} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:58:34.191+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.206+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.228+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:58:34.239+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.239+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:58:34.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:59:05.035+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:59:05.037+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.076+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:59:05.092+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.092+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:59:05.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T07:59:35.890+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:59:35.893+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.915+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:59:35.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:59:35.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:00:06.881+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:00:06.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.904+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:00:06.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:00:06.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T08:00:37.788+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:00:37.790+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.790+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.807+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:00:37.838+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.838+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:00:37.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:01:08.809+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:01:08.812+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.835+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.856+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:01:08.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.867+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:01:08.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T08:01:39.613+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:01:39.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:01:39.659+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.659+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:01:39.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:02:10.459+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:02:10.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.480+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.501+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:02:10.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.511+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:02:10.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:02:41.214+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:02:41.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.217+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.232+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.253+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.253+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:02:41.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.265+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:02:41.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:03:12.166+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:03:12.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.168+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.183+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.204+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:03:12.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.217+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:03:12.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:03:42.840+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:03:42.842+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.856+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.876+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.876+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:03:42.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.888+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:03:42.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:04:13.645+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:04:13.658+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.658+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.691+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.717+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.716+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:04:13.728+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.728+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:04:13.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-16T08:04:44.554+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:04:44.557+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.573+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.594+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:04:44.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.605+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:04:44.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:05:15.362+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:05:15.365+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.380+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.400+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:05:15.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.411+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:05:15.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:05:46.111+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:05:46.114+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.114+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.134+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.159+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:05:46.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.171+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:05:46.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:06:17.106+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:06:17.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.144+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:06:17.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.177+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:06:17.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T08:06:48.144+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:06:48.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.170+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.193+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.193+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:06:48.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.212+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:06:48.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:07:19.128+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:07:19.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.173+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.217+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:07:19.232+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.232+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:07:19.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.127 seconds
[2025-07-16T08:07:49.574+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:07:49.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.587+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:07:49.620+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.619+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:07:49.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:08:20.552+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:08:20.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.601+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.600+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:08:20.613+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.613+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:08:20.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:08:51.628+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:08:51.631+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.653+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.674+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.674+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:08:51.685+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.685+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:08:51.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:09:22.552+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:09:22.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.571+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.594+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:09:22.604+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.604+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:09:22.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:09:53.564+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:09:53.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.578+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:09:53.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:09:53.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:10:24.368+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:10:24.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.385+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.405+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:10:24.416+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:10:24.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:10:55.336+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:10:55.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.354+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:10:55.385+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.385+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:10:55.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:11:26.172+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:11:26.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.201+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:11:26.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:11:26.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:11:57.046+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:11:57.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.064+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:11:57.097+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.097+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:11:57.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:12:28.028+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:12:28.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:12:28.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.085+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:12:28.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:12:58.375+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:12:58.378+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.377+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.405+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.425+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.425+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:12:58.436+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.436+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:12:58.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:13:29.408+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:13:29.412+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.464+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.464+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:13:29.475+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.475+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:13:29.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T08:14:00.329+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:14:00.331+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.346+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.368+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.367+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:14:00.379+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.379+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:14:00.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:14:31.256+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:14:31.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:14:31.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.317+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:14:31.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:15:02.214+0000] {processor.py:161} INFO - Started process (PID=1238) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:15:02.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.217+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.242+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.268+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:15:02.280+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.280+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:15:02.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:15:32.532+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:15:32.534+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.556+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:15:32.593+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.593+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:15:32.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:16:03.551+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:16:03.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.573+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.596+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:16:03.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:16:03.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:16:34.455+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:16:34.457+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.477+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:16:34.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.511+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:16:34.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T08:17:05.362+0000] {processor.py:161} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:17:05.368+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.380+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.402+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:17:05.415+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.414+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:17:05.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:17:36.085+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:17:36.087+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.087+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.104+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.126+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:17:36.139+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.138+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:17:36.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:18:06.995+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:06.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:18:06.998+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:06.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:07.021+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:07.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:07.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:18:07.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:07.053+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:18:07.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:18:37.942+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:18:37.944+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:37.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.961+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.988+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:37.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:18:38.000+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:38.000+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:18:38.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T08:19:08.904+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:19:08.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.938+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.963+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:19:08.978+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.978+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:19:08.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T08:19:39.939+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:19:39.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:39.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.974+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:39.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:19:40.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:40.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:19:40.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:20:10.665+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:20:10.667+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.682+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.702+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.702+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:20:10.713+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.713+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:20:10.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:20:41.442+0000] {processor.py:161} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:20:41.445+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.467+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.489+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:20:41.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.501+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:20:41.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:21:12.271+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:21:12.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.288+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:21:12.320+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.320+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:21:12.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:21:43.102+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:21:43.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.128+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:21:43.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.164+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:21:43.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:22:14.020+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:22:14.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.068+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.094+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:22:14.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.111+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:22:14.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-16T08:22:45.113+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:22:45.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.128+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.151+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:22:45.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.164+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:22:45.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:23:16.053+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:23:16.056+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.088+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:23:16.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:23:16.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T08:23:47.063+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:23:47.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.090+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.112+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:23:47.124+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.124+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:23:47.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T08:24:17.932+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:24:17.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.948+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:24:17.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.979+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:24:17.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:24:48.833+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:24:48.838+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.873+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.895+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.895+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:24:48.907+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:24:48.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T08:25:19.731+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:25:19.738+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.787+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.813+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.813+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:25:19.826+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.825+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:25:19.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.127 seconds
[2025-07-16T08:25:49.920+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:25:49.922+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.935+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:25:49.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.968+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:25:49.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:26:20.882+0000] {processor.py:161} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:26:20.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.936+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.936+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:26:20.948+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.947+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:26:20.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:26:51.814+0000] {processor.py:161} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:26:51.816+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.850+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.850+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:26:51.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.862+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:26:51.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:27:22.689+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:27:22.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.718+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.680+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:27:22.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.692+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:27:22.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:27:53.007+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:27:53.009+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.009+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.031+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.052+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:27:53.064+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.064+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:27:53.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:28:23.220+0000] {processor.py:161} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:28:23.222+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.235+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.255+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:28:23.267+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.266+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:28:23.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T08:28:54.240+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:28:54.242+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.266+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:28:54.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.299+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:28:54.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:29:25.204+0000] {processor.py:161} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:29:25.206+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:29:25.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.251+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:29:25.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:29:56.137+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:29:56.141+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.245+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.269+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:29:56.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.282+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:29:56.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.171 seconds
[2025-07-16T08:30:26.497+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:30:26.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.515+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:30:26.545+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.545+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:30:26.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:30:57.238+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:30:57.241+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.271+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.293+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.293+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:30:57.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.308+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:30:57.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:31:28.102+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:31:28.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.121+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.143+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:31:28.155+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.155+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:31:28.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:31:58.922+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:31:58.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.936+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.966+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:31:58.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.977+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:31:58.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T08:32:29.144+0000] {processor.py:161} INFO - Started process (PID=1476) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:32:29.146+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.168+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.188+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.188+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:32:29.200+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.200+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:32:29.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:32:59.976+0000] {processor.py:161} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:59.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:32:59.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:59.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:00.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:00.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:00.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:33:00.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:00.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:33:00.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:33:30.994+0000] {processor.py:161} INFO - Started process (PID=1490) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:30.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:33:30.996+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:30.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:31.012+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:31.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:31.030+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:33:31.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:31.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:33:31.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:34:01.112+0000] {processor.py:161} INFO - Started process (PID=1497) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:34:01.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.127+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:34:01.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.157+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:34:01.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:34:31.233+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:34:31.235+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.248+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.268+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:34:31.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.278+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:34:31.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:35:02.275+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:35:02.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:35:02.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:35:02.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:35:33.326+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:35:33.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.349+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.374+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:35:33.387+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.387+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:35:33.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:36:04.246+0000] {processor.py:161} INFO - Started process (PID=1525) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:36:04.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.264+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.290+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.290+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:36:04.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.303+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:36:04.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:36:35.186+0000] {processor.py:161} INFO - Started process (PID=1532) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:36:35.190+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.235+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:36:35.247+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.247+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:36:35.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:37:06.168+0000] {processor.py:161} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:37:06.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.190+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:37:06.223+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.223+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:37:06.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:37:36.387+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:37:36.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.390+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.402+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.422+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.422+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:37:36.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.433+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:37:36.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:38:06.579+0000] {processor.py:161} INFO - Started process (PID=1553) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:38:06.581+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.595+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.620+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.620+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:38:06.634+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.634+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:38:06.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:38:37.633+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:38:37.636+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.651+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.670+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:38:37.682+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.682+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:38:37.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:39:07.809+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:39:07.811+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.839+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:39:07.870+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.870+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:39:07.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:39:38.056+0000] {processor.py:161} INFO - Started process (PID=1574) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:39:38.064+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.085+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.108+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:39:38.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.120+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:39:38.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:40:09.021+0000] {processor.py:161} INFO - Started process (PID=1581) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:40:09.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.035+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.055+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:40:09.068+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.068+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:40:09.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:40:40.011+0000] {processor.py:161} INFO - Started process (PID=1588) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:40:40.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.054+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:40:40.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.090+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:40:40.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-07-16T08:41:10.162+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:41:10.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.165+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.191+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:41:10.224+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:41:10.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:41:41.133+0000] {processor.py:161} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:41:41.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.149+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:41:41.183+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.183+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:41:41.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:42:11.430+0000] {processor.py:161} INFO - Started process (PID=1609) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:42:11.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.446+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.466+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:42:11.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.479+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:42:11.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:42:41.696+0000] {processor.py:161} INFO - Started process (PID=1616) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:42:41.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.698+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.713+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.733+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.732+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:42:41.744+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.744+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:42:41.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:43:11.884+0000] {processor.py:161} INFO - Started process (PID=1623) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:43:11.887+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.923+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:43:11.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.934+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:43:11.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:43:42.649+0000] {processor.py:161} INFO - Started process (PID=1630) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:43:42.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.663+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.686+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.686+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:43:42.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.698+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:43:42.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:44:13.574+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:44:13.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.589+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.612+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.612+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:44:13.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.624+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:44:13.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:44:44.051+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:44:44.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.066+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.089+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:44:44.102+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.101+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:44:44.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:45:14.936+0000] {processor.py:161} INFO - Started process (PID=1651) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:45:14.938+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.980+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:45:14.993+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.993+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:45:15.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T08:45:45.841+0000] {processor.py:161} INFO - Started process (PID=1658) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:45:45.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.864+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.890+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:45:45.903+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.902+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:45:45.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:46:16.856+0000] {processor.py:161} INFO - Started process (PID=1665) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:46:16.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.884+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:46:16.922+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.922+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:46:16.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T08:46:47.779+0000] {processor.py:161} INFO - Started process (PID=1672) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:46:47.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.802+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.830+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:46:47.844+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.844+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:46:47.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T08:47:18.776+0000] {processor.py:161} INFO - Started process (PID=1679) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:47:18.779+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.806+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:47:18.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.839+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:47:18.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:47:48.894+0000] {processor.py:161} INFO - Started process (PID=1686) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:47:48.896+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.933+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:47:48.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.945+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:47:48.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:48:19.107+0000] {processor.py:161} INFO - Started process (PID=1693) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:48:19.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.122+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.142+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:48:19.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.152+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:48:19.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:48:49.546+0000] {processor.py:161} INFO - Started process (PID=1700) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:48:49.552+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.552+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.657+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.678+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.678+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:48:49.690+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.690+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:48:49.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.172 seconds
[2025-07-16T08:49:20.503+0000] {processor.py:161} INFO - Started process (PID=1707) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:49:20.506+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.575+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:49:20.588+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.588+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:49:20.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-16T08:49:51.442+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:49:51.445+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.472+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:49:51.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:49:51.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:50:22.427+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:50:22.430+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.466+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:50:22.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.478+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:50:22.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:50:53.191+0000] {processor.py:161} INFO - Started process (PID=1728) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:50:53.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.206+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.226+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:50:53.239+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.239+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:50:53.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:51:24.041+0000] {processor.py:161} INFO - Started process (PID=1735) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:51:24.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.107+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:51:24.146+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.146+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:51:24.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.139 seconds
[2025-07-16T08:51:54.950+0000] {processor.py:161} INFO - Started process (PID=1742) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:51:54.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:54.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.971+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.992+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:54.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:51:55.004+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:55.004+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:51:55.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T08:52:25.932+0000] {processor.py:161} INFO - Started process (PID=1749) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:25.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:52:25.938+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:25.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:26.054+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:26.080+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:26.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:52:26.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:26.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:52:26.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.187 seconds
[2025-07-16T08:52:56.213+0000] {processor.py:161} INFO - Started process (PID=1756) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:52:56.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.238+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.261+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:52:56.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.272+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:52:56.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T08:53:27.137+0000] {processor.py:161} INFO - Started process (PID=1763) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:53:27.139+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.154+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.174+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:53:27.186+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.185+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:53:27.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:53:58.049+0000] {processor.py:161} INFO - Started process (PID=1770) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:53:58.051+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:53:58.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:53:58.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T08:54:28.802+0000] {processor.py:161} INFO - Started process (PID=1777) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:54:28.804+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.819+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.839+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:54:28.851+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.850+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:54:28.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:54:59.661+0000] {processor.py:161} INFO - Started process (PID=1784) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:54:59.663+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.683+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:54:59.715+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.714+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:54:59.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:55:30.577+0000] {processor.py:161} INFO - Started process (PID=1791) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:55:30.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.612+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.638+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:55:30.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.649+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:55:30.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T08:56:01.592+0000] {processor.py:161} INFO - Started process (PID=1798) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:56:01.595+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.594+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.619+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:56:01.665+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.664+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:56:01.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T08:56:32.613+0000] {processor.py:161} INFO - Started process (PID=1805) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:56:32.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:56:32.659+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.659+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:56:32.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:57:03.545+0000] {processor.py:161} INFO - Started process (PID=1812) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:57:03.547+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.561+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.582+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.582+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:57:03.593+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.593+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:57:03.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:57:34.369+0000] {processor.py:161} INFO - Started process (PID=1819) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:57:34.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.387+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.408+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:57:34.419+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.419+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:57:34.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:58:05.236+0000] {processor.py:161} INFO - Started process (PID=1826) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:58:05.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.254+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.285+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.285+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:58:05.297+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.297+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:58:05.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:58:36.135+0000] {processor.py:161} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:58:36.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.154+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.174+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:58:36.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.185+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:58:36.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:59:06.432+0000] {processor.py:161} INFO - Started process (PID=1840) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:59:06.436+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.505+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.528+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.527+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:59:06.543+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.543+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:59:06.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.138 seconds
[2025-07-16T08:59:37.450+0000] {processor.py:161} INFO - Started process (PID=1847) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:59:37.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.468+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.490+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:59:37.502+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.502+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:59:37.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T09:00:08.356+0000] {processor.py:161} INFO - Started process (PID=1854) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:00:08.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.358+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.379+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.402+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:00:08.413+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.413+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:00:08.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:00:39.309+0000] {processor.py:161} INFO - Started process (PID=1861) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:00:39.312+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.326+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:00:39.359+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.359+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:00:39.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:01:10.190+0000] {processor.py:161} INFO - Started process (PID=1868) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:01:10.192+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.228+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:01:10.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.240+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:01:10.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:01:41.082+0000] {processor.py:161} INFO - Started process (PID=1875) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:01:41.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.112+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:01:41.148+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.148+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:01:41.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:02:12.083+0000] {processor.py:161} INFO - Started process (PID=1882) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:02:12.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.096+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:02:12.127+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.127+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:02:12.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.065 seconds
[2025-07-16T09:02:42.436+0000] {processor.py:161} INFO - Started process (PID=1889) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:02:42.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.460+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.483+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.482+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:02:42.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.494+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:02:42.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:03:12.823+0000] {processor.py:161} INFO - Started process (PID=1896) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:03:12.826+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.869+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:03:12.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.880+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:03:12.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:03:44.039+0000] {processor.py:161} INFO - Started process (PID=1903) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:03:44.043+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.062+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.082+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:03:44.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:03:44.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:04:14.982+0000] {processor.py:161} INFO - Started process (PID=1910) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:14.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:04:14.985+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:14.985+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:15.010+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:15.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:15.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:04:15.045+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:15.044+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:04:15.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T09:04:45.691+0000] {processor.py:161} INFO - Started process (PID=1917) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:04:45.694+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.694+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.712+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:04:45.745+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.745+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:04:45.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T09:05:16.646+0000] {processor.py:161} INFO - Started process (PID=1924) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:05:16.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.649+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.695+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:05:16.708+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.708+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:05:16.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T09:05:47.643+0000] {processor.py:161} INFO - Started process (PID=1931) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:05:47.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.691+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.691+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:05:47.702+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.702+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:05:47.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:06:17.962+0000] {processor.py:161} INFO - Started process (PID=1938) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:17.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:06:17.974+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:17.973+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:18.002+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:18.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:18.024+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:06:18.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:18.035+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:06:18.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T09:06:48.235+0000] {processor.py:161} INFO - Started process (PID=1945) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:06:48.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.263+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:06:48.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.298+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:06:48.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T09:07:18.502+0000] {processor.py:161} INFO - Started process (PID=1952) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:07:18.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.525+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:07:18.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.559+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:07:18.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T09:07:49.524+0000] {processor.py:161} INFO - Started process (PID=1959) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:07:49.526+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:07:49.584+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.584+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:07:49.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T09:08:20.598+0000] {processor.py:161} INFO - Started process (PID=1966) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:08:20.601+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.626+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:08:20.662+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.662+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:08:20.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:08:50.760+0000] {processor.py:161} INFO - Started process (PID=1973) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:08:50.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.776+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.797+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:08:50.808+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.808+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:08:50.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T09:09:20.987+0000] {processor.py:161} INFO - Started process (PID=1980) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:20.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:09:20.990+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:20.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:21.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:21.039+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:21.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:09:21.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:21.050+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:09:21.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:09:51.930+0000] {processor.py:161} INFO - Started process (PID=1987) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:09:51.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.946+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:09:51.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.977+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:09:51.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:10:22.793+0000] {processor.py:161} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:10:22.798+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.813+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.834+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.834+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:10:22.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.845+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:10:22.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T09:10:53.714+0000] {processor.py:161} INFO - Started process (PID=2001) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:10:53.717+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.730+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:10:53.761+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.760+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:10:53.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:11:24.450+0000] {processor.py:161} INFO - Started process (PID=2008) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:11:24.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.467+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.487+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:11:24.498+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.498+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:11:24.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:11:55.305+0000] {processor.py:161} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:11:55.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.320+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:11:55.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.349+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:11:55.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T09:12:26.133+0000] {processor.py:161} INFO - Started process (PID=2022) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:12:26.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.147+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.167+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:12:26.178+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.178+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:12:26.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T09:12:57.190+0000] {processor.py:161} INFO - Started process (PID=2029) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:12:57.193+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:12:57.250+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.250+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:12:57.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:13:28.170+0000] {processor.py:161} INFO - Started process (PID=2036) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:13:28.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.194+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:13:28.227+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.226+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:13:28.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:13:59.034+0000] {processor.py:161} INFO - Started process (PID=2043) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:13:59.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.052+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.072+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:13:59.083+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.083+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:13:59.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:14:29.887+0000] {processor.py:161} INFO - Started process (PID=2050) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:14:29.889+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.901+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:14:29.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:14:29.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:15:00.785+0000] {processor.py:161} INFO - Started process (PID=2057) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:15:00.788+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.800+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.824+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.824+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:15:00.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.835+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:15:00.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:15:30.906+0000] {processor.py:161} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:15:30.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.919+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.939+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.939+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:15:30.951+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.951+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:15:30.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:16:01.980+0000] {processor.py:161} INFO - Started process (PID=2071) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:01.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:16:01.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:01.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:02.007+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:02.028+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:02.027+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:16:02.038+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:02.038+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:16:02.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:16:32.881+0000] {processor.py:161} INFO - Started process (PID=2078) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:16:32.884+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.934+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:16:32.947+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:16:32.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:17:03.748+0000] {processor.py:161} INFO - Started process (PID=2085) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:17:03.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.762+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:17:03.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:17:03.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T09:17:34.490+0000] {processor.py:161} INFO - Started process (PID=2092) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:17:34.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.505+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.525+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.525+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:17:34.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:17:34.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:18:05.600+0000] {processor.py:161} INFO - Started process (PID=2099) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:18:05.604+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.648+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.648+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:18:05.660+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.660+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:18:05.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:18:36.076+0000] {processor.py:161} INFO - Started process (PID=2106) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:18:36.078+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.101+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:18:36.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.133+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:18:36.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:19:06.960+0000] {processor.py:161} INFO - Started process (PID=2113) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:06.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:19:06.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:06.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:06.987+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:07.020+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:07.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:19:07.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:07.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:19:07.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T09:19:37.169+0000] {processor.py:161} INFO - Started process (PID=2120) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:19:37.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.204+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:19:37.214+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.214+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:19:37.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:20:07.300+0000] {processor.py:161} INFO - Started process (PID=2127) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:20:07.302+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.318+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:20:07.349+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.349+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:20:07.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:20:38.306+0000] {processor.py:161} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:20:38.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.326+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:20:38.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.357+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:20:38.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:21:09.115+0000] {processor.py:161} INFO - Started process (PID=2141) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:21:09.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.136+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.158+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:21:09.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.169+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:21:09.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T09:21:39.923+0000] {processor.py:161} INFO - Started process (PID=2148) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:21:39.926+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.940+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.961+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:21:39.973+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.972+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:21:39.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T09:22:10.678+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:22:10.681+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.711+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:22:10.746+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.746+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:22:10.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
