[2025-07-16T06:47:43.334+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:47:43.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.369+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:47:43.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:47:43.567+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:47:43.567+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:47:43.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.256 seconds
[2025-07-16T06:48:13.960+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:13.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:48:13.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:13.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:13.991+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:14.018+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:14.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:48:14.030+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:14.030+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:48:14.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T06:48:44.611+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:48:44.614+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.663+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:48:44.707+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.706+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:48:44.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:48:44.719+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:48:44.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.134 seconds
[2025-07-16T06:49:14.856+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:49:14.861+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:14.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.919+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:14.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:14.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:49:15.002+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:15.002+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:49:15.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.206 seconds
[2025-07-16T06:49:45.648+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:49:45.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.676+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:49:45.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:49:45.710+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:49:45.710+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:49:45.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T06:50:16.211+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:50:16.214+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:16.266+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:50:16.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:16.278+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:50:16.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T06:50:46.367+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:50:46.370+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.396+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:50:46.419+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.419+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:50:46.430+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:50:46.430+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:50:46.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T06:51:17.073+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:51:17.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.091+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:17.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:51:17.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:17.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:51:17.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T06:51:47.776+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:51:47.778+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.790+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:51:47.810+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:51:47.821+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:51:47.821+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:51:47.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T06:52:18.562+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:52:18.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.583+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:18.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.604+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:52:18.617+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:18.617+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:52:18.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T06:52:49.247+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:52:49.250+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.261+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:52:49.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:52:49.294+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:52:49.294+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:52:49.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T06:53:19.882+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:53:19.884+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.901+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:19.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:53:19.936+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:19.936+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:53:19.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T06:53:50.534+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:53:50.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.550+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:53:50.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.569+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:53:50.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:53:50.580+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:53:50.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T06:54:21.467+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:54:21.469+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.487+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:21.509+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.509+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:54:21.520+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:21.520+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:54:21.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T06:54:51.961+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:51.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:54:51.964+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:51.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:51.990+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:54:52.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:52.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:54:52.025+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:54:52.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:54:52.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T06:55:22.950+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:55:22.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:22.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.964+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:22.985+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:22.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:55:23.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:23.001+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:55:23.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T06:55:53.560+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:55:53.563+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.577+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:55:53.598+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.598+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:55:53.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:55:53.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:55:53.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T06:56:24.504+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:56:24.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:24.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.640+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:56:24.652+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:24.652+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:56:24.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.177 seconds
[2025-07-16T06:56:54.990+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:54.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:56:54.993+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:54.993+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:55.004+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:56:55.023+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:55.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:56:55.035+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:56:55.035+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:56:55.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T06:57:25.390+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:57:25.392+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.406+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:25.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:57:25.438+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:25.438+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:57:25.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T06:57:55.952+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:55.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:57:55.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:55.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:55.978+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:57:56.000+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:56.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:57:56.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:57:56.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:57:56.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T06:58:26.228+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:58:26.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:26.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:58:26.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:26.283+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:58:26.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T06:58:56.549+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:58:56.552+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.552+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.565+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:58:56.585+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:58:56.598+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:58:56.598+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:58:56.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T06:59:26.924+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:59:26.927+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.952+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:26.975+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.975+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:59:26.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:26.987+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:59:27.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T06:59:57.455+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T06:59:57.460+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.609+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T06:59:57.633+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.632+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T06:59:57.645+0000] {logging_mixin.py:188} INFO - [2025-07-16T06:59:57.645+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T06:59:57.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.224 seconds
[2025-07-16T07:00:28.169+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:00:28.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.187+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:28.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:00:28.140+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:28.140+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:00:28.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:00:58.269+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:00:58.271+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.299+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:00:58.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.320+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:00:58.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:00:58.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:00:58.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:01:28.497+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:01:28.500+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.519+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:28.544+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.544+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:01:28.556+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:28.556+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:01:28.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T07:01:58.749+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:01:58.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.778+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:01:58.800+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.800+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:01:58.812+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:01:58.812+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:01:58.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:02:29.147+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:02:29.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.163+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:29.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.185+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:02:29.197+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:29.197+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:02:29.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:02:59.754+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:02:59.756+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.771+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:02:59.791+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:02:59.803+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:02:59.802+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:02:59.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:03:30.033+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:03:30.037+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.066+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:03:30.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:03:30.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:03:30.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:03:30.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T07:04:00.333+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:04:00.336+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.353+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:00.372+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:04:00.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:00.384+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:04:00.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:04:30.829+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:04:30.831+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.845+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:04:30.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:04:30.878+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:04:30.878+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:04:30.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:05:01.067+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:05:01.070+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.081+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:01.100+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.100+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:05:01.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:01.111+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:05:01.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T07:05:31.306+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:05:31.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.328+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:05:31.349+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:05:31.362+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:05:31.362+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:05:31.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.165 seconds
[2025-07-16T07:06:01.637+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:06:01.640+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.653+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:01.672+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:06:01.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:01.684+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:06:01.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:06:31.805+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:06:31.808+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.831+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:06:31.852+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:06:31.863+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:06:31.863+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:06:31.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:07:01.979+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:01.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:07:01.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:01.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:02.000+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:02.020+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:02.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:07:02.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:02.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:07:02.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:07:32.198+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:07:32.200+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.230+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:07:32.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.250+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:07:32.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:07:32.262+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:07:32.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:08:02.524+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:08:02.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.540+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:02.561+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:08:02.573+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:02.573+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:08:02.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:08:32.803+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:08:32.806+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.832+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:08:32.856+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.856+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:08:32.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:08:32.867+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:08:32.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:09:03.146+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:09:03.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.178+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:03.203+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:09:03.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:03.215+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:09:03.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:09:33.366+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:09:33.369+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.395+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:09:33.421+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:09:33.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:09:33.433+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:09:33.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T07:10:04.436+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:10:04.439+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:04.480+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:10:04.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:04.492+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:10:04.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T07:10:34.597+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:10:34.600+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:10:34.650+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:10:34.661+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:10:34.661+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:10:34.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:11:05.215+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:11:05.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.234+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:05.254+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.254+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:11:05.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:05.265+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:11:05.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:11:35.337+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:11:35.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.351+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:11:35.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:11:35.381+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:11:35.381+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:11:35.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:12:05.492+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:12:05.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.508+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:05.528+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:12:05.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:05.539+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:12:05.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:12:35.650+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:12:35.653+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.664+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:12:35.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:12:35.695+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:12:35.695+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:12:35.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T07:13:05.955+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:05.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:13:05.958+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:05.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:05.978+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:06.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:06.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:13:06.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:06.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:13:06.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:13:36.166+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:13:36.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.205+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:13:36.226+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:13:36.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:13:36.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:13:36.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T07:14:06.454+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:14:06.458+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.493+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:06.513+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.513+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:14:06.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:06.524+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:14:06.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T07:14:36.698+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:14:36.701+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.701+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.717+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:14:36.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:14:36.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:14:36.751+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:14:36.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:15:07.015+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:15:07.017+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:07.066+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.066+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:15:07.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:07.076+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:15:07.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:15:37.147+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:15:37.150+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.173+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:15:37.196+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.196+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:15:37.207+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:15:37.207+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:15:37.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:16:07.862+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:16:07.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.878+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:07.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:16:07.909+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:07.909+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:16:07.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:16:38.424+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:16:38.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.440+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:16:38.463+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:16:38.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:16:38.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:16:38.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:17:08.889+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:17:08.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.904+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:08.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:17:08.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:08.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:17:08.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T07:17:39.063+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:17:39.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.084+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:17:39.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.105+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:17:39.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:17:39.117+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:17:39.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:18:09.633+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:18:09.640+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.751+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:09.775+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:18:09.786+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:09.786+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:18:09.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.184 seconds
[2025-07-16T07:18:40.565+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:18:40.568+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.594+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:18:40.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:18:40.626+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:18:40.626+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:18:40.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:19:10.694+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:19:10.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.696+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.710+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:10.730+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.730+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:19:10.741+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:10.741+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:19:10.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:19:41.047+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:19:41.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.050+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.074+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:19:41.098+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:19:41.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:19:41.109+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:19:41.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:20:11.279+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:20:11.290+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.306+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:11.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:20:11.341+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:11.341+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:20:11.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:20:42.157+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:20:42.160+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.182+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:20:42.203+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:20:42.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:20:42.213+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:20:42.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:21:12.391+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:21:12.396+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.425+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:12.446+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.445+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:21:12.456+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:12.456+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:21:12.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T07:21:43.230+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:21:43.233+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.250+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:21:43.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:21:43.285+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:21:43.285+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:21:43.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:22:13.611+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:22:13.616+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.638+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:13.660+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:22:13.671+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:13.671+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:22:13.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:22:43.909+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:22:43.911+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.933+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:22:43.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:22:43.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:22:43.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:22:43.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:23:14.253+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:23:14.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:14.342+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:23:14.357+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:14.357+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:23:14.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.136 seconds
[2025-07-16T07:23:45.136+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:23:45.140+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.168+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:23:45.195+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:23:45.206+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:23:45.206+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:23:45.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:24:15.348+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:24:15.351+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.377+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:15.398+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.398+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:24:15.409+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:15.409+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:24:15.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:24:45.984+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:45.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:24:45.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:45.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:46.011+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:24:46.033+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:46.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:24:46.044+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:24:46.043+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:24:46.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:25:16.612+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:25:16.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.631+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:16.652+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:25:16.664+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:16.663+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:25:16.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:25:46.995+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:46.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:25:46.997+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:46.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:47.020+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:25:47.046+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:47.046+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:25:47.058+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:25:47.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:25:47.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:26:17.222+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:26:17.229+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.274+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:17.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:26:17.310+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:17.310+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:26:17.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.122 seconds
[2025-07-16T07:26:47.743+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:26:47.746+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.746+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.765+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:26:47.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:26:47.805+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:26:47.805+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:26:47.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T07:27:18.473+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:27:18.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.491+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:18.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.512+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:27:18.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:18.524+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:27:18.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:27:49.465+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:27:49.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.484+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:27:49.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.503+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:27:49.514+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:27:49.514+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:27:49.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:28:19.985+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:19.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:28:19.987+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:19.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:20.010+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:20.034+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:20.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:28:20.045+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:20.045+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:28:20.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:28:50.698+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:28:50.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.823+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:28:50.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:28:50.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:28:50.859+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:28:50.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.195 seconds
[2025-07-16T07:29:21.643+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:29:21.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.669+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:21.689+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:29:21.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:21.699+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:29:21.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:29:52.210+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:29:52.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.234+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:29:52.254+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.254+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:29:52.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:29:52.264+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:29:52.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:30:22.908+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:30:22.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.922+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:22.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.942+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:30:22.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:22.952+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:30:22.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T07:30:53.602+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:30:53.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.633+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:30:53.655+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.655+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:30:53.665+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:30:53.665+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:30:53.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:31:24.580+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:31:24.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.609+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:24.630+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:31:24.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:24.641+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:31:24.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:31:55.504+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:31:55.506+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.525+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:31:55.549+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.549+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:31:55.560+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:31:55.560+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:31:55.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:32:26.580+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:32:26.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.602+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:26.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:32:26.635+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:26.634+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:32:26.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:32:57.405+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:32:57.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:32:57.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:32:57.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:32:57.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:32:57.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.128 seconds
[2025-07-16T07:33:28.542+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:33:28.546+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.678+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:28.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:33:28.715+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:28.715+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:33:28.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.203 seconds
[2025-07-16T07:33:59.025+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:33:59.033+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.082+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:33:59.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:33:59.123+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:33:59.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:33:59.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.125 seconds
[2025-07-16T07:34:29.240+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:34:29.244+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.270+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:34:29.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:34:29.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:34:29.303+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:34:29.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:35:00.220+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:35:00.222+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.240+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:00.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:35:00.274+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:00.274+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:35:00.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:35:31.016+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:35:31.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.039+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:35:31.059+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:35:31.069+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:35:31.069+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:35:31.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:36:01.134+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:36:01.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.152+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:01.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:36:01.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:01.182+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:36:01.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:36:32.158+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:36:32.162+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:36:32.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:36:32.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:36:32.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:36:32.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T07:37:02.286+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:37:02.289+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:02.324+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:37:02.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:02.335+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:37:02.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:37:33.226+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:37:33.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:37:33.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:37:33.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:37:33.274+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:37:33.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:38:04.045+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:38:04.047+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.059+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:04.079+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:38:04.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:04.090+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:38:04.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:38:34.835+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:38:34.837+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.849+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:38:34.869+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:38:34.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:38:34.880+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:38:34.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:39:05.671+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:39:05.673+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.691+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:05.713+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:39:05.725+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:05.725+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:39:05.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:39:36.489+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:39:36.491+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.504+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:39:36.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.524+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:39:36.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:39:36.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:39:36.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:40:07.389+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:40:07.391+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.403+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:07.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:40:07.435+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:07.435+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:40:07.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:40:37.946+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:40:37.949+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:37.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.977+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:40:37.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:37.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:40:38.010+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:40:38.010+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:40:38.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:41:08.834+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:41:08.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:08.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:41:08.878+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:08.878+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:41:08.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T07:41:39.407+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:41:39.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:41:39.463+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:41:39.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:41:39.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:41:39.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:42:10.396+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:42:10.399+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.399+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:10.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.440+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:42:10.452+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:10.451+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:42:10.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:42:41.050+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:42:41.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:42:41.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:42:41.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:42:41.110+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:42:41.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:43:12.102+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:43:12.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:12.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:43:12.162+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:12.162+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:43:12.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:43:42.861+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:43:42.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.876+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:43:42.897+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.896+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:43:42.907+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:43:42.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:43:42.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T07:44:13.747+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:44:13.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.771+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:13.792+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:44:13.803+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:13.803+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:44:13.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:44:44.645+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:44:44.647+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.662+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:44:44.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:44:44.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:44:44.696+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:44:44.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T07:45:15.620+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:45:15.623+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.622+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.643+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:15.667+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:45:15.679+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:15.679+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:45:15.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:45:46.456+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:45:46.459+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.476+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:45:46.496+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.496+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:45:46.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:45:46.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:45:46.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:46:17.186+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:46:17.189+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.208+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:17.234+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.234+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:46:17.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:17.248+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:46:17.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-16T07:46:48.267+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:46:48.270+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.270+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:46:48.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:46:48.334+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:46:48.334+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:46:48.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T07:47:18.559+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:47:18.561+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.586+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:18.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.607+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:47:18.621+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:18.621+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:47:18.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T07:47:49.443+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:47:49.447+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.475+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:47:49.497+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:47:49.509+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:47:49.509+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:47:49.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T07:48:20.344+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:48:20.346+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.359+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:20.380+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.380+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:48:20.392+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:20.392+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:48:20.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T07:48:50.867+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:48:50.875+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.894+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:48:50.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:48:50.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:48:50.930+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:48:50.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T07:49:21.497+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:49:21.500+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.527+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:21.551+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.551+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:49:21.563+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:21.563+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:49:21.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T07:49:52.155+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:49:52.157+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.172+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:49:52.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:49:52.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:49:52.205+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:49:52.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:50:22.944+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:50:22.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.961+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:22.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:50:22.992+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:22.992+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:50:23.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T07:50:53.517+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:50:53.519+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.538+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:50:53.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.559+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:50:53.572+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:50:53.572+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:50:53.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:51:24.111+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:51:24.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:24.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:51:24.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:24.163+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:51:24.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T07:51:54.816+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:51:54.819+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.834+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:51:54.855+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:51:54.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:51:54.866+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:51:54.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T07:52:25.546+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:52:25.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.563+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:25.587+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:52:25.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:25.599+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:52:25.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T07:52:56.339+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:52:56.341+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.353+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:52:56.377+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:52:56.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:52:56.390+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:52:56.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T07:53:27.286+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:53:27.288+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.308+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:27.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.330+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:53:27.343+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:27.343+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:53:27.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T07:53:58.083+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:53:58.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.111+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:53:58.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:53:58.145+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:53:58.145+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:53:58.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T07:54:28.975+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:28.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:54:28.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:28.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:29.002+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:54:29.023+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:29.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:54:29.034+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:54:29.034+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:54:29.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:55:00.129+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:55:00.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:00.167+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:55:00.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:00.182+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:55:00.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T07:55:30.977+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:30.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:55:30.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:30.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:31.019+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:55:31.042+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:31.042+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:55:31.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:55:31.053+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:55:31.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T07:56:01.210+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:56:01.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.225+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:01.244+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:56:01.256+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:01.256+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:56:01.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T07:56:31.869+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:56:31.872+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.895+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:56:31.917+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.916+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:56:31.928+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:56:31.928+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:56:31.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T07:57:02.538+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:57:02.541+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.541+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.560+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:02.582+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:57:02.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:02.594+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:57:02.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T07:57:33.294+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:57:33.296+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.319+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:57:33.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:57:33.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:57:33.350+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:57:33.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T07:58:03.421+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:58:03.424+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.424+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:03.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:58:03.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:03.478+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:58:03.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T07:58:34.188+0000] {processor.py:161} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:58:34.191+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.206+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:58:34.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.228+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:58:34.239+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:58:34.239+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:58:34.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T07:59:05.035+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:59:05.037+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:05.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.076+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:59:05.092+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:05.092+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:59:05.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T07:59:35.890+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T07:59:35.893+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.915+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T07:59:35.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T07:59:35.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T07:59:35.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T07:59:35.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:00:06.881+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:00:06.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.904+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:06.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:00:06.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:06.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:00:06.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T08:00:37.788+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:00:37.790+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.790+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.807+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:00:37.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:00:37.838+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:00:37.838+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:00:37.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:01:08.809+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:01:08.812+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.835+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:08.856+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:01:08.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:08.867+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:01:08.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T08:01:39.613+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:01:39.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:01:39.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:01:39.659+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:01:39.659+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:01:39.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:02:10.459+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:02:10.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.480+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:10.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.501+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:02:10.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:10.511+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:02:10.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:02:41.214+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:02:41.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.217+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.232+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:02:41.253+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.253+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:02:41.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:02:41.265+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:02:41.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:03:12.166+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:03:12.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.168+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.183+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:12.204+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:03:12.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:12.217+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:03:12.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:03:42.840+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:03:42.842+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.856+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:03:42.876+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.876+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:03:42.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:03:42.888+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:03:42.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:04:13.645+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:04:13.658+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.658+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.691+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:13.717+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.716+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:04:13.728+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:13.728+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:04:13.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-16T08:04:44.554+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:04:44.557+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.573+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:04:44.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.594+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:04:44.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:04:44.605+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:04:44.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:05:15.362+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:05:15.365+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.380+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:15.400+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:05:15.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:15.411+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:05:15.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:05:46.111+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:05:46.114+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.114+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.134+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:05:46.159+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:05:46.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:05:46.171+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:05:46.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:06:17.106+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:06:17.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.144+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:17.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:06:17.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:17.177+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:06:17.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T08:06:48.144+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:06:48.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.170+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:06:48.193+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.193+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:06:48.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:06:48.212+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:06:48.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:07:19.128+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:07:19.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.173+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:19.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.217+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:07:19.232+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:19.232+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:07:19.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.127 seconds
[2025-07-16T08:07:49.574+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:07:49.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.587+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:07:49.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:07:49.620+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:07:49.619+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:07:49.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:08:20.552+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:08:20.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:20.601+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.600+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:08:20.613+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:20.613+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:08:20.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:08:51.628+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:08:51.631+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.653+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:08:51.674+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.674+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:08:51.685+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:08:51.685+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:08:51.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:09:22.552+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:09:22.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.571+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:22.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.594+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:09:22.604+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:22.604+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:09:22.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:09:53.564+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:09:53.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.578+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:09:53.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:09:53.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:09:53.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:09:53.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:10:24.368+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:10:24.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.385+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:24.405+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:10:24.416+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:24.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:10:24.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:10:55.336+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:10:55.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.354+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:10:55.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:10:55.385+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:10:55.385+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:10:55.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:11:26.172+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:11:26.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.201+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:26.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:11:26.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:26.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:11:26.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:11:57.046+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:11:57.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.064+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:11:57.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:11:57.097+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:11:57.097+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:11:57.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:12:28.028+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:12:28.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:28.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:12:28.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:28.085+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:12:28.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:12:58.375+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:12:58.378+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.377+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.405+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:12:58.425+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.425+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:12:58.436+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:12:58.436+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:12:58.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:13:29.408+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:13:29.412+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:13:29.464+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.464+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:13:29.475+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:13:29.475+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:13:29.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T08:14:00.329+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:14:00.331+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.346+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:00.368+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.367+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:14:00.379+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:00.379+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:14:00.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:14:31.256+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:14:31.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:14:31.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:14:31.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:14:31.317+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:14:31.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:15:02.214+0000] {processor.py:161} INFO - Started process (PID=1238) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:15:02.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.217+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.242+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:02.268+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:15:02.280+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:02.280+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:15:02.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:15:32.532+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:15:32.534+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.556+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:15:32.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:15:32.593+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:15:32.593+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:15:32.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:16:03.551+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:16:03.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.573+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:03.596+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:16:03.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:03.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:16:03.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:16:34.455+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:16:34.457+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.477+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:16:34.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:16:34.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:16:34.511+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:16:34.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T08:17:05.362+0000] {processor.py:161} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:17:05.368+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.380+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:05.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.402+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:17:05.415+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:05.414+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:17:05.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:17:36.085+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:17:36.087+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.087+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.104+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:17:36.126+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:17:36.139+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:17:36.138+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:17:36.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:18:06.995+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:06.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:18:06.998+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:06.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:07.021+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:07.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:07.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:18:07.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:07.053+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:18:07.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:18:37.942+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:18:37.944+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:37.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.961+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:18:37.988+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:37.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:18:38.000+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:18:38.000+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:18:38.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T08:19:08.904+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:19:08.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.938+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:08.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.963+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:19:08.978+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:08.978+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:19:08.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T08:19:39.939+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:19:39.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:39.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.974+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:19:39.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:39.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:19:40.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:19:40.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:19:40.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:20:10.665+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:20:10.667+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.682+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:10.702+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.702+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:20:10.713+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:10.713+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:20:10.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T08:20:41.442+0000] {processor.py:161} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:20:41.445+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.467+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:20:41.489+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:20:41.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:20:41.501+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:20:41.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:21:12.271+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:21:12.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.288+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:12.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:21:12.320+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:12.320+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:21:12.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:21:43.102+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:21:43.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.128+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:21:43.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:21:43.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:21:43.164+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:21:43.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:22:14.020+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:22:14.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.068+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:14.094+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:22:14.111+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:14.111+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:22:14.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-16T08:22:45.113+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:22:45.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.128+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:22:45.151+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:22:45.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:22:45.164+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:22:45.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:23:16.053+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:23:16.056+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.088+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:16.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:23:16.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:16.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:23:16.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T08:23:47.063+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:23:47.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.090+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:23:47.112+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:23:47.124+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:23:47.124+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:23:47.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T08:24:17.932+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:24:17.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.948+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:17.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:24:17.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:17.979+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:24:17.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:24:48.833+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:24:48.838+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.873+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:24:48.895+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.895+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:24:48.907+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:24:48.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:24:48.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T08:25:19.731+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:25:19.738+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.787+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:19.813+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.813+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:25:19.826+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:19.825+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:25:19.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.127 seconds
[2025-07-16T08:25:49.920+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:25:49.922+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.935+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:25:49.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:25:49.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:25:49.968+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:25:49.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:26:20.882+0000] {processor.py:161} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:26:20.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:20.936+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.936+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:26:20.948+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:20.947+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:26:20.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:26:51.814+0000] {processor.py:161} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:26:51.816+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:26:51.850+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.850+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:26:51.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:26:51.862+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:26:51.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:27:22.689+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:27:22.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.718+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:22.680+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:27:22.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:22.692+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:27:22.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:27:53.007+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:27:53.009+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.009+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.031+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:27:53.052+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:27:53.064+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:27:53.064+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:27:53.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:28:23.220+0000] {processor.py:161} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:28:23.222+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.235+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:23.255+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:28:23.267+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:23.266+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:28:23.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T08:28:54.240+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:28:54.242+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.266+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:28:54.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:28:54.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:28:54.299+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:28:54.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:29:25.204+0000] {processor.py:161} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:29:25.206+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:25.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:29:25.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:25.251+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:29:25.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:29:56.137+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:29:56.141+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.245+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:29:56.269+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:29:56.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:29:56.282+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:29:56.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.171 seconds
[2025-07-16T08:30:26.497+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:30:26.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.515+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:26.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:30:26.545+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:26.545+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:30:26.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:30:57.238+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:30:57.241+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.271+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:30:57.293+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.293+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:30:57.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:30:57.308+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:30:57.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T08:31:28.102+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:31:28.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.121+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:28.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.143+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:31:28.155+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:28.155+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:31:28.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:31:58.922+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:31:58.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.936+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:31:58.966+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:31:58.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:31:58.977+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:31:58.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T08:32:29.144+0000] {processor.py:161} INFO - Started process (PID=1476) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:32:29.146+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.168+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:29.188+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.188+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:32:29.200+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:29.200+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:32:29.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:32:59.976+0000] {processor.py:161} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:32:59.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:32:59.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:32:59.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:00.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:00.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:00.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:33:00.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:00.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:33:00.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:33:30.994+0000] {processor.py:161} INFO - Started process (PID=1490) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:30.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:33:30.996+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:30.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:31.012+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:33:31.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:31.030+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:33:31.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:33:31.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:33:31.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:34:01.112+0000] {processor.py:161} INFO - Started process (PID=1497) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:34:01.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.127+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:01.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:34:01.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:01.157+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:34:01.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:34:31.233+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:34:31.235+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.248+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:34:31.268+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:34:31.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:34:31.278+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:34:31.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:35:02.275+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:35:02.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.295+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:02.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:35:02.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:02.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:35:02.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:35:33.326+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:35:33.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.349+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:35:33.374+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:35:33.387+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:35:33.387+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:35:33.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:36:04.246+0000] {processor.py:161} INFO - Started process (PID=1525) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:36:04.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.264+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:04.290+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.290+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:36:04.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:04.303+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:36:04.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T08:36:35.186+0000] {processor.py:161} INFO - Started process (PID=1532) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:36:35.190+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:36:35.235+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:36:35.247+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:36:35.247+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:36:35.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:37:06.168+0000] {processor.py:161} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:37:06.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.190+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:06.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:37:06.223+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:06.223+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:37:06.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:37:36.387+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:37:36.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.390+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.402+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:37:36.422+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.422+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:37:36.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:37:36.433+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:37:36.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:38:06.579+0000] {processor.py:161} INFO - Started process (PID=1553) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:38:06.581+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.595+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:06.620+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.620+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:38:06.634+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:06.634+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:38:06.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T08:38:37.633+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:38:37.636+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.651+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:38:37.670+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:38:37.682+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:38:37.682+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:38:37.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T08:39:07.809+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:39:07.811+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.839+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:07.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:39:07.870+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:07.870+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:39:07.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:39:38.056+0000] {processor.py:161} INFO - Started process (PID=1574) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:39:38.064+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.085+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:39:38.108+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:39:38.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:39:38.120+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:39:38.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:40:09.021+0000] {processor.py:161} INFO - Started process (PID=1581) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:40:09.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.035+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:09.055+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:40:09.068+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:09.068+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:40:09.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:40:40.011+0000] {processor.py:161} INFO - Started process (PID=1588) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:40:40.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.054+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:40:40.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:40:40.090+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:40:40.090+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:40:40.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-07-16T08:41:10.162+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:41:10.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.165+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.191+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:10.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:41:10.224+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:10.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:41:10.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T08:41:41.133+0000] {processor.py:161} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:41:41.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.149+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:41:41.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:41:41.183+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:41:41.183+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:41:41.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:42:11.430+0000] {processor.py:161} INFO - Started process (PID=1609) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:42:11.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.446+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:11.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.466+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:42:11.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:11.479+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:42:11.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:42:41.696+0000] {processor.py:161} INFO - Started process (PID=1616) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:42:41.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.698+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.713+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:42:41.733+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.732+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:42:41.744+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:42:41.744+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:42:41.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:43:11.884+0000] {processor.py:161} INFO - Started process (PID=1623) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:43:11.887+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:11.923+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:43:11.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:11.934+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:43:11.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:43:42.649+0000] {processor.py:161} INFO - Started process (PID=1630) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:43:42.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.663+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:43:42.686+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.686+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:43:42.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:43:42.698+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:43:42.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:44:13.574+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:44:13.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.589+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:13.612+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.612+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:44:13.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:13.624+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:44:13.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:44:44.051+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:44:44.053+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.066+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:44:44.089+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:44:44.102+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:44:44.101+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:44:44.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:45:14.936+0000] {processor.py:161} INFO - Started process (PID=1651) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:45:14.938+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:14.980+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:45:14.993+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:14.993+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:45:15.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T08:45:45.841+0000] {processor.py:161} INFO - Started process (PID=1658) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:45:45.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.864+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:45:45.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.890+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:45:45.903+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:45:45.902+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:45:45.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T08:46:16.856+0000] {processor.py:161} INFO - Started process (PID=1665) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:46:16.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.884+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:16.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:46:16.922+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:16.922+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:46:16.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T08:46:47.779+0000] {processor.py:161} INFO - Started process (PID=1672) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:46:47.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.802+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:46:47.830+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:46:47.844+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:46:47.844+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:46:47.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T08:47:18.776+0000] {processor.py:161} INFO - Started process (PID=1679) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:47:18.779+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.806+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:18.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:47:18.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:18.839+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:47:18.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T08:47:48.894+0000] {processor.py:161} INFO - Started process (PID=1686) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:47:48.896+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:47:48.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.933+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:47:48.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:47:48.945+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:47:48.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:48:19.107+0000] {processor.py:161} INFO - Started process (PID=1693) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:48:19.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.122+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:19.142+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:48:19.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:19.152+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:48:19.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T08:48:49.546+0000] {processor.py:161} INFO - Started process (PID=1700) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:48:49.552+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.552+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.657+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:48:49.678+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.678+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:48:49.690+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:48:49.690+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:48:49.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.172 seconds
[2025-07-16T08:49:20.503+0000] {processor.py:161} INFO - Started process (PID=1707) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:49:20.506+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:20.575+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:49:20.588+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:20.588+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:49:20.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-16T08:49:51.442+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:49:51.445+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.472+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:49:51.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:49:51.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:49:51.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:49:51.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T08:50:22.427+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:50:22.430+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:22.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.466+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:50:22.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:22.478+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:50:22.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T08:50:53.191+0000] {processor.py:161} INFO - Started process (PID=1728) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:50:53.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.206+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:50:53.226+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:50:53.239+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:50:53.239+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:50:53.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:51:24.041+0000] {processor.py:161} INFO - Started process (PID=1735) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:51:24.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.107+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:24.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:51:24.146+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:24.146+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:51:24.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.139 seconds
[2025-07-16T08:51:54.950+0000] {processor.py:161} INFO - Started process (PID=1742) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:51:54.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:54.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.971+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:51:54.992+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:54.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:51:55.004+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:51:55.004+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:51:55.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T08:52:25.932+0000] {processor.py:161} INFO - Started process (PID=1749) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:25.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:52:25.938+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:25.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:26.054+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:26.080+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:26.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:52:26.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:26.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:52:26.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.187 seconds
[2025-07-16T08:52:56.213+0000] {processor.py:161} INFO - Started process (PID=1756) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:52:56.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.238+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:52:56.261+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:52:56.273+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:52:56.272+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:52:56.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T08:53:27.137+0000] {processor.py:161} INFO - Started process (PID=1763) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:53:27.139+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.154+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:27.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.174+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:53:27.186+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:27.185+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:53:27.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:53:58.049+0000] {processor.py:161} INFO - Started process (PID=1770) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:53:58.051+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:53:58.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:53:58.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:53:58.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:53:58.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T08:54:28.802+0000] {processor.py:161} INFO - Started process (PID=1777) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:54:28.804+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.819+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:28.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.839+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:54:28.851+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:28.850+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:54:28.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T08:54:59.661+0000] {processor.py:161} INFO - Started process (PID=1784) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:54:59.663+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.683+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:54:59.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.704+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:54:59.715+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:54:59.714+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:54:59.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T08:55:30.577+0000] {processor.py:161} INFO - Started process (PID=1791) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:55:30.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.612+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:55:30.638+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:55:30.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:55:30.649+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:55:30.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T08:56:01.592+0000] {processor.py:161} INFO - Started process (PID=1798) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:56:01.595+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.594+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.619+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:01.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:56:01.665+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:01.664+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:56:01.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T08:56:32.613+0000] {processor.py:161} INFO - Started process (PID=1805) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:56:32.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:56:32.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:56:32.659+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:56:32.659+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:56:32.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T08:57:03.545+0000] {processor.py:161} INFO - Started process (PID=1812) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:57:03.547+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.561+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:03.582+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.582+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:57:03.593+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:03.593+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:57:03.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T08:57:34.369+0000] {processor.py:161} INFO - Started process (PID=1819) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:57:34.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.387+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:57:34.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.408+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:57:34.419+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:57:34.419+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:57:34.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:58:05.236+0000] {processor.py:161} INFO - Started process (PID=1826) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:58:05.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.254+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:05.285+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.285+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:58:05.297+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:05.297+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:58:05.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T08:58:36.135+0000] {processor.py:161} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:58:36.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.154+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:58:36.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.174+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:58:36.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:58:36.185+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:58:36.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T08:59:06.432+0000] {processor.py:161} INFO - Started process (PID=1840) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:59:06.436+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.505+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:06.528+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.527+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:59:06.543+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:06.543+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:59:06.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.138 seconds
[2025-07-16T08:59:37.450+0000] {processor.py:161} INFO - Started process (PID=1847) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T08:59:37.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.468+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T08:59:37.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.490+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T08:59:37.502+0000] {logging_mixin.py:188} INFO - [2025-07-16T08:59:37.502+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T08:59:37.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T09:00:08.356+0000] {processor.py:161} INFO - Started process (PID=1854) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:00:08.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.358+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.379+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:08.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.402+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:00:08.413+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:08.413+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:00:08.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:00:39.309+0000] {processor.py:161} INFO - Started process (PID=1861) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:00:39.312+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.326+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:00:39.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:00:39.359+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:00:39.359+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:00:39.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:01:10.190+0000] {processor.py:161} INFO - Started process (PID=1868) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:01:10.192+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:10.228+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.228+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:01:10.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:10.240+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:01:10.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:01:41.082+0000] {processor.py:161} INFO - Started process (PID=1875) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:01:41.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.112+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:01:41.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:01:41.148+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:01:41.148+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:01:41.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:02:12.083+0000] {processor.py:161} INFO - Started process (PID=1882) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:02:12.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.096+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:12.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:02:12.127+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:12.127+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:02:12.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.065 seconds
[2025-07-16T09:02:42.436+0000] {processor.py:161} INFO - Started process (PID=1889) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:02:42.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.460+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:02:42.483+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.482+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:02:42.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:02:42.494+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:02:42.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:03:12.823+0000] {processor.py:161} INFO - Started process (PID=1896) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:03:12.826+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:12.869+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:03:12.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:12.880+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:03:12.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:03:44.039+0000] {processor.py:161} INFO - Started process (PID=1903) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:03:44.043+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.062+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:03:44.082+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:03:44.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:03:44.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:03:44.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:04:14.982+0000] {processor.py:161} INFO - Started process (PID=1910) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:14.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:04:14.985+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:14.985+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:15.010+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:15.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:15.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:04:15.045+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:15.044+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:04:15.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T09:04:45.691+0000] {processor.py:161} INFO - Started process (PID=1917) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:04:45.694+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.694+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.712+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:04:45.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:04:45.745+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:04:45.745+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:04:45.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T09:05:16.646+0000] {processor.py:161} INFO - Started process (PID=1924) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:05:16.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.649+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:16.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.695+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:05:16.708+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:16.708+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:05:16.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T09:05:47.643+0000] {processor.py:161} INFO - Started process (PID=1931) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:05:47.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:05:47.691+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.691+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:05:47.702+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:05:47.702+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:05:47.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:06:17.962+0000] {processor.py:161} INFO - Started process (PID=1938) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:17.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:06:17.974+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:17.973+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:18.002+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:18.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:18.024+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:06:18.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:18.035+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:06:18.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T09:06:48.235+0000] {processor.py:161} INFO - Started process (PID=1945) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:06:48.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.263+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:06:48.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:06:48.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:06:48.298+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:06:48.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T09:07:18.502+0000] {processor.py:161} INFO - Started process (PID=1952) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:07:18.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.525+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:18.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:07:18.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:18.559+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:07:18.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T09:07:49.524+0000] {processor.py:161} INFO - Started process (PID=1959) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:07:49.526+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:07:49.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:07:49.584+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:07:49.584+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:07:49.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T09:08:20.598+0000] {processor.py:161} INFO - Started process (PID=1966) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:08:20.601+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.626+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:20.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:08:20.662+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:20.662+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:08:20.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:08:50.760+0000] {processor.py:161} INFO - Started process (PID=1973) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:08:50.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.776+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:08:50.797+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:08:50.808+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:08:50.808+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:08:50.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T09:09:20.987+0000] {processor.py:161} INFO - Started process (PID=1980) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:20.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:09:20.990+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:20.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:21.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:21.039+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:21.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:09:21.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:21.050+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:09:21.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:09:51.930+0000] {processor.py:161} INFO - Started process (PID=1987) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:09:51.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.946+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:09:51.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:09:51.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:09:51.977+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:09:51.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:10:22.793+0000] {processor.py:161} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:10:22.798+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.813+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:22.834+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.834+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:10:22.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:22.845+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:10:22.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T09:10:53.714+0000] {processor.py:161} INFO - Started process (PID=2001) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:10:53.717+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.730+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:10:53.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:10:53.761+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:10:53.760+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:10:53.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:11:24.450+0000] {processor.py:161} INFO - Started process (PID=2008) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:11:24.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.467+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:24.487+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:11:24.498+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:24.498+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:11:24.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:11:55.305+0000] {processor.py:161} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:11:55.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.320+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:11:55.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:11:55.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:11:55.349+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:11:55.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-16T09:12:26.133+0000] {processor.py:161} INFO - Started process (PID=2022) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:12:26.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.147+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:26.167+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:12:26.178+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:26.178+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:12:26.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T09:12:57.190+0000] {processor.py:161} INFO - Started process (PID=2029) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:12:57.193+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:12:57.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:12:57.250+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:12:57.250+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:12:57.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:13:28.170+0000] {processor.py:161} INFO - Started process (PID=2036) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:13:28.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.194+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:28.215+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:13:28.227+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:28.226+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:13:28.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:13:59.034+0000] {processor.py:161} INFO - Started process (PID=2043) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:13:59.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.052+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:13:59.072+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:13:59.083+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:13:59.083+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:13:59.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:14:29.887+0000] {processor.py:161} INFO - Started process (PID=2050) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:14:29.889+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.901+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:14:29.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:14:29.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:14:29.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:14:29.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:15:00.785+0000] {processor.py:161} INFO - Started process (PID=2057) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:15:00.788+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.800+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:00.824+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.824+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:15:00.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:00.835+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:15:00.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:15:30.906+0000] {processor.py:161} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:15:30.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.919+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:15:30.939+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.939+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:15:30.951+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:15:30.951+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:15:30.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:16:01.980+0000] {processor.py:161} INFO - Started process (PID=2071) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:01.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:16:01.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:01.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:02.007+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:02.028+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:02.027+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:16:02.038+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:02.038+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:16:02.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:16:32.881+0000] {processor.py:161} INFO - Started process (PID=2078) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:16:32.884+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:16:32.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.934+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:16:32.947+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:16:32.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:16:32.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T09:17:03.748+0000] {processor.py:161} INFO - Started process (PID=2085) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:17:03.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.762+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:03.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:17:03.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:03.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:17:03.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-16T09:17:34.490+0000] {processor.py:161} INFO - Started process (PID=2092) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:17:34.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.505+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:17:34.525+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.525+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:17:34.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:17:34.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:17:34.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:18:05.600+0000] {processor.py:161} INFO - Started process (PID=2099) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:18:05.604+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.627+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:05.648+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.648+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:18:05.660+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:05.660+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:18:05.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:18:36.076+0000] {processor.py:161} INFO - Started process (PID=2106) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:18:36.078+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.101+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:18:36.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:18:36.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:18:36.133+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:18:36.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:19:06.960+0000] {processor.py:161} INFO - Started process (PID=2113) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:06.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:19:06.963+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:06.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:06.987+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:07.020+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:07.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:19:07.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:07.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:19:07.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T09:19:37.169+0000] {processor.py:161} INFO - Started process (PID=2120) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:19:37.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:19:37.204+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:19:37.214+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:19:37.214+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:19:37.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:20:07.300+0000] {processor.py:161} INFO - Started process (PID=2127) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:20:07.302+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.318+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:07.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:20:07.349+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:07.349+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:20:07.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:20:38.306+0000] {processor.py:161} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:20:38.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.326+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:20:38.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:20:38.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:20:38.357+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:20:38.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:21:09.115+0000] {processor.py:161} INFO - Started process (PID=2141) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:21:09.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.136+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:09.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.158+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:21:09.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:09.169+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:21:09.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T09:21:39.923+0000] {processor.py:161} INFO - Started process (PID=2148) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:21:39.926+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.940+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:21:39.961+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:21:39.973+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:21:39.972+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:21:39.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T09:22:10.678+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:22:10.681+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.711+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:10.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:22:10.746+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:10.746+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:22:10.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T09:22:41.648+0000] {processor.py:161} INFO - Started process (PID=2162) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:41.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:22:41.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:41.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:41.675+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:22:41.705+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:41.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:22:41.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:22:41.719+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:22:41.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:23:12.606+0000] {processor.py:161} INFO - Started process (PID=2169) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:12.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:23:12.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:12.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:12.632+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:12.656+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:12.656+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:23:12.668+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:12.668+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:23:12.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T09:23:43.514+0000] {processor.py:161} INFO - Started process (PID=2176) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:43.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:23:43.519+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:43.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:43.542+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:23:43.563+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:43.563+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:23:43.575+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:23:43.574+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:23:43.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T09:24:14.352+0000] {processor.py:161} INFO - Started process (PID=2183) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:14.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:24:14.355+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:14.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:14.388+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:14.416+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:14.416+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:24:14.429+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:14.429+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:24:14.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T09:24:45.161+0000] {processor.py:161} INFO - Started process (PID=2190) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:45.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:24:45.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:45.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:45.180+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:24:45.201+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:45.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:24:45.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:24:45.213+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:24:45.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T09:25:15.986+0000] {processor.py:161} INFO - Started process (PID=2197) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:15.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:25:15.988+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:15.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:16.005+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:16.025+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:16.025+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:25:16.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:16.036+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:25:16.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:25:46.949+0000] {processor.py:161} INFO - Started process (PID=2204) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:46.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:25:46.952+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:46.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:46.976+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:25:46.996+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:46.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:25:47.008+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:25:47.008+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:25:47.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T09:26:17.987+0000] {processor.py:161} INFO - Started process (PID=2211) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:17.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:26:17.990+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:17.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:18.009+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:18.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:18.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:26:18.040+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:18.040+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:26:18.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T09:26:48.961+0000] {processor.py:161} INFO - Started process (PID=2218) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:48.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:26:48.965+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:48.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:48.987+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:26:49.011+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:49.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:26:49.026+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:26:49.026+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:26:49.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T09:27:19.136+0000] {processor.py:161} INFO - Started process (PID=2225) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:19.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:27:19.139+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:19.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:19.155+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:19.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:19.177+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:27:19.188+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:19.188+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:27:19.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:27:49.253+0000] {processor.py:161} INFO - Started process (PID=2232) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:49.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:27:49.256+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:49.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:49.274+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:27:49.296+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:49.296+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:27:49.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:27:49.307+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:27:49.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:28:19.522+0000] {processor.py:161} INFO - Started process (PID=2239) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:19.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:28:19.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:19.524+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:19.538+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:19.558+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:19.558+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:28:19.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:19.569+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:28:19.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:28:49.758+0000] {processor.py:161} INFO - Started process (PID=2246) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:49.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:28:49.760+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:49.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:49.776+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:28:49.798+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:49.798+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:28:49.809+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:28:49.809+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:28:49.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:29:20.747+0000] {processor.py:161} INFO - Started process (PID=2253) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:20.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:29:20.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:20.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:20.762+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:20.783+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:20.783+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:29:20.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:20.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:29:20.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T09:29:51.071+0000] {processor.py:161} INFO - Started process (PID=2260) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:51.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:29:51.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:51.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:51.094+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:29:51.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:51.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:29:51.130+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:29:51.130+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:29:51.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T09:30:22.071+0000] {processor.py:161} INFO - Started process (PID=2267) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:22.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:30:22.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:22.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:22.101+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:22.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:22.122+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:30:22.134+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:22.133+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:30:22.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T09:30:53.161+0000] {processor.py:161} INFO - Started process (PID=2274) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:53.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:30:53.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:53.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:53.198+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:30:53.221+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:53.221+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:30:53.233+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:30:53.233+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:30:53.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T09:31:23.411+0000] {processor.py:161} INFO - Started process (PID=2281) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:23.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:31:23.413+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:23.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:23.433+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:23.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:23.453+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:31:23.465+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:23.465+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:31:23.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T09:31:54.443+0000] {processor.py:161} INFO - Started process (PID=2288) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:54.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:31:54.446+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:54.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:54.462+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:31:54.483+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:54.483+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:31:54.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:31:54.494+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:31:54.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:32:25.465+0000] {processor.py:161} INFO - Started process (PID=2295) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:25.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:32:25.468+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:25.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:25.481+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:25.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:25.501+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:32:25.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:25.512+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:32:25.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:32:56.402+0000] {processor.py:161} INFO - Started process (PID=2302) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:56.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:32:56.404+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:56.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:56.424+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:32:56.447+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:56.446+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:32:56.458+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:32:56.458+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:32:56.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:33:27.406+0000] {processor.py:161} INFO - Started process (PID=2309) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:27.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:33:27.409+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:27.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:27.422+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:27.442+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:27.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:33:27.454+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:27.453+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:33:27.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:33:58.292+0000] {processor.py:161} INFO - Started process (PID=2316) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:58.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:33:58.294+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:58.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:58.307+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:33:58.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:58.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:33:58.337+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:33:58.337+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:33:58.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:34:28.459+0000] {processor.py:161} INFO - Started process (PID=2323) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:28.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:34:28.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:28.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:28.477+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:28.497+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:28.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:34:28.508+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:28.508+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:34:28.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T09:34:59.444+0000] {processor.py:161} INFO - Started process (PID=2330) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:59.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:34:59.447+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:59.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:59.469+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:34:59.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:59.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:34:59.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:34:59.504+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:34:59.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T09:35:30.504+0000] {processor.py:161} INFO - Started process (PID=2337) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:35:30.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:35:30.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:35:30.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:35:30.532+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:35:30.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:35:30.553+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:35:30.565+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:35:30.565+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:35:30.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T09:36:01.550+0000] {processor.py:161} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:01.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:36:01.553+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:01.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:01.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:01.602+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:01.602+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:36:01.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:01.615+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:36:01.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T09:36:31.746+0000] {processor.py:161} INFO - Started process (PID=2351) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:31.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:36:31.749+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:31.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:31.763+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:36:31.787+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:31.787+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:36:31.798+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:36:31.798+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:36:31.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:37:01.931+0000] {processor.py:161} INFO - Started process (PID=2358) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:01.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:37:01.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:01.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:01.950+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:01.969+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:01.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:37:01.980+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:01.979+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:37:01.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T09:37:32.492+0000] {processor.py:161} INFO - Started process (PID=2365) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:32.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:37:32.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:32.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:32.518+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:37:32.541+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:32.541+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:37:32.551+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:37:32.551+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:37:32.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T09:38:03.581+0000] {processor.py:161} INFO - Started process (PID=2372) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:03.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:38:03.590+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:03.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:03.603+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:03.623+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:03.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:38:03.634+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:03.634+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:38:03.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:38:33.693+0000] {processor.py:161} INFO - Started process (PID=2379) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:33.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:38:33.695+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:33.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:33.711+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:38:33.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:33.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:38:33.747+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:38:33.747+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:38:33.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T09:39:03.791+0000] {processor.py:161} INFO - Started process (PID=2386) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:03.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:39:03.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:03.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:03.806+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:03.825+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:03.825+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:39:03.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:03.836+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:39:03.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:39:34.879+0000] {processor.py:161} INFO - Started process (PID=2393) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:34.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:39:34.882+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:34.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:34.899+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:39:34.920+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:34.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:39:34.932+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:39:34.932+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:39:34.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:40:05.926+0000] {processor.py:161} INFO - Started process (PID=2400) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:05.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:40:05.929+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:05.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:05.952+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:05.971+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:05.971+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:40:05.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:05.982+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:40:05.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:40:36.060+0000] {processor.py:161} INFO - Started process (PID=2407) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:36.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:40:36.063+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:36.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:36.076+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:40:36.098+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:36.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:40:36.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:40:36.110+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:40:36.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T09:41:07.012+0000] {processor.py:161} INFO - Started process (PID=2414) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:07.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:41:07.015+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:07.015+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:07.039+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:07.062+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:07.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:41:07.073+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:07.073+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:41:07.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:41:37.907+0000] {processor.py:161} INFO - Started process (PID=2421) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:37.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:41:37.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:37.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:37.936+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:41:37.959+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:37.958+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:41:37.970+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:41:37.970+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:41:37.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T09:42:08.947+0000] {processor.py:161} INFO - Started process (PID=2428) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:08.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:42:08.950+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:08.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:08.983+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:09.007+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:09.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:42:09.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:09.019+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:42:09.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T09:42:39.188+0000] {processor.py:161} INFO - Started process (PID=2435) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:39.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:42:39.193+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:39.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:39.234+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:42:39.268+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:39.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:42:39.281+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:42:39.281+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:42:39.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.119 seconds
[2025-07-16T09:43:09.391+0000] {processor.py:161} INFO - Started process (PID=2442) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:09.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:43:09.418+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:09.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:09.474+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:09.495+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:09.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:43:09.507+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:09.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:43:09.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.137 seconds
[2025-07-16T09:43:39.593+0000] {processor.py:161} INFO - Started process (PID=2449) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:39.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:43:39.597+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:39.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:39.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:43:39.653+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:39.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:43:39.668+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:43:39.667+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:43:39.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T09:44:09.889+0000] {processor.py:161} INFO - Started process (PID=2456) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:09.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:44:09.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:09.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:09.911+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:09.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:09.934+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:44:09.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:09.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:44:09.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T09:44:40.018+0000] {processor.py:161} INFO - Started process (PID=2463) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:40.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:44:40.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:40.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:40.045+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:44:40.067+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:40.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:44:40.081+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:44:40.081+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:44:40.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T09:45:10.204+0000] {processor.py:161} INFO - Started process (PID=2470) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:10.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:45:10.207+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:10.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:10.238+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:10.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:10.259+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:45:10.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:10.275+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:45:10.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T09:45:40.410+0000] {processor.py:161} INFO - Started process (PID=2477) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:40.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:45:40.414+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:40.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:40.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:45:40.468+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:40.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:45:40.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:45:40.479+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:45:40.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:46:10.643+0000] {processor.py:161} INFO - Started process (PID=2484) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:10.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:46:10.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:10.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:10.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:10.690+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:10.690+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:46:10.701+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:10.701+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:46:10.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:46:40.820+0000] {processor.py:161} INFO - Started process (PID=2491) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:40.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:46:40.823+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:40.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:40.838+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:46:40.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:40.858+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:46:40.869+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:46:40.869+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:46:40.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T09:47:11.074+0000] {processor.py:161} INFO - Started process (PID=2498) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:11.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:47:11.076+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:11.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:11.088+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:11.107+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:11.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:47:11.118+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:11.118+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:47:11.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T09:47:42.059+0000] {processor.py:161} INFO - Started process (PID=2505) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:42.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:47:42.062+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:42.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:42.078+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:47:42.100+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:42.099+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:47:42.112+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:47:42.112+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:47:42.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T09:48:12.190+0000] {processor.py:161} INFO - Started process (PID=2512) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:12.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:48:12.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:12.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:12.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:12.230+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:12.230+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:48:12.243+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:12.243+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:48:12.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T09:48:43.161+0000] {processor.py:161} INFO - Started process (PID=2519) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:43.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:48:43.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:43.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:43.177+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:48:43.199+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:43.199+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:48:43.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:48:43.211+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:48:43.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T09:49:14.060+0000] {processor.py:161} INFO - Started process (PID=2526) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:14.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:49:14.063+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:14.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:14.083+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:14.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:14.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:49:14.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:14.117+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:49:14.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:49:44.942+0000] {processor.py:161} INFO - Started process (PID=2533) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:44.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:49:44.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:44.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:44.979+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:49:45.004+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:45.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:49:45.016+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:49:45.016+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:49:45.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T09:50:15.881+0000] {processor.py:161} INFO - Started process (PID=2540) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:15.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:50:15.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:15.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:15.896+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:15.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:15.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:50:15.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:15.930+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:50:15.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T09:50:46.741+0000] {processor.py:161} INFO - Started process (PID=2547) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:46.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:50:46.745+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:46.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:46.760+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:50:46.781+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:46.780+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:50:46.792+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:50:46.792+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:50:46.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T09:51:17.566+0000] {processor.py:161} INFO - Started process (PID=2554) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:17.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:51:17.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:17.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:17.593+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:17.616+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:17.616+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:51:17.627+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:17.627+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:51:17.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T09:51:48.642+0000] {processor.py:161} INFO - Started process (PID=2561) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:48.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:51:48.645+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:48.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:48.697+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:51:48.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:48.718+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:51:48.731+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:51:48.731+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:51:48.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.113 seconds
[2025-07-16T09:52:18.799+0000] {processor.py:161} INFO - Started process (PID=2568) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:18.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:52:18.802+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:18.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:18.817+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:18.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:18.846+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:52:18.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:18.858+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:52:18.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T09:52:49.711+0000] {processor.py:161} INFO - Started process (PID=2575) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:49.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:52:49.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:49.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:49.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:52:49.770+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:49.770+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:52:49.783+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:52:49.783+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:52:49.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T09:53:20.215+0000] {processor.py:161} INFO - Started process (PID=2582) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:20.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:53:20.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:20.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:20.245+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:20.272+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:20.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:53:20.284+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:20.284+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:53:20.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:53:50.380+0000] {processor.py:161} INFO - Started process (PID=2589) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:50.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:53:50.383+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:50.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:50.398+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:53:50.421+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:50.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:53:50.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:53:50.431+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:53:50.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T09:54:20.552+0000] {processor.py:161} INFO - Started process (PID=2596) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:20.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:54:20.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:20.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:20.578+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:20.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:20.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:54:20.611+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:20.611+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:54:20.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:54:50.716+0000] {processor.py:161} INFO - Started process (PID=2603) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:50.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:54:50.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:50.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:50.735+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:54:50.758+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:50.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:54:50.770+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:54:50.770+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:54:50.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T09:55:21.820+0000] {processor.py:161} INFO - Started process (PID=2610) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:21.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:55:21.823+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:21.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:21.857+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:21.879+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:21.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:55:21.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:21.892+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:55:21.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T09:55:52.790+0000] {processor.py:161} INFO - Started process (PID=2617) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:52.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:55:52.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:52.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:52.813+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:55:52.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:52.838+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:55:52.854+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:55:52.854+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:55:52.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T09:56:23.838+0000] {processor.py:161} INFO - Started process (PID=2624) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:23.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:56:23.841+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:23.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:23.867+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:23.891+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:23.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:56:23.904+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:23.904+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:56:23.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T09:56:54.646+0000] {processor.py:161} INFO - Started process (PID=2631) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:54.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:56:54.648+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:54.648+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:54.661+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:56:54.687+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:54.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:56:54.700+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:56:54.700+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:56:54.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T09:57:25.521+0000] {processor.py:161} INFO - Started process (PID=2638) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:25.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:57:25.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:25.524+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:25.540+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:25.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:25.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:57:25.579+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:25.579+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:57:25.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T09:57:55.714+0000] {processor.py:161} INFO - Started process (PID=2645) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:55.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:57:55.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:55.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:55.763+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:57:55.783+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:55.783+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:57:55.795+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:57:55.794+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:57:55.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T09:58:26.720+0000] {processor.py:161} INFO - Started process (PID=2652) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:26.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:58:26.723+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:26.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:26.739+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:26.762+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:26.762+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:58:26.774+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:26.774+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:58:26.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T09:58:56.885+0000] {processor.py:161} INFO - Started process (PID=2659) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:56.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:58:56.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:56.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:56.914+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:58:56.939+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:56.939+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:58:56.952+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:58:56.952+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:58:56.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T09:59:27.113+0000] {processor.py:161} INFO - Started process (PID=2666) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:27.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:59:27.119+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:27.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:27.148+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:27.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:27.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:59:27.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:27.182+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:59:27.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T09:59:57.361+0000] {processor.py:161} INFO - Started process (PID=2673) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:57.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T09:59:57.365+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:57.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:57.397+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T09:59:57.420+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:57.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T09:59:57.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T09:59:57.432+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T09:59:57.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T10:00:27.545+0000] {processor.py:161} INFO - Started process (PID=2680) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:27.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:00:27.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:27.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:27.572+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:27.595+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:27.595+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:00:27.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:27.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:00:27.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T10:00:57.929+0000] {processor.py:161} INFO - Started process (PID=2687) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:57.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:00:57.932+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:57.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:57.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:00:57.978+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:57.978+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:00:57.989+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:00:57.989+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:00:58.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:01:28.988+0000] {processor.py:161} INFO - Started process (PID=2694) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:28.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:01:28.991+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:28.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:29.009+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:29.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:29.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:01:29.040+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:29.040+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:01:29.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:01:59.847+0000] {processor.py:161} INFO - Started process (PID=2701) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:59.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:01:59.850+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:59.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:59.865+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:01:59.886+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:59.886+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:01:59.897+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:01:59.897+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:01:59.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T10:02:30.653+0000] {processor.py:161} INFO - Started process (PID=2708) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:02:30.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:02:30.656+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:02:30.656+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:02:30.681+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:02:30.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:02:30.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:02:30.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:02:30.726+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:02:30.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T10:03:00.878+0000] {processor.py:161} INFO - Started process (PID=2715) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:00.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:03:00.881+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:00.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:00.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:00.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:00.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:03:00.941+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:00.941+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:03:00.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T10:03:31.821+0000] {processor.py:161} INFO - Started process (PID=2722) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:31.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:03:31.824+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:31.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:31.840+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:03:31.863+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:31.863+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:03:31.875+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:03:31.875+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:03:31.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T10:04:02.717+0000] {processor.py:161} INFO - Started process (PID=2729) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:02.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:04:02.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:02.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:02.733+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:02.754+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:02.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:04:02.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:02.764+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:04:02.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:04:33.438+0000] {processor.py:161} INFO - Started process (PID=2736) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:33.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:04:33.441+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:33.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:33.470+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:04:33.493+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:33.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:04:33.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:04:33.504+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:04:33.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T10:05:04.369+0000] {processor.py:161} INFO - Started process (PID=2743) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:04.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:05:04.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:04.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:04.419+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:04.442+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:04.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:05:04.454+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:04.454+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:05:04.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-16T10:05:35.144+0000] {processor.py:161} INFO - Started process (PID=2750) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:35.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:05:35.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:35.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:35.163+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:05:35.195+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:35.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:05:35.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:05:35.213+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:05:35.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T10:06:06.009+0000] {processor.py:161} INFO - Started process (PID=2757) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:06.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:06:06.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:06.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:06.042+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:06.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:06.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:06:06.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:06.077+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:06:06.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T10:06:36.866+0000] {processor.py:161} INFO - Started process (PID=2764) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:36.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:06:36.870+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:36.869+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:36.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:06:36.921+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:36.921+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:06:36.932+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:06:36.932+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:06:36.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T10:07:07.814+0000] {processor.py:161} INFO - Started process (PID=2771) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:07.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:07:07.818+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:07.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:07.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:07.872+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:07.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:07:07.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:07.883+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:07:07.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:07:38.717+0000] {processor.py:161} INFO - Started process (PID=2778) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:38.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:07:38.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:38.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:38.738+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:07:38.763+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:38.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:07:38.774+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:07:38.774+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:07:38.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T10:08:09.624+0000] {processor.py:161} INFO - Started process (PID=2785) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:09.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:08:09.626+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:09.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:09.639+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:09.660+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:09.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:08:09.671+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:09.671+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:08:09.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:08:40.451+0000] {processor.py:161} INFO - Started process (PID=2792) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:40.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:08:40.454+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:40.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:40.486+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:08:40.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:40.511+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:08:40.522+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:08:40.522+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:08:40.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T10:09:11.305+0000] {processor.py:161} INFO - Started process (PID=2799) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:11.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:09:11.308+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:11.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:11.332+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:11.353+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:11.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:09:11.365+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:11.365+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:09:11.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T10:09:42.256+0000] {processor.py:161} INFO - Started process (PID=2806) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:42.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:09:42.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:42.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:42.291+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:09:42.315+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:42.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:09:42.328+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:09:42.328+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:09:42.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T10:10:13.369+0000] {processor.py:161} INFO - Started process (PID=2813) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:13.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:10:13.372+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:13.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:13.398+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:13.420+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:13.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:10:13.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:13.432+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:10:13.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T10:10:43.569+0000] {processor.py:161} INFO - Started process (PID=2820) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:43.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:10:43.572+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:43.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:43.596+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:10:43.617+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:43.616+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:10:43.627+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:10:43.627+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:10:43.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T10:11:14.599+0000] {processor.py:161} INFO - Started process (PID=2827) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:14.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:11:14.602+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:14.602+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:14.616+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:14.636+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:14.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:11:14.647+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:14.647+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:11:14.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T10:11:45.542+0000] {processor.py:161} INFO - Started process (PID=2834) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:45.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:11:45.544+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:45.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:45.557+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:11:45.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:45.580+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:11:45.591+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:11:45.591+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:11:45.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:12:16.301+0000] {processor.py:161} INFO - Started process (PID=2841) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:16.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:12:16.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:16.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:16.317+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:16.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:16.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:12:16.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:16.350+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:12:16.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:12:47.229+0000] {processor.py:161} INFO - Started process (PID=2848) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:47.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:12:47.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:47.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:47.247+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:12:47.270+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:47.270+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:12:47.281+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:12:47.281+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:12:47.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T10:13:18.246+0000] {processor.py:161} INFO - Started process (PID=2855) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:18.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:13:18.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:18.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:18.281+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:18.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:18.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:13:18.316+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:18.316+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:13:18.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T10:13:49.208+0000] {processor.py:161} INFO - Started process (PID=2862) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:49.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:13:49.211+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:49.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:49.226+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:13:49.249+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:49.249+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:13:49.260+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:13:49.260+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:13:49.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T10:14:20.123+0000] {processor.py:161} INFO - Started process (PID=2869) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:20.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:14:20.126+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:20.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:20.141+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:20.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:20.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:14:20.175+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:20.175+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:14:20.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T10:14:51.117+0000] {processor.py:161} INFO - Started process (PID=2876) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:51.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:14:51.120+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:51.120+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:51.146+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:14:51.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:51.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:14:51.180+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:14:51.180+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:14:51.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T10:15:22.029+0000] {processor.py:161} INFO - Started process (PID=2883) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:22.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:15:22.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:22.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:22.059+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:22.082+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:22.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:15:22.094+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:22.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:15:22.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:15:52.834+0000] {processor.py:161} INFO - Started process (PID=2890) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:52.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:15:52.844+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:52.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:52.868+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:15:52.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:52.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:15:52.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:15:52.910+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:15:52.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T10:16:23.773+0000] {processor.py:161} INFO - Started process (PID=2897) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:23.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:16:23.776+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:23.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:23.802+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:23.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:23.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:16:23.839+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:23.839+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:16:23.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T10:16:54.739+0000] {processor.py:161} INFO - Started process (PID=2904) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:54.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:16:54.742+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:54.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:54.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:16:54.776+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:54.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:16:54.790+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:16:54.790+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:16:54.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T10:17:25.795+0000] {processor.py:161} INFO - Started process (PID=2911) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:25.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:17:25.799+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:25.799+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:25.822+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:25.851+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:25.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:17:25.865+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:25.865+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:17:25.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T10:17:56.963+0000] {processor.py:161} INFO - Started process (PID=2918) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:56.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:17:56.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:56.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:56.986+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:17:57.008+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:57.007+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:17:57.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:17:57.021+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:17:57.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:18:27.093+0000] {processor.py:161} INFO - Started process (PID=2925) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:27.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:18:27.097+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:27.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:27.115+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:27.138+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:27.138+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:18:27.149+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:27.149+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:18:27.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T10:18:58.171+0000] {processor.py:161} INFO - Started process (PID=2932) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:58.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:18:58.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:58.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:58.201+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:18:58.224+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:58.224+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:18:58.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:18:58.235+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:18:58.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T10:19:29.147+0000] {processor.py:161} INFO - Started process (PID=2939) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:29.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:19:29.151+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:29.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:29.164+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:29.183+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:29.183+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:19:29.195+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:29.195+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:19:29.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:19:59.278+0000] {processor.py:161} INFO - Started process (PID=2946) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:59.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:19:59.280+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:59.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:59.293+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:19:59.314+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:59.314+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:19:59.325+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:19:59.324+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:19:59.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:20:30.275+0000] {processor.py:161} INFO - Started process (PID=2953) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:20:30.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:20:30.277+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:20:30.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:20:30.290+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:20:30.311+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:20:30.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:20:30.322+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:20:30.322+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:20:30.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T10:21:01.096+0000] {processor.py:161} INFO - Started process (PID=2960) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:01.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:21:01.099+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:01.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:01.121+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:01.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:01.143+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:21:01.155+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:01.155+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:21:01.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:21:32.222+0000] {processor.py:161} INFO - Started process (PID=2967) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:32.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:21:32.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:32.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:32.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:21:32.276+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:32.276+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:21:32.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:21:32.287+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:21:32.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T10:22:03.092+0000] {processor.py:161} INFO - Started process (PID=2974) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:03.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:22:03.096+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:03.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:03.122+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:03.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:03.146+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:22:03.159+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:03.159+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:22:03.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:22:33.330+0000] {processor.py:161} INFO - Started process (PID=2981) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:33.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:22:33.332+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:33.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:33.346+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:22:33.372+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:33.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:22:33.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:22:33.384+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:22:33.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T10:23:03.696+0000] {processor.py:161} INFO - Started process (PID=2988) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:03.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:23:03.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:03.699+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:03.712+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:03.732+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:03.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:23:03.744+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:03.744+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:23:03.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T10:23:34.783+0000] {processor.py:161} INFO - Started process (PID=2995) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:34.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:23:34.786+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:34.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:34.806+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:23:34.826+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:34.826+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:23:34.837+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:23:34.837+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:23:34.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T10:24:05.665+0000] {processor.py:161} INFO - Started process (PID=3002) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:05.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:24:05.668+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:05.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:05.692+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:05.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:05.718+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:24:05.731+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:05.731+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:24:05.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T10:24:36.610+0000] {processor.py:161} INFO - Started process (PID=3009) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:36.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:24:36.612+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:36.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:36.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:24:36.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:36.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:24:36.661+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:24:36.661+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:24:36.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T10:25:06.824+0000] {processor.py:161} INFO - Started process (PID=3016) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:06.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:25:06.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:06.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:06.858+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:06.881+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:06.881+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:25:06.893+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:06.893+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:25:06.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:25:37.826+0000] {processor.py:161} INFO - Started process (PID=3023) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:37.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:25:37.829+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:37.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:37.856+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:25:37.881+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:37.880+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:25:37.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:25:37.892+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:25:37.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:26:08.704+0000] {processor.py:161} INFO - Started process (PID=3030) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:08.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:26:08.708+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:08.708+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:08.724+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:08.745+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:08.745+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:26:08.756+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:08.756+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:26:08.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T10:26:39.725+0000] {processor.py:161} INFO - Started process (PID=3037) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:39.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:26:39.728+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:39.728+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:39.741+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:26:39.761+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:39.760+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:26:39.772+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:26:39.772+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:26:39.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:27:10.695+0000] {processor.py:161} INFO - Started process (PID=3044) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:10.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:27:10.700+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:10.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:10.788+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:10.833+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:10.833+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:27:10.844+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:10.844+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:27:10.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.168 seconds
[2025-07-16T10:27:41.764+0000] {processor.py:161} INFO - Started process (PID=3051) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:41.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:27:41.767+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:41.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:41.782+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:27:41.804+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:41.804+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:27:41.815+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:27:41.815+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:27:41.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T10:28:11.878+0000] {processor.py:161} INFO - Started process (PID=3058) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:11.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:28:11.882+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:11.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:11.903+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:11.925+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:11.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:28:11.937+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:11.937+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:28:11.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:28:42.022+0000] {processor.py:161} INFO - Started process (PID=3065) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:42.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:28:42.026+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:42.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:42.052+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:28:42.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:42.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:28:42.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:28:42.085+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:28:42.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T10:29:12.951+0000] {processor.py:161} INFO - Started process (PID=3072) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:12.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:29:12.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:12.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:12.979+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:12.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:12.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:29:13.011+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:13.011+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:29:13.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:29:43.881+0000] {processor.py:161} INFO - Started process (PID=3079) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:43.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:29:43.884+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:43.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:43.914+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:29:43.937+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:43.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:29:43.950+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:29:43.950+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:29:43.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T10:30:14.969+0000] {processor.py:161} INFO - Started process (PID=3086) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:14.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:30:14.972+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:14.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:14.992+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:15.013+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:15.013+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:30:15.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:15.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:30:15.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T10:30:46.003+0000] {processor.py:161} INFO - Started process (PID=3093) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:46.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:30:46.006+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:46.005+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:46.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:30:46.039+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:46.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:30:46.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:30:46.050+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:30:46.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:31:17.058+0000] {processor.py:161} INFO - Started process (PID=3100) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:17.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:31:17.061+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:17.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:17.081+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:17.101+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:17.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:31:17.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:17.115+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:31:17.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:31:47.224+0000] {processor.py:161} INFO - Started process (PID=3107) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:47.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:31:47.227+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:47.226+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:47.251+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:31:47.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:47.278+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:31:47.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:31:47.292+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:31:47.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:32:17.495+0000] {processor.py:161} INFO - Started process (PID=3114) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:17.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:32:17.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:17.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:17.540+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:17.562+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:17.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:32:17.573+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:17.573+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:32:17.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T10:32:48.029+0000] {processor.py:161} INFO - Started process (PID=3121) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:48.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:32:48.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:48.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:48.044+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:32:48.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:48.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:32:48.076+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:32:48.076+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:32:48.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:33:18.143+0000] {processor.py:161} INFO - Started process (PID=3128) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:18.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:33:18.145+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:18.145+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:18.160+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:18.180+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:18.180+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:33:18.191+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:18.191+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:33:18.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T10:33:48.418+0000] {processor.py:161} INFO - Started process (PID=3135) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:48.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:33:48.424+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:48.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:48.555+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:33:48.580+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:48.580+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:33:48.591+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:33:48.591+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:33:48.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.206 seconds
[2025-07-16T10:34:18.972+0000] {processor.py:161} INFO - Started process (PID=3142) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:18.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:34:18.974+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:18.974+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:18.993+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:19.015+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:19.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:34:19.028+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:19.027+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:34:19.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T10:34:49.150+0000] {processor.py:161} INFO - Started process (PID=3149) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:49.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:34:49.153+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:49.153+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:49.179+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:34:49.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:49.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:34:49.219+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:34:49.219+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:34:49.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T10:35:19.318+0000] {processor.py:161} INFO - Started process (PID=3156) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:19.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:35:19.320+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:19.320+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:19.333+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:19.353+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:19.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:35:19.366+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:19.366+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:35:19.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:35:50.127+0000] {processor.py:161} INFO - Started process (PID=3163) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:50.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:35:50.129+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:50.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:50.144+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:35:50.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:50.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:35:50.175+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:35:50.175+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:35:50.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T10:36:21.109+0000] {processor.py:161} INFO - Started process (PID=3170) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:21.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:36:21.112+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:21.112+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:21.134+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:21.157+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:21.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:36:21.170+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:21.170+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:36:21.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T10:36:51.314+0000] {processor.py:161} INFO - Started process (PID=3177) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:51.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:36:51.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:51.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:51.339+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:36:51.377+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:51.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:36:51.392+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:36:51.392+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:36:51.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T10:37:21.588+0000] {processor.py:161} INFO - Started process (PID=3184) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:21.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:37:21.591+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:21.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:21.603+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:21.633+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:21.633+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:37:21.646+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:21.646+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:37:21.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T10:37:51.765+0000] {processor.py:161} INFO - Started process (PID=3191) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:51.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:37:51.767+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:51.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:51.793+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:37:51.818+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:51.817+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:37:51.833+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:37:51.832+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:37:51.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T10:38:22.054+0000] {processor.py:161} INFO - Started process (PID=3198) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:22.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:38:22.057+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:22.057+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:22.074+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:22.095+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:22.095+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:38:22.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:22.105+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:38:22.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T10:38:53.022+0000] {processor.py:161} INFO - Started process (PID=3205) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:53.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:38:53.027+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:53.026+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:53.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:38:53.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:53.064+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:38:53.076+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:38:53.075+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:38:53.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T10:39:23.196+0000] {processor.py:161} INFO - Started process (PID=3212) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:23.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:39:23.199+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:23.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:23.221+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:23.244+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:23.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:39:23.257+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:23.257+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:39:23.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T10:39:54.101+0000] {processor.py:161} INFO - Started process (PID=3219) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:54.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:39:54.103+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:54.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:54.121+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:39:54.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:54.143+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:39:54.160+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:39:54.159+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:39:54.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T10:40:44.257+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:40:44.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:40:44.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:40:44.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:40:44.285+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:40:44.336+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:40:44.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:40:44.348+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:40:44.347+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:40:44.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-16T10:41:14.455+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:14.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:41:14.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:14.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:14.498+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:14.526+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:14.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:41:14.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:14.540+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:41:14.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-16T10:41:44.697+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:44.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:41:44.700+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:44.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:44.741+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:41:44.766+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:44.766+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:41:44.779+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:41:44.778+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:41:44.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.110 seconds
[2025-07-16T10:42:15.168+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:15.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:42:15.171+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:15.170+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:15.189+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:15.212+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:15.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:42:15.224+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:15.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:42:15.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T10:42:45.315+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:45.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:42:45.318+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:45.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:45.334+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:42:45.353+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:45.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:42:45.366+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:42:45.366+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:42:45.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T10:43:16.282+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:16.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:43:16.284+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:16.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:16.306+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:16.329+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:16.328+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:43:16.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:16.340+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:43:16.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T10:43:46.815+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:46.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:43:46.818+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:46.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:46.841+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:43:46.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:46.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:43:46.873+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:43:46.873+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:43:46.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T10:44:17.838+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:17.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:44:17.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:17.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:17.860+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:17.885+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:17.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:44:17.896+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:17.896+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:44:17.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T10:44:48.195+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:48.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:44:48.199+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:48.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:48.217+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:44:48.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:48.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:44:48.251+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:44:48.251+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:44:48.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T10:45:19.173+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:19.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:45:19.180+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:19.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:19.215+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:19.241+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:19.241+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:45:19.254+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:19.253+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:45:19.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-16T10:45:49.394+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:49.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:45:49.397+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:49.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:49.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:45:49.438+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:49.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:45:49.450+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:45:49.450+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:45:49.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T10:46:19.602+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:19.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:46:19.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:19.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:19.630+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:19.654+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:19.654+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:46:19.666+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:19.666+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:46:19.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T10:46:49.890+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:49.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:46:49.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:49.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:49.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:46:49.929+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:49.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:46:49.940+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:46:49.940+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:46:49.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T10:47:21.036+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:21.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:47:21.044+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:21.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:21.079+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:21.101+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:21.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:47:21.112+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:21.112+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:47:21.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T10:47:51.362+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:51.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:47:51.364+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:51.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:51.377+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:47:51.397+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:51.396+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:47:51.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:47:51.408+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:47:51.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T10:48:22.253+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:22.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:48:22.256+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:22.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:22.270+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:22.295+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:22.294+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:48:22.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:22.307+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:48:22.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T10:48:52.439+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:52.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:48:52.442+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:52.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:52.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:48:52.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:52.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:48:52.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:48:52.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:48:52.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T10:49:22.673+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:22.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:49:22.676+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:22.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:22.701+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:22.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:22.726+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:49:22.738+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:22.738+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:49:22.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T10:49:52.894+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:52.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:49:52.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:52.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:52.931+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:49:52.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:52.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:49:52.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:49:52.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:49:52.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T10:50:23.398+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:23.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:50:23.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:23.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:23.430+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:23.454+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:23.454+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:50:23.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:23.466+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:50:23.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:50:53.602+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:53.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:50:53.605+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:53.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:53.631+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:50:53.652+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:53.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:50:53.664+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:50:53.664+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:50:53.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T10:51:24.136+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:24.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:51:24.138+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:24.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:24.154+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:24.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:24.176+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:51:24.189+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:24.189+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:51:24.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T10:51:54.256+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:54.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:51:54.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:54.258+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:54.272+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:51:54.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:54.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:51:54.313+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:51:54.312+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:51:54.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T10:52:24.469+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:24.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:52:24.473+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:24.472+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:24.499+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:24.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:24.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:52:24.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:24.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:52:24.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T10:52:54.646+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:54.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:52:54.649+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:54.649+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:54.676+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:52:54.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:54.698+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:52:54.711+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:52:54.711+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:52:54.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T10:53:24.793+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:24.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:53:24.796+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:24.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:24.821+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:24.844+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:24.843+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:53:24.855+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:24.854+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:53:24.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T10:53:54.997+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:54.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:53:55.003+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:55.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:55.032+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:53:55.057+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:55.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:53:55.069+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:53:55.069+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:53:55.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T10:54:25.165+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:25.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:54:25.168+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:25.168+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:25.196+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:25.219+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:25.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:54:25.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:25.231+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:54:25.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T10:54:55.326+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:55.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:54:55.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:55.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:55.355+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:54:55.383+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:55.383+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:54:55.395+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:54:55.395+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:54:55.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T10:55:26.254+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:26.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:55:26.257+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:26.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:26.283+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:26.310+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:26.309+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:55:26.322+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:26.322+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:55:26.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T10:55:56.430+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:56.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:55:56.433+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:56.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:56.458+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:55:56.480+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:56.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:55:56.493+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:55:56.492+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:55:56.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T10:56:27.425+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:27.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:56:27.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:27.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:27.450+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:27.473+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:27.473+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:56:27.485+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:27.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:56:27.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T10:56:58.350+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:58.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:56:58.354+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:58.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:58.382+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:56:58.406+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:58.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:56:58.417+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:56:58.417+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:56:58.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T10:57:29.258+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:57:29.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:57:29.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:57:29.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:57:29.291+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:57:29.319+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:57:29.318+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:57:29.333+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:57:29.333+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:57:29.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.107 seconds
[2025-07-16T10:58:00.021+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:00.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:58:00.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:00.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:00.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:00.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:00.075+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:58:00.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:00.086+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:58:00.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T10:58:30.982+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:30.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:58:30.986+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:30.985+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:31.011+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:58:31.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:31.035+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:58:31.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:58:31.048+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:58:31.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T10:59:01.806+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:01.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:59:01.809+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:01.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:01.831+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:01.855+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:01.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:59:01.867+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:01.867+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:59:01.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T10:59:31.973+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:31.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T10:59:31.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:31.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:31.999+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T10:59:32.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:32.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T10:59:32.035+0000] {logging_mixin.py:188} INFO - [2025-07-16T10:59:32.035+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T10:59:32.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:01:59.471+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:01:59.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:01:59.475+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:01:59.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:01:59.507+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:01:59.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:01:59.559+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:01:59.574+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:01:59.574+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:01:59.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.133 seconds
[2025-07-16T11:02:30.481+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:02:30.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:02:30.484+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:02:30.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:02:30.529+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:02:30.560+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:02:30.560+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:02:30.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:02:30.576+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:02:30.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.116 seconds
[2025-07-16T11:03:01.409+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:01.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:03:01.413+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:01.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:01.435+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:01.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:01.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:03:01.476+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:01.476+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:03:01.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T11:03:31.527+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:31.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:03:31.530+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:31.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:31.548+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:03:31.572+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:31.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:03:31.586+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:03:31.586+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:03:31.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T11:04:01.659+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:01.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:04:01.661+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:01.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:01.678+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:01.705+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:01.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:04:01.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:01.718+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:04:01.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T11:04:32.505+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:32.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:04:32.508+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:32.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:32.531+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:04:32.560+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:32.560+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:04:32.574+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:04:32.574+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:04:32.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T11:05:03.459+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:03.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:05:03.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:03.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:03.484+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:03.508+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:03.507+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:05:03.520+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:03.520+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:05:03.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:05:34.269+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:34.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:05:34.271+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:34.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:34.289+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:05:34.314+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:34.313+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:05:34.326+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:05:34.326+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:05:34.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T11:06:05.135+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:05.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:06:05.138+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:05.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:05.159+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:05.183+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:05.183+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:06:05.197+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:05.197+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:06:05.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T11:06:35.974+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:35.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:06:35.977+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:35.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:35.998+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:06:36.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:36.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:06:36.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:06:36.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:06:36.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:07:06.837+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:06.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:07:06.841+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:06.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:06.866+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:06.896+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:06.895+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:07:06.909+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:06.909+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:07:06.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T11:07:37.771+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:37.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:07:37.775+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:37.775+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:37.800+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:07:37.831+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:37.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:07:37.845+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:07:37.844+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:07:37.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T11:08:08.659+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:08.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:08:08.662+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:08.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:08.679+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:08.706+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:08.706+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:08:08.722+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:08.722+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:08:08.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T11:08:39.584+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:39.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:08:39.587+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:39.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:39.613+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:08:39.639+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:39.639+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:08:39.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:08:39.651+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:08:39.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T11:09:10.471+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:10.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:09:10.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:10.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:10.499+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:10.528+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:10.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:09:10.544+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:10.543+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:09:10.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-16T11:09:41.302+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:41.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:09:41.305+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:41.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:41.332+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:09:41.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:41.358+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:09:41.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:09:41.372+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:09:41.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:10:12.212+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:12.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:10:12.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:12.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:12.237+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:12.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:12.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:10:12.274+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:12.274+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:10:12.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:10:43.101+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:43.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:10:43.104+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:43.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:43.130+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:10:43.156+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:43.156+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:10:43.168+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:10:43.168+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:10:43.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:11:13.990+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:13.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:11:13.994+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:13.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:14.015+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:14.040+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:14.040+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:11:14.054+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:14.054+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:11:14.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:11:44.878+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:44.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:11:44.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:44.880+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:44.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:11:44.931+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:44.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:11:44.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:11:44.946+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:11:44.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T11:12:15.786+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:15.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:12:15.789+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:15.789+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:15.817+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:15.847+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:15.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:12:15.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:15.862+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:12:15.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T11:12:46.638+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:46.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:12:46.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:46.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:46.661+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:12:46.687+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:46.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:12:46.700+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:12:46.700+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:12:46.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:13:17.367+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:17.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:13:17.370+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:17.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:17.390+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:17.420+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:17.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:13:17.436+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:17.436+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:13:17.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:13:48.271+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:48.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:13:48.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:48.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:48.300+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:13:48.323+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:48.323+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:13:48.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:13:48.335+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:13:48.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:14:19.126+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:19.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:14:19.129+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:19.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:19.150+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:19.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:19.177+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:14:19.190+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:19.190+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:14:19.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T11:14:50.051+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:50.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:14:50.054+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:50.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:50.080+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:14:50.102+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:50.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:14:50.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:14:50.115+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:14:50.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T11:15:20.877+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:20.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:15:20.880+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:20.880+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:20.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:20.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:20.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:15:20.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:20.945+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:15:20.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:15:51.738+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:51.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:15:51.740+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:51.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:51.761+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:15:51.785+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:51.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:15:51.797+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:15:51.797+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:15:51.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:16:22.671+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:22.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:16:22.674+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:22.674+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:22.691+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:22.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:22.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:16:22.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:22.725+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:16:22.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T11:16:53.486+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:53.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:16:53.489+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:53.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:53.504+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:16:53.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:53.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:16:53.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:16:53.539+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:16:53.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T11:17:24.458+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:24.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:17:24.460+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:24.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:24.481+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:24.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:24.504+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:17:24.517+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:24.517+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:17:24.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:17:55.227+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:55.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:17:55.230+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:55.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:55.255+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:17:55.281+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:55.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:17:55.295+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:17:55.295+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:17:55.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T11:18:26.203+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:18:26.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:18:26.206+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:18:26.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:18:26.225+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:18:26.253+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:18:26.253+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:18:26.266+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:18:26.266+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:18:26.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T11:23:30.286+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:23:30.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:23:30.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:23:30.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:23:30.340+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:23:30.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:23:30.411+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:23:30.443+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:23:30.442+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:23:30.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.199 seconds
[2025-07-16T11:24:00.536+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:00.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:24:00.539+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:00.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:00.564+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:00.602+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:00.601+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:24:00.618+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:00.618+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:24:00.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.110 seconds
[2025-07-16T11:24:31.489+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:31.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:24:31.492+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:31.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:31.522+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:24:31.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:31.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:24:31.561+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:24:31.561+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:24:31.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:25:02.401+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:02.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:25:02.403+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:02.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:02.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:02.475+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:02.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:25:02.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:02.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:25:02.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-16T11:25:33.160+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:33.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:25:33.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:33.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:33.188+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:25:33.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:33.217+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:25:33.234+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:25:33.234+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:25:33.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.109 seconds
[2025-07-16T11:26:03.931+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:03.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:26:03.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:03.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:03.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:03.984+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:03.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:26:03.998+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:03.998+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:26:04.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:26:34.769+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:34.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:26:34.773+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:34.772+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:34.798+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:26:34.823+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:34.823+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:26:34.836+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:26:34.836+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:26:34.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T11:27:05.571+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:05.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:27:05.574+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:05.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:05.598+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:05.628+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:05.628+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:27:05.642+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:05.641+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:27:05.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T11:27:36.540+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:36.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:27:36.543+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:36.543+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:36.571+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:27:36.597+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:36.597+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:27:36.614+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:27:36.614+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:27:36.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T11:28:07.303+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:07.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:28:07.306+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:07.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:07.332+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:07.357+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:07.357+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:28:07.369+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:07.369+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:28:07.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T11:28:38.139+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:38.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:28:38.142+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:38.142+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:38.162+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:28:38.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:38.185+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:28:38.199+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:28:38.199+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:28:38.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T11:29:08.887+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:08.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:29:08.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:08.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:08.917+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:08.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:08.942+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:29:08.955+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:08.955+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:29:08.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T11:29:39.702+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:39.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:29:39.705+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:39.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:39.731+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:29:39.758+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:39.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:29:39.774+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:29:39.773+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:29:39.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.104 seconds
[2025-07-16T11:30:10.455+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:10.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:30:10.459+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:10.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:10.483+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:10.512+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:10.512+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:30:10.526+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:10.526+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:30:10.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:30:41.327+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:41.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:30:41.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:41.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:41.354+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:30:41.378+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:41.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:30:41.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:30:41.390+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:30:41.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T11:31:12.188+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:12.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:31:12.191+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:12.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:12.217+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:12.243+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:12.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:31:12.256+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:12.256+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:31:12.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:31:42.977+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:42.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:31:42.980+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:42.980+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:43.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:31:43.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:43.036+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:31:43.056+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:31:43.056+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:31:43.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-16T11:32:13.825+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:13.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:32:13.828+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:13.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:13.847+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:13.871+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:13.871+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:32:13.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:13.883+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:32:13.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T11:32:44.572+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:44.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:32:44.574+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:44.574+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:44.595+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:32:44.620+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:44.620+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:32:44.633+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:32:44.633+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:32:44.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:33:15.246+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:15.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:33:15.249+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:15.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:15.273+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:15.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:15.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:33:15.312+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:15.312+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:33:15.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T11:33:46.047+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:46.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:33:46.051+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:46.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:46.073+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:33:46.107+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:46.106+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:33:46.123+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:33:46.123+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:33:46.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.104 seconds
[2025-07-16T11:34:16.924+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:16.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:34:16.927+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:16.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:16.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:16.983+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:16.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:34:16.996+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:16.996+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:34:17.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T11:34:47.689+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:47.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:34:47.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:47.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:47.714+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:34:47.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:47.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:34:47.753+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:34:47.753+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:34:47.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:35:18.553+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:18.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:35:18.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:18.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:18.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:18.610+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:18.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:35:18.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:18.623+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:35:18.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:35:49.351+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:49.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:35:49.354+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:49.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:49.379+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:35:49.404+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:49.404+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:35:49.416+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:35:49.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:35:49.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:36:20.258+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:20.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:36:20.263+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:20.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:20.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:20.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:20.330+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:36:20.343+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:20.343+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:36:20.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-16T11:36:50.559+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:50.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:36:50.562+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:50.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:50.582+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:36:50.606+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:50.606+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:36:50.619+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:36:50.619+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:36:50.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:37:21.256+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:21.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:37:21.259+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:21.258+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:21.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:21.303+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:21.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:37:21.316+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:21.316+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:37:21.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T11:37:51.993+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:51.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:37:52.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:52.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:52.033+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:37:52.082+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:52.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:37:52.103+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:37:52.102+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:37:52.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.154 seconds
[2025-07-16T11:38:22.888+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:22.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:38:22.891+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:22.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:22.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:22.941+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:22.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:38:22.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:22.953+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:38:22.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T11:38:53.772+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:53.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:38:53.775+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:53.775+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:53.797+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:38:53.821+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:53.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:38:53.835+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:38:53.835+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:38:53.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:39:24.547+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:24.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:39:24.549+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:24.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:24.574+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:24.600+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:24.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:39:24.615+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:24.614+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:39:24.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T11:39:55.369+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:55.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:39:55.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:55.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:55.396+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:39:55.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:55.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:39:55.437+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:39:55.436+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:39:55.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T11:40:26.202+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:26.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:40:26.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:26.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:26.236+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:26.271+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:26.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:40:26.286+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:26.286+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:40:26.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-16T11:40:57.019+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:57.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:40:57.023+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:57.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:57.047+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:40:57.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:57.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:40:57.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:40:57.086+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:40:57.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:41:27.737+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:27.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:41:27.740+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:27.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:27.758+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:27.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:27.781+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:41:27.795+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:27.795+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:41:27.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:41:58.399+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:58.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:41:58.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:58.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:58.425+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:41:58.448+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:58.448+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:41:58.462+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:41:58.462+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:41:58.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T11:42:29.215+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:42:29.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:42:29.218+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:42:29.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:42:29.241+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:42:29.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:42:29.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:42:29.277+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:42:29.277+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:42:29.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:43:00.005+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:00.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:43:00.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:00.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:00.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:00.071+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:00.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:43:00.085+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:00.084+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:43:00.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-16T11:43:30.724+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:30.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:43:30.728+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:30.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:30.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:43:30.784+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:30.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:43:30.796+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:43:30.796+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:43:30.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:44:01.739+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:01.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:44:01.742+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:01.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:01.764+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:01.787+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:01.786+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:44:01.800+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:01.800+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:44:01.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:44:32.378+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:32.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:44:32.380+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:32.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:32.400+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:44:32.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:32.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:44:32.438+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:44:32.437+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:44:32.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:45:03.161+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:03.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:45:03.164+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:03.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:03.186+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:03.210+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:03.210+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:45:03.223+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:03.223+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:45:03.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T11:45:33.930+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:33.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:45:33.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:33.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:33.957+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:45:33.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:33.981+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:45:33.994+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:45:33.993+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:45:34.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T11:46:04.660+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:04.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:46:04.664+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:04.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:04.686+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:04.713+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:04.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:46:04.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:04.726+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:46:04.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:46:35.456+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:35.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:46:35.458+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:35.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:35.476+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:46:35.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:35.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:46:35.511+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:46:35.510+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:46:35.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:47:06.154+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:06.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:47:06.157+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:06.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:06.175+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:06.202+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:06.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:47:06.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:06.216+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:47:06.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T11:47:36.907+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:36.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:47:36.912+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:36.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:36.929+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:47:36.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:36.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:47:36.968+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:47:36.968+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:47:36.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T11:48:07.707+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:07.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:48:07.711+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:07.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:07.733+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:07.760+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:07.759+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:48:07.772+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:07.772+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:48:07.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T11:48:38.535+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:38.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:48:38.538+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:38.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:38.562+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:48:38.586+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:38.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:48:38.600+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:48:38.600+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:48:38.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T11:49:09.227+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:09.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:49:09.230+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:09.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:09.258+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:09.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:09.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:49:09.297+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:09.296+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:49:09.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T11:49:39.963+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:39.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:49:39.966+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:39.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:39.983+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:49:40.007+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:40.007+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:49:40.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:49:40.021+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:49:40.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:50:10.699+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:10.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:50:10.703+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:10.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:10.729+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:10.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:10.752+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:50:10.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:10.764+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:50:10.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T11:50:41.582+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:41.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:50:41.585+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:41.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:41.604+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:50:41.626+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:41.626+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:50:41.638+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:50:41.638+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:50:41.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:51:12.527+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:12.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:51:12.530+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:12.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:12.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:12.565+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:12.565+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:51:12.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:12.582+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:51:12.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T11:51:43.526+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:43.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:51:43.530+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:43.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:43.551+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:51:43.573+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:43.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:51:43.586+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:51:43.586+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:51:43.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T11:52:14.429+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:14.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:52:14.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:14.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:14.454+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:14.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:14.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:52:14.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:14.489+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:52:14.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T11:52:44.686+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:44.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:52:44.689+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:44.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:44.717+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:52:44.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:44.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:52:44.751+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:52:44.751+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:52:44.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T11:53:15.555+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:15.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:53:15.558+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:15.558+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:15.572+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:15.595+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:15.595+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:53:15.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:15.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:53:15.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T11:53:45.798+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:45.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:53:45.802+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:45.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:45.831+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:53:45.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:45.858+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:53:45.875+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:53:45.874+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:53:45.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T11:54:16.095+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:16.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:54:16.098+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:16.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:16.112+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:16.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:16.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:54:16.149+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:16.148+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:54:16.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T11:54:46.923+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:46.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:54:46.925+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:46.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:46.943+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:54:46.966+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:46.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:54:46.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:54:46.979+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:54:46.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T11:55:17.734+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:17.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:55:17.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:17.739+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:17.773+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:17.801+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:17.801+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:55:17.817+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:17.817+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:55:17.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.110 seconds
[2025-07-16T11:55:48.397+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:48.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:55:48.400+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:48.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:48.427+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:55:48.449+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:48.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:55:48.461+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:55:48.461+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:55:48.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T11:56:18.624+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:18.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:56:18.626+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:18.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:18.646+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:18.667+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:18.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:56:18.678+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:18.678+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:56:18.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T11:56:48.907+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:48.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:56:48.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:48.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:48.926+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:56:48.950+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:48.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:56:48.967+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:56:48.966+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:56:48.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T11:57:19.808+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:19.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:57:19.811+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:19.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:19.837+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:19.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:19.864+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:57:19.877+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:19.877+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:57:19.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T11:57:50.715+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:50.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:57:50.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:50.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:50.733+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:57:50.755+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:50.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:57:50.766+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:57:50.766+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:57:50.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T11:58:20.888+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:20.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:58:20.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:20.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:20.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:20.929+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:20.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:58:20.941+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:20.941+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:58:20.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T11:58:51.104+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:51.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:58:51.107+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:51.107+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:51.122+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:58:51.142+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:51.142+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:58:51.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:58:51.162+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:58:51.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T11:59:21.381+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:21.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:59:21.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:21.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:21.400+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:21.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:21.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:59:21.437+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:21.437+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:59:21.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T11:59:51.575+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:51.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T11:59:51.581+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:51.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:51.672+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T11:59:51.696+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:51.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T11:59:51.708+0000] {logging_mixin.py:188} INFO - [2025-07-16T11:59:51.708+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T11:59:51.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.158 seconds
[2025-07-16T12:00:21.950+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:21.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:00:21.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:21.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:21.987+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:22.011+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:22.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:00:22.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:22.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:00:22.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T12:00:52.553+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:52.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:00:52.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:52.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:52.569+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:00:52.589+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:52.589+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:00:52.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:00:52.599+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:00:52.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T12:01:22.791+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:22.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:01:22.794+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:22.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:22.809+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:22.832+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:22.832+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:01:22.847+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:22.847+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:01:22.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:01:53.336+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:53.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:01:53.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:53.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:53.351+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:01:53.372+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:53.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:01:53.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:01:53.384+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:01:53.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T12:02:23.480+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:23.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:02:23.485+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:23.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:23.503+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:23.524+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:23.524+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:02:23.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:23.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:02:23.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:02:53.789+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:53.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:02:53.791+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:53.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:53.807+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:02:53.829+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:53.829+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:02:53.841+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:02:53.841+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:02:53.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T12:03:24.086+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:24.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:03:24.088+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:24.088+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:24.106+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:24.126+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:24.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:03:24.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:24.137+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:03:24.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:03:54.234+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:54.235+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:03:54.237+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:54.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:54.265+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:03:54.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:54.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:03:54.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:03:54.299+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:03:54.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T12:04:24.368+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:24.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:04:24.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:24.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:24.385+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:24.406+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:24.406+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:04:24.418+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:24.418+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:04:24.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:04:54.739+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:54.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:04:54.741+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:54.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:54.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:04:54.777+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:54.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:04:54.788+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:04:54.788+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:04:54.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:05:24.866+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:24.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:05:24.868+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:24.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:24.884+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:24.908+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:24.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:05:24.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:24.919+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:05:24.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:05:55.063+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:55.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:05:55.066+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:55.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:55.086+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:05:55.107+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:55.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:05:55.118+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:05:55.118+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:05:55.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T12:06:26.174+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:26.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:06:26.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:26.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:26.193+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:26.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:26.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:06:26.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:26.225+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:06:26.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T12:06:56.510+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:56.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:06:56.516+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:56.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:56.556+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:06:56.584+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:56.583+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:06:56.596+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:06:56.596+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:06:56.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-16T12:07:26.735+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:26.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:07:26.737+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:26.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:26.763+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:26.784+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:26.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:07:26.795+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:26.795+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:07:26.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T12:07:56.925+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:56.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:07:56.929+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:56.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:56.959+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:07:56.980+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:56.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:07:56.991+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:07:56.991+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:07:57.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T12:08:27.173+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:27.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:08:27.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:27.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:27.204+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:27.227+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:27.227+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:08:27.239+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:27.239+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:08:27.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T12:08:57.470+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:57.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:08:57.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:57.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:57.501+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:08:57.523+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:57.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:08:57.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:08:57.536+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:08:57.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:09:28.478+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:28.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:09:28.481+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:28.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:28.498+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:28.523+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:28.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:09:28.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:28.535+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:09:28.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:09:58.690+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:58.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:09:58.694+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:58.693+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:58.720+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:09:58.743+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:58.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:09:58.755+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:09:58.755+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:09:58.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T12:10:29.118+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:29.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:10:29.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:29.120+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:29.137+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:29.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:29.158+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:10:29.170+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:29.170+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:10:29.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:10:59.357+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:59.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:10:59.359+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:59.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:59.375+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:10:59.396+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:59.396+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:10:59.408+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:10:59.407+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:10:59.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:11:30.418+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:11:30.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:11:30.426+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:11:30.425+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:11:30.463+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:11:30.486+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:11:30.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:11:30.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:11:30.498+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:11:30.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.116 seconds
[2025-07-16T12:12:00.640+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:00.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:12:00.643+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:00.643+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:00.668+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:00.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:00.691+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:12:00.703+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:00.703+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:12:00.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:12:31.108+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:31.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:12:31.110+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:31.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:31.122+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:12:31.146+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:31.145+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:12:31.159+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:12:31.159+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:12:31.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:13:01.237+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:01.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:13:01.240+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:01.240+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:01.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:01.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:01.274+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:13:01.286+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:01.286+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:13:01.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T12:13:31.389+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:31.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:13:31.391+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:31.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:31.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:13:31.441+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:31.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:13:31.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:13:31.453+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:13:31.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T12:14:01.707+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:01.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:14:01.712+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:01.712+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:01.727+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:01.749+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:01.749+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:14:01.762+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:01.762+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:14:01.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T12:14:31.855+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:31.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:14:31.858+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:31.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:31.872+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:14:31.894+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:31.893+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:14:31.905+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:14:31.905+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:14:31.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T12:15:02.072+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:02.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:15:02.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:02.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:02.093+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:02.116+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:02.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:15:02.128+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:02.128+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:15:02.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T12:15:32.202+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:32.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:15:32.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:32.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:32.222+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:15:32.243+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:32.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:15:32.255+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:15:32.255+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:15:32.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:16:02.908+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:02.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:16:02.911+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:02.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:02.931+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:02.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:02.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:16:02.965+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:02.965+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:16:02.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:16:33.128+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:33.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:16:33.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:33.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:33.157+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:16:33.182+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:33.182+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:16:33.194+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:16:33.194+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:16:33.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T12:17:03.532+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:03.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:17:03.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:03.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:03.579+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:03.609+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:03.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:17:03.623+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:03.623+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:17:03.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.129 seconds
[2025-07-16T12:17:33.907+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:33.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:17:33.909+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:33.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:33.924+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:17:33.948+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:33.948+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:17:33.961+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:17:33.961+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:17:33.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:18:04.061+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:04.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:18:04.063+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:04.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:04.076+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:04.101+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:04.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:18:04.114+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:04.114+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:18:04.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T12:18:34.231+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:34.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:18:34.236+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:34.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:34.255+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:18:34.279+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:34.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:18:34.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:18:34.292+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:18:34.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T12:19:04.586+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:04.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:19:04.589+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:04.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:04.607+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:04.630+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:04.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:19:04.643+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:04.643+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:19:04.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T12:19:34.731+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:34.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:19:34.735+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:34.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:34.757+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:19:34.780+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:34.780+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:19:34.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:19:34.792+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:19:34.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:20:04.995+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:04.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:20:04.997+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:04.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:05.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:05.039+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:05.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:20:05.052+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:05.052+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:20:05.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T12:20:35.555+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:35.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:20:35.558+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:35.558+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:35.581+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:20:35.603+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:35.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:20:35.616+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:20:35.616+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:20:35.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:21:05.701+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:05.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:21:05.703+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:05.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:05.717+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:05.743+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:05.742+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:21:05.756+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:05.755+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:21:05.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:21:35.903+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:35.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:21:35.905+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:35.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:35.922+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:21:35.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:35.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:21:35.956+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:21:35.956+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:21:35.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T12:22:06.030+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:06.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:22:06.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:06.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:06.045+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:06.066+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:06.066+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:22:06.078+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:06.078+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:22:06.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:22:36.227+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:36.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:22:36.234+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:36.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:36.270+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:22:36.295+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:36.295+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:22:36.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:22:36.307+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:22:36.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.110 seconds
[2025-07-16T12:23:06.409+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:06.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:23:06.411+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:06.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:06.433+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:06.455+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:06.455+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:23:06.466+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:06.466+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:23:06.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T12:23:36.750+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:36.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:23:36.753+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:36.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:36.787+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:23:36.816+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:36.816+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:23:36.831+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:23:36.831+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:23:36.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-16T12:24:07.759+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:07.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:24:07.762+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:07.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:07.779+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:07.810+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:07.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:24:07.823+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:07.823+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:24:07.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T12:24:38.056+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:38.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:24:38.066+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:38.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:38.108+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:24:38.132+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:38.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:24:38.144+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:24:38.144+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:24:38.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.119 seconds
[2025-07-16T12:25:09.303+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:09.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:25:09.306+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:09.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:09.341+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:09.366+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:09.366+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:25:09.379+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:09.379+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:25:09.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T12:25:40.252+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:40.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:25:40.255+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:40.254+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:40.268+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:25:40.288+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:40.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:25:40.301+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:25:40.301+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:25:40.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T12:26:11.283+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:11.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:26:11.286+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:11.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:11.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:11.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:11.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:26:11.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:11.339+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:26:11.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T12:26:41.551+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:41.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:26:41.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:41.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:41.570+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:26:41.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:41.594+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:26:41.606+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:26:41.606+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:26:41.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:27:11.943+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:11.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:27:11.945+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:11.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:11.972+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:11.996+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:11.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:27:12.008+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:12.008+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:27:12.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T12:27:42.111+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:42.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:27:42.118+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:42.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:42.237+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:27:42.264+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:42.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:27:42.280+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:27:42.280+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:27:42.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.196 seconds
[2025-07-16T12:28:12.842+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:12.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:28:12.846+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:12.845+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:12.870+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:12.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:12.897+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:28:12.910+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:12.910+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:28:12.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T12:28:43.076+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:43.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:28:43.079+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:43.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:43.098+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:28:43.120+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:43.120+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:28:43.132+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:28:43.131+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:28:43.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:29:13.342+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:13.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:29:13.345+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:13.345+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:13.361+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:13.383+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:13.383+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:29:13.395+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:13.395+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:29:13.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:29:44.385+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:44.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:29:44.389+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:44.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:44.403+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:29:44.425+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:44.425+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:29:44.437+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:29:44.437+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:29:44.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:30:14.531+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:14.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:30:14.533+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:14.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:14.549+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:14.571+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:14.571+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:30:14.582+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:14.582+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:30:14.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:30:44.686+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:44.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:30:44.689+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:44.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:44.709+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:30:44.730+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:44.729+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:30:44.743+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:30:44.743+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:30:44.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:31:14.978+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:14.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:31:14.981+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:14.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:14.994+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:15.017+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:15.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:31:15.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:15.029+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:31:15.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T12:31:46.048+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:46.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:31:46.051+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:46.050+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:46.074+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:31:46.096+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:46.096+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:31:46.109+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:31:46.109+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:31:46.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:32:16.259+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:16.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:32:16.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:16.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:16.287+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:16.311+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:16.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:32:16.323+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:16.322+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:32:16.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T12:32:46.497+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:46.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:32:46.499+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:46.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:46.513+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:32:46.535+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:46.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:32:46.549+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:32:46.548+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:32:46.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:33:16.800+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:16.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:33:16.803+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:16.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:16.895+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:16.918+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:16.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:33:16.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:16.930+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:33:16.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.154 seconds
[2025-07-16T12:33:47.524+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:47.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:33:47.526+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:47.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:47.538+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:33:47.558+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:47.558+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:33:47.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:33:47.569+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:33:47.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T12:34:18.781+0000] {processor.py:161} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:18.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:34:18.784+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:18.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:18.815+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:18.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:18.842+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:34:18.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:18.859+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:34:18.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-16T12:34:49.834+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:49.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:34:49.837+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:49.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:49.862+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:34:49.885+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:49.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:34:49.897+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:34:49.897+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:34:49.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T12:35:21.000+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:21.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:35:21.007+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:21.006+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:21.053+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:21.107+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:21.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:35:21.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:21.122+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:35:21.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.149 seconds
[2025-07-16T12:35:51.285+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:51.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:35:51.288+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:51.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:51.310+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:35:51.332+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:51.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:35:51.344+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:35:51.344+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:35:51.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:36:21.443+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:21.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:36:21.447+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:21.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:21.485+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:21.510+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:21.510+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:36:21.522+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:21.522+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:36:21.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.109 seconds
[2025-07-16T12:36:51.811+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:51.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:36:51.813+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:51.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:51.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:36:51.849+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:51.849+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:36:51.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:36:51.861+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:36:51.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T12:37:22.018+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:22.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:37:22.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:22.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:22.048+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:22.073+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:22.073+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:37:22.087+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:22.087+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:37:22.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T12:37:52.170+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:52.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:37:52.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:52.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:52.204+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:37:52.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:52.231+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:37:52.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:37:52.247+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:37:52.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T12:38:22.342+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:22.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:38:22.346+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:22.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:22.364+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:22.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:22.390+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:38:22.402+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:22.402+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:38:22.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T12:38:52.654+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:52.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:38:52.657+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:52.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:52.680+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:38:52.703+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:52.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:38:52.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:38:52.714+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:38:52.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T12:39:23.715+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:23.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:39:23.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:23.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:23.742+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:23.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:23.764+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:39:23.777+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:23.777+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:39:23.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T12:39:53.883+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:53.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:39:53.886+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:53.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:53.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:39:53.927+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:53.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:39:53.939+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:39:53.939+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:39:53.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:40:24.937+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:24.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:40:24.940+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:24.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:24.955+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:24.979+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:24.979+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:40:24.992+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:24.992+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:40:25.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:40:55.173+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:55.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:40:55.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:55.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:55.190+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:40:55.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:55.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:40:55.230+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:40:55.230+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:40:55.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T12:41:26.095+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:26.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:41:26.097+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:26.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:26.128+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:26.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:26.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:41:26.170+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:26.170+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:41:26.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T12:41:56.661+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:56.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:41:56.668+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:56.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:56.754+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:41:56.778+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:56.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:41:56.791+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:41:56.791+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:41:56.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.160 seconds
[2025-07-16T12:42:27.829+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:27.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:42:27.832+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:27.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:27.849+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:27.871+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:27.871+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:42:27.883+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:27.883+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:42:27.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T12:42:59.006+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:59.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:42:59.009+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:59.009+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:59.037+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:42:59.059+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:59.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:42:59.073+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:42:59.072+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:42:59.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T12:43:29.306+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:29.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:43:29.311+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:29.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:29.348+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:29.374+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:29.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:43:29.386+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:29.386+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:43:29.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T12:43:59.466+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:59.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:43:59.469+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:59.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:59.494+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:43:59.515+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:59.515+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:43:59.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:43:59.526+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:43:59.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T12:44:29.652+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:44:29.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:44:29.655+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:44:29.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:44:29.676+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:44:29.698+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:44:29.697+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:44:29.709+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:44:29.709+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:44:29.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:45:00.005+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:00.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:45:00.008+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:00.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:00.023+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:00.047+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:00.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:45:00.059+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:00.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:45:00.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T12:45:31.047+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:31.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:45:31.052+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:31.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:31.094+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:45:31.117+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:31.117+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:45:31.130+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:45:31.129+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:45:31.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-16T12:46:01.317+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:01.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:46:01.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:01.321+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:01.348+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:01.376+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:01.375+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:46:01.388+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:01.388+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:46:01.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T12:46:31.528+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:31.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:46:31.530+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:31.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:31.556+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:46:31.579+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:31.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:46:31.590+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:46:31.590+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:46:31.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T12:47:01.870+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:01.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:47:01.873+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:01.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:01.898+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:01.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:01.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:47:01.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:01.930+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:47:01.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T12:47:32.040+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:32.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:47:32.043+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:32.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:32.064+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:47:32.087+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:32.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:47:32.098+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:47:32.098+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:47:32.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:48:03.039+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:03.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:48:03.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:03.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:03.062+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:03.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:03.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:48:03.099+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:03.099+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:48:03.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:48:33.273+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:33.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:48:33.276+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:33.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:33.294+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:48:33.315+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:33.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:48:33.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:48:33.327+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:48:33.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T12:49:04.245+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:04.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:49:04.249+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:04.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:04.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:04.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:04.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:49:04.310+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:04.310+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:49:04.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T12:49:35.429+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:35.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:49:35.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:35.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:35.454+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:49:35.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:35.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:49:35.490+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:49:35.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:49:35.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T12:50:05.604+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:05.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:50:05.606+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:05.606+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:05.620+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:05.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:05.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:50:05.653+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:05.653+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:50:05.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T12:50:35.982+0000] {processor.py:161} INFO - Started process (PID=1238) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:35.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:50:35.985+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:35.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:36.005+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:50:36.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:36.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:50:36.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:50:36.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:50:36.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T12:51:06.950+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:06.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:51:06.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:06.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:06.974+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:07.000+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:06.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:51:07.012+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:07.011+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:51:07.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T12:51:37.941+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:37.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:51:37.943+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:37.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:37.956+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:51:37.976+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:37.976+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:51:37.989+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:51:37.989+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:51:38.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T12:52:08.171+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:08.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:52:08.174+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:08.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:08.193+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:08.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:08.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:52:08.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:08.225+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:52:08.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T12:52:39.071+0000] {processor.py:161} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:39.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:52:39.074+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:39.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:39.096+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:52:39.124+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:39.124+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:52:39.138+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:52:39.137+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:52:39.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T12:53:10.181+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:10.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:53:10.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:10.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:10.208+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:10.233+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:10.233+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:53:10.246+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:10.246+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:53:10.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T12:53:40.303+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:40.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:53:40.306+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:40.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:40.328+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:53:40.349+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:40.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:53:40.361+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:53:40.361+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:53:40.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:54:10.667+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:10.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:54:10.670+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:10.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:10.689+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:10.710+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:10.709+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:54:10.722+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:10.721+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:54:10.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T12:54:41.641+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:41.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:54:41.644+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:41.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:41.669+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:54:41.695+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:41.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:54:41.709+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:54:41.709+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:54:41.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T12:55:12.679+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:12.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:55:12.682+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:12.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:12.706+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:12.728+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:12.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:55:12.740+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:12.739+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:55:12.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T12:55:43.665+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:43.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:55:43.668+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:43.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:43.693+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:55:43.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:43.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:55:43.729+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:55:43.728+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:55:43.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T12:56:13.931+0000] {processor.py:161} INFO - Started process (PID=1316) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:13.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:56:13.933+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:13.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:13.949+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:13.970+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:13.970+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:56:13.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:13.982+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:56:13.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T12:56:44.724+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:44.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:56:44.727+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:44.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:44.742+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:56:44.766+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:44.766+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:56:44.779+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:56:44.778+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:56:44.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T12:57:15.684+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:15.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:57:15.688+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:15.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:15.706+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:15.731+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:15.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:57:15.743+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:15.743+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:57:15.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T12:57:46.653+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:46.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:57:46.656+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:46.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:46.671+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:57:46.692+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:46.692+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:57:46.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:57:46.704+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:57:46.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T12:58:17.734+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:17.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:58:17.738+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:17.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:17.770+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:17.795+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:17.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:58:17.809+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:17.809+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:58:17.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T12:58:48.022+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:48.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:58:48.026+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:48.026+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:48.047+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:58:48.068+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:48.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:58:48.080+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:58:48.080+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:58:48.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T12:59:19.062+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:19.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:59:19.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:19.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:19.087+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:19.272+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:19.272+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:59:19.291+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:19.291+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:59:19.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.252 seconds
[2025-07-16T12:59:49.396+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:49.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T12:59:49.398+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:49.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:49.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T12:59:49.438+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:49.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T12:59:49.451+0000] {logging_mixin.py:188} INFO - [2025-07-16T12:59:49.451+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T12:59:49.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T13:00:20.294+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:20.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:00:20.297+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:20.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:20.315+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:20.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:20.340+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:00:20.353+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:20.353+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:00:20.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:00:50.524+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:50.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:00:50.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:50.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:50.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:00:50.565+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:50.564+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:00:50.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:00:50.575+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:00:50.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T13:01:20.748+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:20.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:01:20.751+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:20.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:20.790+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:20.814+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:20.814+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:01:20.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:20.827+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:01:20.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T13:01:51.106+0000] {processor.py:161} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:51.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:01:51.109+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:51.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:51.126+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:01:51.147+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:51.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:01:51.159+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:01:51.158+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:01:51.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T13:02:22.273+0000] {processor.py:161} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:22.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:02:22.276+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:22.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:22.306+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:22.329+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:22.328+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:02:22.342+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:22.342+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:02:22.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T13:02:52.431+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:52.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:02:52.434+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:52.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:52.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:02:52.473+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:52.473+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:02:52.486+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:02:52.485+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:02:52.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T13:03:23.333+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:23.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:03:23.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:23.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:23.348+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:23.370+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:23.370+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:03:23.382+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:23.382+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:03:23.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T13:03:53.563+0000] {processor.py:161} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:53.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:03:53.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:53.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:53.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:03:53.602+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:53.602+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:03:53.614+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:03:53.614+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:03:53.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T13:04:24.440+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:24.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:04:24.443+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:24.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:24.471+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:24.501+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:24.501+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:04:24.515+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:24.515+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:04:24.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T13:04:55.574+0000] {processor.py:161} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:55.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:04:55.577+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:55.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:55.589+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:04:55.610+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:55.610+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:04:55.622+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:04:55.621+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:04:55.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T13:05:26.415+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:26.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:05:26.417+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:26.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:26.434+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:26.459+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:26.459+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:05:26.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:26.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:05:26.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:05:57.381+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:57.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:05:57.386+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:57.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:57.458+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:05:57.485+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:57.485+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:05:57.498+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:05:57.498+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:05:57.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.144 seconds
[2025-07-16T13:06:27.871+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:27.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:06:27.874+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:27.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:27.891+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:27.913+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:27.913+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:06:27.925+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:27.925+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:06:27.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T13:06:58.834+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:58.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:06:58.837+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:58.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:58.865+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:06:58.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:58.892+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:06:58.904+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:06:58.904+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:06:58.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T13:07:29.853+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:07:29.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:07:29.856+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:07:29.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:07:29.876+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:07:29.900+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:07:29.900+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:07:29.913+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:07:29.913+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:07:29.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:08:00.812+0000] {processor.py:161} INFO - Started process (PID=1476) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:00.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:08:00.814+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:00.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:00.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:00.848+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:00.848+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:08:00.859+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:00.859+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:08:00.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T13:08:31.025+0000] {processor.py:161} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:31.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:08:31.027+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:31.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:31.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:08:31.065+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:31.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:08:31.077+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:08:31.077+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:08:31.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:09:01.161+0000] {processor.py:161} INFO - Started process (PID=1490) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:01.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:09:01.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:01.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:01.176+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:01.197+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:01.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:09:01.209+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:01.209+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:09:01.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T13:09:31.484+0000] {processor.py:161} INFO - Started process (PID=1497) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:31.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:09:31.488+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:31.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:31.518+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:09:31.548+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:31.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:09:31.566+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:09:31.566+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:09:31.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-16T13:10:02.412+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:02.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:10:02.415+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:02.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:02.443+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:02.468+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:02.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:10:02.482+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:02.482+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:10:02.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T13:10:32.566+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:32.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:10:32.569+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:32.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:32.603+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:10:32.641+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:32.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:10:32.654+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:10:32.654+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:10:32.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.110 seconds
[2025-07-16T13:11:03.638+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:03.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:11:03.647+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:03.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:03.665+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:03.688+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:03.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:11:03.699+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:03.699+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:11:03.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T13:11:34.631+0000] {processor.py:161} INFO - Started process (PID=1525) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:34.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:11:34.634+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:34.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:34.646+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:11:34.669+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:34.669+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:11:34.681+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:11:34.681+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:11:34.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T13:12:05.610+0000] {processor.py:161} INFO - Started process (PID=1532) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:05.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:12:05.614+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:05.613+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:05.636+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:05.663+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:05.662+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:12:05.683+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:05.682+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:12:05.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T13:12:36.552+0000] {processor.py:161} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:36.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:12:36.555+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:36.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:36.575+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:12:36.599+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:36.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:12:36.611+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:12:36.611+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:12:36.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T13:13:07.348+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:07.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:13:07.351+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:07.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:07.381+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:07.403+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:07.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:13:07.415+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:07.415+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:13:07.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T13:13:38.383+0000] {processor.py:161} INFO - Started process (PID=1553) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:38.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:13:38.386+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:38.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:38.455+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:13:38.481+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:38.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:13:38.494+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:13:38.493+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:13:38.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.139 seconds
[2025-07-16T13:14:08.731+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:08.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:14:08.734+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:08.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:08.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:08.778+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:08.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:14:08.789+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:08.789+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:14:08.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T13:14:39.017+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:39.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:14:39.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:39.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:39.039+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:14:39.064+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:39.064+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:14:39.078+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:14:39.078+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:14:39.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T13:15:09.266+0000] {processor.py:161} INFO - Started process (PID=1574) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:09.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:15:09.269+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:09.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:09.286+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:09.307+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:09.306+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:15:09.318+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:09.318+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:15:09.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:15:40.088+0000] {processor.py:161} INFO - Started process (PID=1581) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:40.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:15:40.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:40.093+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:40.114+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:15:40.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:40.143+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:15:40.156+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:15:40.156+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:15:40.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T13:16:11.201+0000] {processor.py:161} INFO - Started process (PID=1588) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:11.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:16:11.204+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:11.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:11.227+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:11.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:11.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:16:11.260+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:11.260+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:16:11.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T13:16:41.360+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:41.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:16:41.362+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:41.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:41.382+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:16:41.405+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:41.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:16:41.417+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:16:41.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:16:41.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:17:12.467+0000] {processor.py:161} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:12.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:17:12.470+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:12.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:12.497+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:12.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:12.527+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:17:12.541+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:12.541+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:17:12.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T13:17:42.701+0000] {processor.py:161} INFO - Started process (PID=1609) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:42.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:17:42.704+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:42.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:42.725+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:17:42.752+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:42.751+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:17:42.764+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:17:42.764+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:17:42.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T13:18:13.047+0000] {processor.py:161} INFO - Started process (PID=1616) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:13.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:18:13.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:13.050+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:13.078+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:13.102+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:13.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:18:13.115+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:13.115+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:18:13.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T13:18:43.276+0000] {processor.py:161} INFO - Started process (PID=1623) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:43.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:18:43.279+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:43.279+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:43.293+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:18:43.316+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:43.316+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:18:43.328+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:18:43.328+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:18:43.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T13:19:14.291+0000] {processor.py:161} INFO - Started process (PID=1630) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:14.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:19:14.294+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:14.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:14.315+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:14.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:14.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:19:14.356+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:14.356+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:19:14.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T13:19:44.422+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:44.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:19:44.425+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:44.425+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:44.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:19:44.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:44.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:19:44.482+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:19:44.482+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:19:44.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T13:20:15.355+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:15.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:20:15.358+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:15.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:15.371+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:15.391+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:15.391+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:20:15.403+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:15.403+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:20:15.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T13:20:46.335+0000] {processor.py:161} INFO - Started process (PID=1651) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:46.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:20:46.338+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:46.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:46.352+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:20:46.377+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:46.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:20:46.390+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:20:46.389+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:20:46.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T13:21:17.231+0000] {processor.py:161} INFO - Started process (PID=1658) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:21:17.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:21:17.234+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:21:17.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:21:17.256+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:21:17.278+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:21:17.278+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:21:17.290+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:21:17.290+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:21:17.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T13:30:50.525+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:30:50.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:30:50.529+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:30:50.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:30:50.560+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:30:50.618+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:30:50.618+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:30:50.635+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:30:50.635+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:30:50.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.144 seconds
[2025-07-16T13:31:20.939+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:20.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:31:20.943+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:20.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:20.983+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:21.011+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:21.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:31:21.024+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:21.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:31:21.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-16T13:31:51.133+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:51.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:31:51.136+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:51.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:51.149+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:31:51.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:51.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:31:51.184+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:31:51.183+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:31:51.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T13:32:21.289+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:21.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:32:21.291+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:21.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:21.305+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:21.324+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:21.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:32:21.337+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:21.337+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:32:21.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T13:32:51.580+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:51.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:32:51.583+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:51.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:51.599+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:32:51.623+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:51.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:32:51.636+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:32:51.635+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:32:51.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T13:33:21.718+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:21.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:33:21.721+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:21.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:21.748+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:21.770+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:21.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:33:21.782+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:21.781+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:33:21.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T13:33:51.896+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:51.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:33:51.898+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:51.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:51.924+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:33:51.948+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:51.948+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:33:51.959+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:33:51.959+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:33:51.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T13:34:22.294+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:22.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:34:22.296+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:22.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:22.332+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:22.355+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:22.355+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:34:22.375+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:22.374+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:34:22.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.107 seconds
[2025-07-16T13:34:53.320+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:53.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:34:53.323+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:53.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:53.340+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:34:53.361+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:53.361+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:34:53.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:34:53.373+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:34:53.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:35:24.394+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:24.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:35:24.397+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:24.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:24.409+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:24.431+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:24.431+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:35:24.443+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:24.443+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:35:24.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T13:35:54.495+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:54.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:35:54.498+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:54.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:54.511+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:35:54.533+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:54.533+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:35:54.545+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:35:54.545+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:35:54.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T13:36:24.627+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:24.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:36:24.630+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:24.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:24.648+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:24.672+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:24.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:36:24.685+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:24.684+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:36:24.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T13:36:55.293+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:55.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:36:55.296+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:55.295+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:55.317+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:36:55.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:55.340+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:36:55.353+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:36:55.353+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:36:55.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:37:25.517+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:25.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:37:25.520+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:25.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:25.537+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:25.558+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:25.558+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:37:25.570+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:25.570+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:37:25.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T13:37:55.796+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:55.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:37:55.799+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:55.798+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:55.811+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:37:55.832+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:55.831+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:37:55.842+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:37:55.842+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:37:55.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T13:38:25.952+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:25.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:38:25.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:25.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:25.967+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:25.988+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:25.987+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:38:25.998+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:25.998+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:38:26.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T13:38:56.172+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:56.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:38:56.177+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:56.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:56.190+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:38:56.213+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:56.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:38:56.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:38:56.225+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:38:56.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:39:26.415+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:26.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:39:26.418+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:26.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:26.431+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:26.453+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:26.453+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:39:26.469+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:26.469+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:39:26.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T13:39:56.741+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:56.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:39:56.744+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:56.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:56.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:39:56.781+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:56.781+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:39:56.793+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:39:56.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:39:56.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T13:40:27.018+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:27.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:40:27.021+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:27.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:27.042+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:27.063+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:27.063+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:40:27.075+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:27.074+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:40:27.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T13:40:57.296+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:57.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:40:57.299+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:57.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:57.314+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:40:57.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:57.335+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:40:57.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:40:57.347+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:40:57.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:41:28.333+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:28.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:41:28.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:28.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:28.382+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:28.404+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:28.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:41:28.415+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:28.415+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:41:28.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-16T13:41:58.524+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:58.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:41:58.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:58.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:58.558+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:41:58.579+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:58.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:41:58.591+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:41:58.591+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:41:58.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T13:42:29.056+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:29.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:42:29.059+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:29.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:29.080+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:29.102+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:29.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:42:29.114+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:29.113+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:42:29.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T13:42:59.364+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:59.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:42:59.371+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:59.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:59.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:42:59.467+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:59.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:42:59.479+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:42:59.479+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:42:59.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.143 seconds
[2025-07-16T13:43:29.756+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:29.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:43:29.759+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:29.759+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:29.774+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:29.797+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:29.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:43:29.809+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:29.809+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:43:29.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:43:59.944+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:59.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:43:59.946+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:59.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:59.960+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:43:59.982+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:59.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:43:59.994+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:43:59.994+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:44:00.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T13:44:30.134+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:44:30.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:44:30.137+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:44:30.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:44:30.151+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:44:30.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:44:30.173+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:44:30.185+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:44:30.185+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:44:30.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:45:00.290+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:00.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:45:00.293+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:00.293+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:00.306+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:00.327+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:00.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:45:00.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:00.338+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:45:00.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T13:45:30.503+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:30.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:45:30.506+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:30.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:30.524+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:45:30.546+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:30.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:45:30.557+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:45:30.557+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:45:30.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-16T13:46:01.494+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:01.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:46:01.497+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:01.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:01.519+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:01.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:01.540+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:46:01.553+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:01.553+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:46:01.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:46:31.717+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:31.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:46:31.720+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:31.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:31.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:46:31.769+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:31.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:46:31.781+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:46:31.781+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:46:31.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T13:47:01.869+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:01.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:47:01.872+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:01.872+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:01.895+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:01.921+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:01.921+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:47:01.934+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:01.934+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:47:01.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T13:47:32.892+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:32.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:47:32.895+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:32.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:32.919+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:47:32.942+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:32.942+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:47:32.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:47:32.953+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:47:32.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T13:48:03.871+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:03.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:48:03.874+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:03.874+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:03.892+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:03.918+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:03.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:48:03.931+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:03.931+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:48:03.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T13:48:34.847+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:34.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:48:34.849+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:34.849+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:34.869+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:48:34.892+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:34.892+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:48:34.905+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:48:34.905+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:48:34.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T13:49:05.806+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:05.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:49:05.808+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:05.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:05.829+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:05.850+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:05.850+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:49:05.862+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:05.862+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:49:05.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T13:49:36.686+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:36.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:49:36.690+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:36.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:36.717+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:49:36.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:36.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:49:36.751+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:49:36.750+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:49:36.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T13:50:06.840+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:06.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:50:06.842+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:06.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:06.857+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:06.879+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:06.878+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:50:06.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:06.890+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:50:06.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T13:50:36.970+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:36.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:50:36.973+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:36.972+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:36.996+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:50:37.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:37.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:50:37.030+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:50:37.030+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:50:37.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T13:51:07.218+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:07.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:51:07.221+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:07.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:07.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:07.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:07.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:51:07.277+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:07.277+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:51:07.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T13:51:37.408+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:37.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:51:37.412+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:37.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:37.479+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:51:37.504+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:37.504+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:51:37.520+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:51:37.519+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:51:37.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.135 seconds
[2025-07-16T13:52:07.730+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:07.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:52:07.733+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:07.733+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:07.760+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:07.929+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:07.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:52:07.943+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:07.943+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:52:07.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T13:52:38.868+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:38.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:52:38.871+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:38.871+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:38.902+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:52:38.930+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:38.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:52:38.943+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:52:38.943+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:52:38.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-16T13:53:09.826+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:09.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:53:09.828+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:09.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:09.855+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:09.878+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:09.878+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:53:09.890+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:09.890+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:53:09.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T13:53:40.080+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:40.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:53:40.083+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:40.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:40.105+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:53:40.130+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:40.130+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:53:40.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:53:40.142+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:53:40.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T13:54:10.332+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:10.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:54:10.335+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:10.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:10.363+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:10.389+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:10.389+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:54:10.403+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:10.403+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:54:10.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T13:54:40.475+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:40.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:54:40.478+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:40.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:40.500+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:54:40.534+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:40.534+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:54:40.546+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:54:40.546+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:54:40.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T13:55:11.534+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:11.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:55:11.537+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:11.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:11.551+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:11.572+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:11.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:55:11.584+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:11.583+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:55:11.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-16T13:55:41.729+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:41.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:55:41.731+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:41.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:41.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:55:41.769+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:41.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:55:41.783+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:55:41.783+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:55:41.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T13:56:12.112+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:12.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:56:12.114+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:12.114+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:12.130+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:12.153+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:12.153+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:56:12.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:12.165+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:56:12.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T13:56:42.998+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:42.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:56:43.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:43.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:43.026+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:56:43.050+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:43.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:56:43.062+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:56:43.062+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:56:43.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T13:57:14.044+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:14.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:57:14.047+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:14.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:14.067+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:14.088+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:14.088+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:57:14.100+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:14.100+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:57:14.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T13:57:45.043+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:45.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:57:45.046+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:45.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:45.060+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:57:45.087+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:45.087+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:57:45.099+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:57:45.099+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:57:45.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T13:58:15.417+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:15.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:58:15.420+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:15.419+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:15.435+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:15.456+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:15.456+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:58:15.468+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:15.468+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:58:15.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T13:58:45.569+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:45.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:58:45.576+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:45.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:45.589+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:58:45.612+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:45.612+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:58:45.625+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:58:45.624+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:58:45.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T13:59:15.744+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:15.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:59:15.748+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:15.747+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:15.770+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:15.796+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:15.796+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:59:15.810+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:15.810+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:59:15.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T13:59:46.128+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:46.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T13:59:46.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:46.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:46.155+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T13:59:46.180+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:46.180+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T13:59:46.192+0000] {logging_mixin.py:188} INFO - [2025-07-16T13:59:46.192+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T13:59:46.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:00:16.380+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:16.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:00:16.383+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:16.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:16.404+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:16.428+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:16.428+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:00:16.439+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:16.439+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:00:16.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T14:00:46.586+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:46.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:00:46.589+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:46.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:46.606+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:00:46.629+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:46.629+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:00:46.642+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:00:46.642+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:00:46.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T14:01:16.797+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:16.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:01:16.799+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:16.799+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:16.819+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:16.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:16.843+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:01:16.857+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:16.856+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:01:16.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T14:01:47.044+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:47.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:01:47.047+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:47.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:47.069+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:01:47.093+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:47.092+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:01:47.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:01:47.105+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:01:47.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T14:02:17.183+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:17.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:02:17.186+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:17.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:17.203+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:17.225+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:17.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:02:17.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:17.238+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:02:17.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T14:02:47.426+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:47.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:02:47.429+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:47.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:47.452+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:02:47.476+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:47.476+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:02:47.489+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:02:47.489+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:02:47.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T14:03:18.533+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:18.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:03:18.536+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:18.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:18.554+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:18.579+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:18.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:03:18.592+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:18.592+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:03:18.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T14:03:48.814+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:48.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:03:48.817+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:48.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:48.852+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:03:48.874+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:48.874+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:03:48.887+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:03:48.887+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:03:48.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T14:04:18.996+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:18.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:04:18.999+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:18.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:19.025+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:19.049+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:19.048+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:04:19.063+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:19.063+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:04:19.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T14:04:49.285+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:49.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:04:49.289+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:49.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:49.320+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:04:49.344+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:49.343+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:04:49.356+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:04:49.356+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:04:49.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T14:05:19.440+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:19.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:05:19.443+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:19.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:19.470+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:19.491+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:19.491+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:05:19.503+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:19.503+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:05:19.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T14:05:49.675+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:49.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:05:49.678+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:49.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:49.702+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:05:49.727+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:49.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:05:49.740+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:05:49.740+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:05:49.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T14:06:19.849+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:19.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:06:19.852+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:19.852+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:19.908+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:19.931+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:19.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:06:19.944+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:19.943+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:06:19.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-16T14:06:50.042+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:50.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:06:50.044+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:50.044+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:50.057+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:06:50.079+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:50.078+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:06:50.092+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:06:50.091+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:06:50.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T14:07:20.339+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:20.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:07:20.342+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:20.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:20.376+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:20.409+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:20.409+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:07:20.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:20.423+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:07:20.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-07-16T14:07:51.150+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:51.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:07:51.152+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:51.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:51.168+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:07:51.189+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:51.189+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:07:51.201+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:07:51.201+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:07:51.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T14:08:22.102+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:22.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:08:22.105+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:22.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:22.135+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:22.160+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:22.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:08:22.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:22.172+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:08:22.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T14:08:53.007+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:53.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:08:53.009+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:53.008+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:53.047+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:08:53.070+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:53.070+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:08:53.083+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:08:53.083+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:08:53.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T14:09:23.983+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:23.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:09:23.986+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:23.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:24.023+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:24.045+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:24.045+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:09:24.057+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:24.056+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:09:24.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-16T14:09:54.834+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:54.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:09:54.838+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:54.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:54.861+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:09:54.885+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:54.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:09:54.899+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:09:54.898+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:09:54.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:10:25.118+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:25.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:10:25.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:25.120+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:25.139+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:25.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:25.162+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:10:25.176+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:25.175+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:10:25.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T14:10:56.115+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:56.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:10:56.118+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:56.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:56.140+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:10:56.163+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:56.162+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:10:56.175+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:10:56.175+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:10:56.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T14:11:26.259+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:26.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:11:26.262+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:26.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:26.274+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:26.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:26.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:11:26.309+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:26.309+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:11:26.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T14:11:57.170+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:57.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:11:57.172+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:57.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:57.188+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:11:57.219+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:57.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:11:57.230+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:11:57.230+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:11:57.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T14:12:28.089+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:28.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:12:28.092+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:28.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:28.109+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:28.131+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:28.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:12:28.143+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:28.142+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:12:28.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-16T14:12:59.130+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:59.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:12:59.133+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:59.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:59.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:12:59.178+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:59.178+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:12:59.190+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:12:59.190+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:12:59.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T14:13:30.229+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:13:30.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:13:30.231+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:13:30.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:13:30.248+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:13:30.269+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:13:30.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:13:30.281+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:13:30.281+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:13:30.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T14:14:01.308+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:01.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:14:01.310+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:01.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:01.333+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:01.357+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:01.357+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:14:01.370+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:01.370+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:14:01.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T14:14:31.589+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:31.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:14:31.592+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:31.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:31.619+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:14:31.642+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:31.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:14:31.656+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:14:31.655+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:14:31.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T14:15:02.660+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:02.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:15:02.663+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:02.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:02.689+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:02.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:02.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:15:02.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:02.726+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:15:02.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T14:15:32.840+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:32.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:15:32.843+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:32.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:32.871+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:15:32.899+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:32.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:15:32.918+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:15:32.918+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:15:32.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-16T14:16:03.303+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:03.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:16:03.305+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:03.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:03.323+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:03.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:03.346+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:16:03.359+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:03.359+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:16:03.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:16:34.386+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:34.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:16:34.388+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:34.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:34.410+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:16:34.431+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:34.431+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:16:34.444+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:16:34.443+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:16:34.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T14:17:04.563+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:04.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:17:04.565+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:04.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:04.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:04.603+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:04.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:17:04.617+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:04.617+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:17:04.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T14:17:35.661+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:35.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:17:35.664+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:35.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:35.677+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:17:35.701+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:35.701+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:17:35.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:17:35.714+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:17:35.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:18:05.883+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:05.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:18:05.887+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:05.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:05.908+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:05.949+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:05.948+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:18:05.973+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:05.973+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:18:05.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.126 seconds
[2025-07-16T14:18:36.999+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:37.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:18:37.004+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:37.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:37.028+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:18:37.057+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:37.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:18:37.072+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:18:37.072+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:18:37.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-16T14:19:07.267+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:07.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:19:07.272+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:07.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:07.290+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:07.321+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:07.320+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:19:07.334+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:07.334+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:19:07.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T14:19:38.329+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:38.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:19:38.333+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:38.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:38.364+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:19:38.388+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:38.387+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:19:38.400+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:19:38.399+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:19:38.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:20:08.564+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:08.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:20:08.567+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:08.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:08.590+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:08.613+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:08.613+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:20:08.625+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:08.625+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:20:08.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T14:20:38.715+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:38.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:20:38.718+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:38.717+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:38.738+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:20:38.760+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:38.760+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:20:38.772+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:20:38.772+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:20:38.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T14:21:09.022+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:09.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:21:09.025+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:09.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:09.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:09.069+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:09.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:21:09.081+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:09.081+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:21:09.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T14:21:39.154+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:39.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:21:39.156+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:39.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:39.172+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:21:39.202+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:39.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:21:39.214+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:21:39.213+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:21:39.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T14:22:09.736+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:09.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:22:09.741+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:09.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:09.773+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:09.805+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:09.805+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:22:09.820+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:09.820+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:22:09.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.121 seconds
[2025-07-16T14:22:40.034+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:40.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:22:40.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:40.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:40.062+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:22:40.083+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:40.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:22:40.094+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:22:40.094+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:22:40.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T14:23:10.398+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:10.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:23:10.407+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:10.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:10.513+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:10.538+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:10.538+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:23:10.553+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:10.553+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:23:10.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.190 seconds
[2025-07-16T14:23:40.940+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:40.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:23:40.943+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:40.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:40.956+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:23:40.978+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:40.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:23:40.989+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:23:40.989+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:23:41.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-16T14:24:11.947+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:11.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:24:11.950+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:11.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:11.967+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:11.993+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:11.993+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:24:12.005+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:12.005+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:24:12.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T14:24:43.058+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:43.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:24:43.061+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:43.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:43.080+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:24:43.109+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:43.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:24:43.122+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:24:43.121+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:24:43.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:25:13.885+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:13.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:25:13.888+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:13.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:13.912+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:13.935+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:13.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:25:13.948+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:13.948+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:25:13.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:25:44.013+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:44.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:25:44.016+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:44.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:44.036+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:25:44.060+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:44.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:25:44.076+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:25:44.076+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:25:44.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:26:14.302+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:14.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:26:14.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:14.304+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:14.322+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:14.344+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:14.344+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:26:14.357+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:14.357+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:26:14.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:26:45.339+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:45.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:26:45.341+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:45.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:45.363+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:26:45.386+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:45.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:26:45.400+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:26:45.400+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:26:45.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T14:27:15.479+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:15.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:27:15.482+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:15.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:15.506+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:15.527+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:15.527+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:27:15.540+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:15.540+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:27:15.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T14:27:45.681+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:45.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:27:45.684+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:45.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:45.714+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:27:45.740+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:45.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:27:45.753+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:27:45.753+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:27:45.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T14:28:15.885+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:15.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:28:15.887+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:15.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:15.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:15.920+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:15.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:28:15.931+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:15.931+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:28:15.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-16T14:28:45.999+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:45.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:28:46.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:46.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:46.014+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:28:46.035+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:46.035+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:28:46.048+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:28:46.048+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:28:46.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-16T14:29:16.973+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:16.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:29:16.975+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:16.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:16.995+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:17.017+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:17.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:29:17.029+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:17.029+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:29:17.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T14:29:48.016+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:48.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:29:48.019+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:48.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:48.043+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:29:48.067+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:48.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:29:48.080+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:29:48.080+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:29:48.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:30:18.167+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:18.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:30:18.169+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:18.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:18.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:18.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:18.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:30:18.217+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:18.217+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:30:18.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T14:30:48.284+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:48.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:30:48.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:48.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:48.309+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:30:48.334+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:48.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:30:48.347+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:30:48.346+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:30:48.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T14:31:18.635+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:18.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:31:18.638+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:18.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:18.654+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:18.679+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:18.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:31:18.690+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:18.690+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:31:18.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:31:48.772+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:48.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:31:48.774+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:48.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:48.789+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:31:48.812+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:48.812+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:31:48.823+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:31:48.823+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:31:48.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:32:19.118+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:19.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:32:19.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:19.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:19.143+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:19.166+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:19.166+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:32:19.178+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:19.177+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:32:19.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T14:32:50.097+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:50.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:32:50.101+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:50.100+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:50.127+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:32:50.158+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:50.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:32:50.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:32:50.173+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:32:50.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T14:33:21.186+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:21.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:33:21.191+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:21.190+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:21.222+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:21.246+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:21.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:33:21.258+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:21.258+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:33:21.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T14:33:52.219+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:52.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:33:52.222+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:52.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:52.246+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:33:52.275+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:52.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:33:52.298+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:33:52.298+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:33:52.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-16T14:34:22.411+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:22.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:34:22.417+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:22.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:22.446+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:22.470+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:22.470+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:34:22.484+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:22.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:34:22.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T14:34:52.653+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:52.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:34:52.656+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:52.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:52.690+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:34:52.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:52.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:34:52.732+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:34:52.732+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:34:52.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.107 seconds
[2025-07-16T14:35:22.846+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:22.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:35:22.849+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:22.849+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:22.877+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:22.902+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:22.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:35:22.919+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:22.919+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:35:22.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-16T14:35:53.039+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:53.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:35:53.041+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:53.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:53.060+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:35:53.084+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:53.084+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:35:53.097+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:35:53.097+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:35:53.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T14:36:23.373+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:23.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:36:23.376+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:23.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:23.398+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:23.420+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:23.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:36:23.432+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:23.432+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:36:23.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T14:36:54.382+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:54.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:36:54.384+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:54.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:54.403+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:36:54.430+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:54.430+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:36:54.444+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:36:54.444+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:36:54.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T14:37:25.424+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:25.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:37:25.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:25.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:25.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:25.463+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:25.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:37:25.476+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:25.475+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:37:25.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T14:37:56.496+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:56.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:37:56.498+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:56.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:56.514+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:37:56.539+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:56.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:37:56.552+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:37:56.552+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:37:56.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T14:38:26.819+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:26.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:38:26.822+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:26.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:26.840+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:26.864+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:26.864+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:38:26.877+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:26.877+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:38:26.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-16T14:38:57.084+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:57.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:38:57.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:57.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:57.110+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:38:57.135+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:57.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:38:57.148+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:38:57.148+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:38:57.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T14:39:28.098+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:28.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:39:28.100+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:28.100+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:28.125+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:28.148+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:28.148+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:39:28.161+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:28.161+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:39:28.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T14:39:58.257+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:58.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:39:58.260+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:58.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:58.281+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:39:58.305+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:58.305+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:39:58.317+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:39:58.317+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:39:58.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:40:28.470+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:28.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:40:28.474+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:28.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:28.490+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:28.516+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:28.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:40:28.529+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:28.529+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:40:28.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T14:40:58.774+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:58.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:40:58.778+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:58.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:58.804+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:40:58.827+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:58.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:40:58.841+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:40:58.841+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:40:58.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:41:28.999+0000] {processor.py:161} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:28.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:41:29.001+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:29.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:29.013+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:29.036+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:29.036+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:41:29.049+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:29.048+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:41:29.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T14:41:59.322+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:59.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:41:59.324+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:59.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:59.339+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:41:59.362+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:59.362+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:41:59.375+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:41:59.375+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:41:59.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:42:29.489+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:29.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:42:29.491+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:29.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:29.508+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:29.530+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:29.530+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:42:29.542+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:29.542+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:42:29.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T14:42:59.864+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:59.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:42:59.868+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:59.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:59.889+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:42:59.912+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:59.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:42:59.924+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:42:59.924+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:42:59.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-16T14:43:30.002+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:43:30.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:43:30.005+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:43:30.005+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:43:30.031+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:43:30.055+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:43:30.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:43:30.068+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:43:30.068+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:43:30.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:44:00.161+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:00.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:44:00.165+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:00.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:00.191+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:00.216+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:00.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:44:00.232+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:00.232+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:44:00.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T14:44:30.387+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:30.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:44:30.393+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:30.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:30.425+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:44:30.455+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:30.455+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:44:30.469+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:44:30.469+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:44:30.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-16T14:45:00.668+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:00.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:45:00.671+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:00.671+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:00.697+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:00.719+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:00.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:45:00.732+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:00.732+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:45:00.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:45:30.967+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:30.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:45:30.969+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:30.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:30.985+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:45:31.009+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:31.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:45:31.022+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:45:31.022+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:45:31.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T14:46:01.284+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:01.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:46:01.287+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:01.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:01.313+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:01.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:01.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:46:01.351+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:01.351+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:46:01.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-16T14:46:31.530+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:31.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:46:31.533+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:31.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:31.559+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:46:31.581+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:31.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:46:31.594+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:46:31.594+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:46:31.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:47:01.838+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:01.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:47:01.841+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:01.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:01.866+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:01.891+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:01.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:47:01.907+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:01.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:47:01.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-16T14:47:32.126+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:32.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:47:32.129+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:32.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:32.147+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:47:32.173+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:32.173+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:47:32.187+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:47:32.187+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:47:32.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T14:48:02.290+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:02.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:48:02.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:02.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:02.308+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:02.329+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:02.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:48:02.340+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:02.340+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:48:02.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-16T14:48:33.370+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:33.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:48:33.373+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:33.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:33.400+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:48:33.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:33.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:48:33.437+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:48:33.437+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:48:33.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:49:04.383+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:04.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:49:04.386+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:04.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:04.405+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:04.428+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:04.428+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:49:04.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:04.440+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:49:04.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T14:49:35.410+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:35.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:49:35.413+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:35.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:35.427+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:49:35.448+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:35.448+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:49:35.460+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:49:35.460+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:49:35.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T14:50:06.347+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:06.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:50:06.350+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:06.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:06.379+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:06.403+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:06.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:50:06.416+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:06.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:50:06.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-16T14:50:37.357+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:37.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:50:37.361+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:37.361+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:37.383+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:50:37.410+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:37.410+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:50:37.423+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:50:37.423+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:50:37.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:51:07.584+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:07.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:51:07.587+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:07.586+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:07.612+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:07.638+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:07.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:51:07.651+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:07.650+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:51:07.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:51:37.844+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:37.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:51:37.847+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:37.847+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:37.870+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:51:37.894+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:37.894+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:51:37.909+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:51:37.908+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:51:37.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-16T14:52:07.982+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:07.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:52:07.984+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:07.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:08.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:08.025+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:08.025+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:52:08.037+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:08.037+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:52:08.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T14:52:38.602+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:38.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:52:38.606+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:38.606+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:38.632+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:52:38.657+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:38.657+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:52:38.671+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:52:38.670+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:52:38.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-16T14:53:09.551+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:09.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:53:09.554+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:09.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:09.567+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:09.593+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:09.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:53:09.607+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:09.606+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:53:09.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T14:53:39.873+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:39.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:53:39.877+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:39.877+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:40.016+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:53:40.040+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:40.040+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:53:40.052+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:53:40.052+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:53:40.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.207 seconds
[2025-07-16T14:54:10.263+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:10.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:54:10.265+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:10.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:10.280+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:10.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:10.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:54:10.318+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:10.318+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:54:10.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T14:54:41.277+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:41.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:54:41.281+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:41.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:41.296+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:54:41.318+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:41.318+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:54:41.330+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:54:41.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:54:41.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T14:55:11.697+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:11.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:55:11.701+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:11.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:11.715+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:11.739+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:11.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:55:11.750+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:11.750+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:55:11.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-16T14:55:42.752+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:42.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:55:42.755+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:42.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:42.772+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:55:42.795+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:42.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:55:42.807+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:55:42.807+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:55:42.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-16T14:56:13.029+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:13.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:56:13.032+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:13.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:13.060+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:13.086+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:13.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:56:13.101+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:13.100+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:56:13.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T14:56:43.200+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:43.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:56:43.203+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:43.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:43.223+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:56:43.246+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:43.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:56:43.258+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:56:43.258+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:56:43.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-16T14:57:13.467+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:13.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:57:13.470+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:13.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:13.494+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:13.519+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:13.518+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:57:13.531+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:13.531+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:57:13.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T14:57:43.674+0000] {processor.py:161} INFO - Started process (PID=1238) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:43.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:57:43.678+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:43.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:43.692+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:57:43.714+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:43.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:57:43.726+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:57:43.726+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:57:43.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-16T14:58:13.952+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:13.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:58:13.954+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:13.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:13.978+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:13.998+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:13.998+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:58:14.010+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:14.010+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:58:14.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T14:58:44.244+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:44.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:58:44.248+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:44.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:44.281+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:58:44.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:44.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:58:44.316+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:58:44.315+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:58:44.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-16T14:59:14.426+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:14.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:59:14.429+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:14.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:14.450+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:14.472+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:14.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:59:14.484+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:14.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:59:14.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-16T14:59:44.557+0000] {processor.py:161} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:44.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T14:59:44.560+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:44.560+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:44.582+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T14:59:44.603+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:44.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T14:59:44.619+0000] {logging_mixin.py:188} INFO - [2025-07-16T14:59:44.618+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T14:59:44.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T15:00:14.727+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:14.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:00:14.730+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:14.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:14.751+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:14.774+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:14.774+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:00:14.785+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:14.785+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:00:14.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T15:00:44.874+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:44.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:00:44.879+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:44.879+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:44.914+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:00:44.938+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:44.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:00:44.950+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:00:44.950+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:00:44.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-16T15:01:15.119+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:15.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:01:15.121+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:15.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:15.144+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:15.168+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:15.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:01:15.180+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:15.180+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:01:15.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-16T15:01:45.276+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:45.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:01:45.282+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:45.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:45.315+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:01:45.339+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:45.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:01:45.351+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:01:45.351+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:01:45.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-16T15:02:15.659+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:15.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:02:15.666+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:15.666+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:15.681+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:15.703+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:15.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:02:15.715+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:15.715+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:02:15.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-16T15:02:45.950+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:45.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:02:45.953+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:45.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:45.980+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:02:46.002+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:46.002+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:02:46.015+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:02:46.014+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:02:46.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-16T15:03:16.088+0000] {processor.py:161} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:16.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:03:16.091+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:16.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:16.107+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:16.132+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:16.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:03:16.145+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:16.145+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:03:16.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-16T15:03:46.598+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:46.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:03:46.602+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:46.602+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:46.621+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:03:46.645+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:46.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:03:46.658+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:03:46.658+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:03:46.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T15:04:17.234+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:17.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:04:17.238+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:17.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:17.260+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:17.283+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:17.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:04:17.295+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:17.294+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:04:17.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-16T15:04:48.032+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:48.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:04:48.035+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:48.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:48.047+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:04:48.068+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:48.068+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:04:48.080+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:04:48.079+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:04:48.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-16T15:05:18.201+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:18.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:05:18.205+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:18.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:18.228+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:18.252+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:18.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:05:18.263+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:18.263+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:05:18.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-16T15:05:48.376+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:48.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:05:48.379+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:48.379+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:48.403+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:05:48.427+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:48.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:05:48.440+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:05:48.440+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:05:48.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-16T15:06:18.555+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:18.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:06:18.559+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:18.559+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:18.587+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:18.624+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:18.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:06:18.637+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:18.637+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:06:18.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-16T15:06:49.635+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:49.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:06:49.639+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:49.639+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:49.664+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:06:49.688+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:49.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:06:49.700+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:06:49.700+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:06:49.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-16T15:07:20.753+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:20.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:07:20.757+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:20.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:20.788+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:20.816+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:20.815+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:07:20.831+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:20.831+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:07:20.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-16T15:07:50.966+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:50.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:07:50.970+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:50.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:51.005+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:07:51.031+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:51.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:07:51.043+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:07:51.043+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:07:51.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-16T15:08:21.232+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:08:21.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-16T15:08:21.235+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:08:21.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:08:21.265+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-16T15:08:21.292+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:08:21.291+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-16T15:08:21.304+0000] {logging_mixin.py:188} INFO - [2025-07-16T15:08:21.304+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-16T15:08:21.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
