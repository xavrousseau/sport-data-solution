[2025-07-15T08:31:10.127+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:31:10.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.152+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.272+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:31:10.283+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.282+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:31:10.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.181 seconds
[2025-07-15T08:31:40.427+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:31:40.431+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.453+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:31:40.490+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:31:40.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:32:11.347+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:32:11.350+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.371+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.395+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.395+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:32:11.405+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.405+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:32:11.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T08:32:42.259+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:32:42.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.281+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.308+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:32:42.319+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.319+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:32:42.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:33:12.588+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:33:12.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.637+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:33:12.648+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.648+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:33:12.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:33:42.813+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:33:42.816+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.848+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:33:42.858+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.858+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:33:42.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T08:34:12.991+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:12.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:34:12.994+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:12.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:13.023+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:13.046+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:13.046+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:34:13.058+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:13.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:34:13.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
