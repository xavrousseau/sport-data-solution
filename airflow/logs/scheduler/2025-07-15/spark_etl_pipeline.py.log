[2025-07-15T08:31:10.127+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:31:10.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.152+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:10.272+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:31:10.283+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:10.282+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:31:10.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.181 seconds
[2025-07-15T08:31:40.427+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:31:40.431+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.453+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:31:40.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:31:40.490+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:31:40.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:31:40.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:32:11.347+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:32:11.350+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.371+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:11.395+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.395+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:32:11.405+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:11.405+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:32:11.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T08:32:42.259+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:32:42.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.281+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:32:42.308+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:32:42.319+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:32:42.319+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:32:42.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:33:12.588+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:33:12.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:12.637+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:33:12.648+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:12.648+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:33:12.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:33:42.813+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:33:42.816+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:33:42.848+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:33:42.858+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:33:42.858+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:33:42.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T08:34:12.991+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:12.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:34:12.994+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:12.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:13.023+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:13.046+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:13.046+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:34:13.058+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:13.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:34:13.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T08:34:43.145+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:43.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:34:43.148+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:43.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:43.163+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:34:43.184+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:43.184+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:34:43.197+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:34:43.196+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:34:43.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T08:35:14.210+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:14.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:35:14.212+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:14.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:14.227+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:14.259+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:14.259+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:35:14.270+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:14.270+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:35:14.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:35:44.667+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:44.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:35:44.670+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:44.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:44.698+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:35:44.722+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:44.722+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:35:44.733+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:35:44.733+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:35:44.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T08:36:14.950+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:14.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:36:14.952+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:14.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:14.974+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:14.997+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:14.997+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:36:15.012+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:15.012+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:36:15.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T08:36:45.846+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:45.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:36:45.848+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:45.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:45.864+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:36:45.887+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:45.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:36:45.899+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:36:45.899+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:36:45.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T08:37:16.905+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:16.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:37:16.908+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:16.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:16.926+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:16.946+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:16.946+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:37:16.957+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:16.957+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:37:16.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T08:37:47.947+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:47.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:37:47.950+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:47.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:47.966+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:37:47.990+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:47.990+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:37:48.002+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:37:48.002+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:37:48.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:38:18.127+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:18.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:38:18.129+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:18.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:18.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:18.165+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:18.164+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:38:18.175+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:18.174+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:38:18.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T08:38:48.355+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:48.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:38:48.357+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:48.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:48.371+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:38:48.391+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:48.390+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:38:48.402+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:38:48.401+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:38:48.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T08:39:18.629+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:18.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:39:18.632+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:18.632+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:18.716+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:18.745+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:18.745+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:39:18.758+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:18.758+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:39:18.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.162 seconds
[2025-07-15T08:39:49.039+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:49.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:39:49.042+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:49.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:49.056+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:39:49.075+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:49.075+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:39:49.086+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:39:49.085+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:39:49.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T08:40:20.113+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:20.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:40:20.116+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:20.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:20.133+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:20.155+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:20.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:40:20.166+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:20.166+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:40:20.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T08:40:51.198+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:51.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:40:51.200+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:51.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:51.217+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:40:51.238+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:51.238+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:40:51.249+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:40:51.249+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:40:51.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T08:41:22.118+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:22.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:41:22.120+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:22.120+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:22.137+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:22.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:22.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:41:22.172+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:22.172+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:41:22.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T08:41:52.466+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:52.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:41:52.469+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:52.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:52.485+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:41:52.507+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:52.507+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:41:52.518+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:41:52.518+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:41:52.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T08:42:22.639+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:22.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:42:22.642+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:22.642+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:22.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:22.699+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:22.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:42:22.710+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:22.710+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:42:22.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T08:42:52.909+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:52.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:42:52.912+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:52.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:52.934+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:42:52.957+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:52.957+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:42:52.968+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:42:52.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:42:52.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T08:43:23.997+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:23.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:43:24.000+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:24.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:24.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:24.041+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:24.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:43:24.053+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:24.053+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:43:24.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T08:43:54.293+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:54.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:43:54.298+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:54.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:54.312+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:43:54.333+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:54.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:43:54.345+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:43:54.345+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:43:54.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T08:44:24.406+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:24.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:44:24.409+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:24.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:24.430+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:24.454+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:24.454+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:44:24.464+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:24.464+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:44:24.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T08:44:54.710+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:54.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:44:54.713+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:54.712+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:54.757+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:44:54.782+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:54.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:44:54.793+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:44:54.792+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:44:54.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-15T08:45:24.917+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:24.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:45:24.920+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:24.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:24.942+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:24.967+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:24.967+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:45:24.980+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:24.980+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:45:24.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T08:45:55.852+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:55.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:45:55.855+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:55.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:55.901+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:45:55.923+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:55.923+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:45:55.934+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:45:55.933+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:45:55.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-15T08:46:26.883+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:26.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:46:26.886+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:26.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:26.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:26.933+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:26.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:46:26.945+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:26.945+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:46:26.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T08:46:57.954+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:57.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:46:57.959+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:57.959+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:57.975+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:46:57.995+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:57.995+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:46:58.005+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:46:58.005+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:46:58.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T08:47:28.238+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:28.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:47:28.243+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:28.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:28.290+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:28.311+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:28.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:47:28.321+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:28.321+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:47:28.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.115 seconds
[2025-07-15T08:47:59.343+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:59.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:47:59.346+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:59.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:59.369+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:47:59.389+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:59.389+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:47:59.399+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:47:59.399+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:47:59.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T08:48:30.128+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:48:30.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:48:30.131+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:48:30.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:48:30.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:48:30.165+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:48:30.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:48:30.176+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:48:30.176+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:48:30.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T08:49:00.281+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:00.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:49:00.285+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:00.285+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:00.317+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:00.340+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:00.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:49:00.350+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:00.350+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:49:00.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T08:49:31.239+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:31.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:49:31.242+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:31.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:31.265+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:49:31.288+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:31.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:49:31.299+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:49:31.299+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:49:31.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:50:02.193+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:02.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:50:02.196+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:02.196+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:02.218+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:02.243+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:02.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:50:02.255+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:02.255+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:50:02.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T08:50:33.129+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:33.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:50:33.132+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:33.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:33.156+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:50:33.179+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:33.179+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:50:33.191+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:50:33.191+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:50:33.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T08:51:04.147+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:04.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:51:04.150+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:04.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:04.172+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:04.199+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:04.199+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:51:04.210+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:04.210+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:51:04.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T08:51:34.447+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:34.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:51:34.450+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:34.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:34.466+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:51:34.488+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:34.488+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:51:34.502+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:51:34.501+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:51:34.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T08:52:04.681+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:04.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:52:04.683+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:04.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:04.709+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:04.730+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:04.730+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:52:04.741+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:04.741+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:52:04.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T08:52:34.835+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:34.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:52:34.839+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:34.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:34.867+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:52:34.897+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:34.897+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:52:34.910+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:52:34.910+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:52:34.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-15T08:53:05.213+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:05.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:53:05.216+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:05.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:05.247+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:05.282+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:05.282+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:53:05.300+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:05.300+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:53:05.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-15T08:53:35.450+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:35.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:53:35.455+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:35.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:35.483+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:53:35.505+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:35.505+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:53:35.516+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:53:35.516+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:53:35.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T08:54:05.613+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:05.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:54:05.615+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:05.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:05.641+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:05.663+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:05.663+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:54:05.673+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:05.673+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:54:05.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:54:36.623+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:36.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:54:36.626+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:36.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:36.649+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:54:36.672+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:36.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:54:36.682+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:54:36.682+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:54:36.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T08:55:07.616+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:07.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:55:07.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:07.618+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:07.642+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:07.664+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:07.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:55:07.674+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:07.674+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:55:07.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T08:55:37.754+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:37.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:55:37.758+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:37.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:37.786+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:55:37.808+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:37.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:55:37.819+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:55:37.818+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:55:37.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T08:56:08.814+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:08.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:56:08.816+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:08.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:08.842+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:08.861+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:08.861+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:56:08.872+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:08.872+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:56:08.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T08:56:38.984+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:38.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:56:38.987+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:38.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:39.010+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:56:39.032+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:39.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:56:39.043+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:56:39.043+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:56:39.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:57:09.169+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:09.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:57:09.171+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:09.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:09.192+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:09.215+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:09.214+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:57:09.225+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:09.225+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:57:09.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T08:57:39.299+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:39.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:57:39.302+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:39.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:39.318+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:57:39.338+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:39.338+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:57:39.349+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:57:39.349+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:57:39.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T08:58:09.591+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:09.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:58:09.594+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:09.594+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:09.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:09.638+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:09.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:58:09.649+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:09.649+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:58:09.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T08:58:40.573+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:40.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:58:40.576+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:40.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:40.600+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:58:40.623+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:40.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:58:40.636+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:58:40.636+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:58:40.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T08:59:11.580+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:11.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:59:11.583+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:11.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:11.614+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:11.634+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:11.634+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:59:11.644+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:11.644+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:59:11.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T08:59:42.564+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:42.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T08:59:42.567+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:42.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:42.587+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T08:59:42.608+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:42.608+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T08:59:42.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T08:59:42.618+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T08:59:42.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T09:00:12.735+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:12.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:00:12.738+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:12.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:12.761+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:12.783+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:12.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:00:12.793+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:12.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:00:12.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T09:00:43.855+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:43.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:00:43.863+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:43.862+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:43.882+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:00:43.905+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:43.905+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:00:43.916+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:00:43.915+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:00:43.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T09:01:14.207+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:14.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:01:14.211+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:14.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:14.237+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:14.258+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:14.258+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:01:14.269+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:14.269+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:01:14.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T09:01:44.443+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:44.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:01:44.447+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:44.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:44.475+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:01:44.497+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:44.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:01:44.508+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:01:44.508+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:01:44.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T09:02:14.587+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:14.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:02:14.590+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:14.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:14.620+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:14.643+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:14.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:02:14.653+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:14.653+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:02:14.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:02:44.786+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:44.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:02:44.789+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:44.789+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:44.819+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:02:44.839+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:44.838+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:02:44.849+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:02:44.849+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:02:44.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:03:15.058+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:15.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:03:15.065+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:15.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:15.114+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:15.151+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:15.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:03:15.162+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:15.162+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:03:15.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.130 seconds
[2025-07-15T09:03:45.270+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:45.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:03:45.281+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:45.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:45.330+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:03:45.352+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:45.352+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:03:45.364+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:03:45.364+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:03:45.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.120 seconds
[2025-07-15T09:04:15.517+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:15.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:04:15.519+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:15.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:15.543+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:15.563+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:15.563+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:04:15.573+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:15.573+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:04:15.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T09:04:45.697+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:45.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:04:45.700+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:45.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:45.729+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:04:45.757+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:45.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:04:45.769+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:04:45.769+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:04:45.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T09:05:15.918+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:15.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:05:15.922+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:15.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:15.947+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:15.970+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:15.970+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:05:15.981+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:15.981+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:05:15.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T09:05:46.404+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:46.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:05:46.407+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:46.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:46.438+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:05:46.460+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:46.460+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:05:46.472+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:05:46.471+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:05:46.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:06:16.776+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:16.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:06:16.779+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:16.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:16.801+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:16.822+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:16.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:06:16.833+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:16.833+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:06:16.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T09:06:46.969+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:46.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:06:46.971+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:46.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:46.993+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:06:47.018+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:47.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:06:47.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:06:47.028+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:06:47.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:07:17.212+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:17.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:07:17.216+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:17.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:17.240+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:17.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:17.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:07:17.271+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:17.271+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:07:17.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T09:07:47.463+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:47.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:07:47.466+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:47.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:47.495+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:07:47.516+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:47.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:07:47.527+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:07:47.527+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:07:47.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:08:17.734+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:17.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:08:17.737+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:17.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:17.765+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:17.789+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:17.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:08:17.800+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:17.800+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:08:17.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T09:08:48.001+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:48.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:08:48.004+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:48.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:48.030+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:08:48.052+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:48.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:08:48.063+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:08:48.062+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:08:48.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T09:09:18.161+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:18.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:09:18.164+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:18.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:18.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:18.204+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:18.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:09:18.214+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:18.214+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:09:18.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T09:09:48.419+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:48.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:09:48.422+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:48.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:48.458+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:09:48.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:48.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:09:48.490+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:09:48.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:09:48.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T09:10:18.673+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:18.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:10:18.678+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:18.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:18.701+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:18.722+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:18.722+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:10:18.732+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:18.732+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:10:18.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T09:10:48.857+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:48.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:10:48.860+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:48.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:48.882+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:10:48.904+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:48.903+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:10:48.915+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:10:48.915+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:10:48.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T09:11:19.113+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:19.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:11:19.116+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:19.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:19.147+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:19.168+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:19.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:11:19.179+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:19.178+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:11:19.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T09:11:49.428+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:49.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:11:49.431+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:49.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:49.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:11:49.480+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:49.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:11:49.490+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:11:49.490+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:11:49.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T09:12:19.676+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:19.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:12:19.679+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:19.678+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:19.701+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:19.723+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:19.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:12:19.733+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:19.733+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:12:19.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T09:12:49.925+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:49.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:12:49.927+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:49.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:49.943+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:12:49.963+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:49.963+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:12:49.973+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:12:49.972+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:12:49.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T09:13:20.090+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:20.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:13:20.095+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:20.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:20.120+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:20.140+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:20.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:13:20.150+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:20.150+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:13:20.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T09:13:50.255+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:50.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:13:50.259+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:50.258+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:50.289+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:13:50.315+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:50.314+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:13:50.325+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:13:50.325+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:13:50.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T09:14:20.487+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:20.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:14:20.494+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:20.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:20.526+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:20.548+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:20.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:14:20.559+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:20.559+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:14:20.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T09:14:50.679+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:50.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:14:50.681+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:50.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:50.706+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:14:50.727+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:50.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:14:50.737+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:14:50.737+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:14:50.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:15:20.842+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:20.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:15:20.846+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:20.846+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:20.887+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:20.914+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:20.914+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:15:20.927+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:20.927+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:15:20.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-07-15T09:15:51.199+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:51.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:15:51.201+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:51.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:51.221+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:15:51.249+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:51.249+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:15:51.262+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:15:51.262+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:15:51.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:16:21.539+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:21.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:16:21.543+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:21.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:21.568+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:21.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:21.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:16:21.602+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:21.602+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:16:21.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:16:51.719+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:51.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:16:51.724+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:51.724+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:51.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:16:51.769+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:51.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:16:51.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:16:51.780+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:16:51.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:17:21.896+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:21.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:17:21.898+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:21.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:21.916+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:21.939+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:21.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:17:21.949+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:21.948+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:17:21.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T09:17:52.173+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:52.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:17:52.177+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:52.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:52.197+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:17:52.219+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:52.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:17:52.229+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:17:52.229+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:17:52.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T09:18:22.440+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:22.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:18:22.444+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:22.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:22.478+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:22.509+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:22.509+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:18:22.520+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:22.520+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:18:22.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-15T09:18:52.654+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:52.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:18:52.656+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:52.656+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:52.690+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:18:52.721+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:52.721+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:18:52.732+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:18:52.732+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:18:52.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-15T09:19:22.979+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:22.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:19:22.982+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:22.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:23.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:23.024+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:23.024+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:19:23.034+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:23.034+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:19:23.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T09:19:53.251+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:53.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:19:53.254+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:53.253+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:53.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:19:53.301+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:53.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:19:53.313+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:19:53.312+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:19:53.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:20:23.423+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:23.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:20:23.426+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:23.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:23.455+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:23.488+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:23.488+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:20:23.500+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:23.500+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:20:23.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-15T09:20:53.626+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:53.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:20:53.628+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:53.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:53.659+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:20:53.685+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:53.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:20:53.695+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:20:53.695+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:20:53.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T09:21:24.413+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:24.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:21:24.416+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:24.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:24.438+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:24.462+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:24.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:21:24.473+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:24.473+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:21:24.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T09:21:54.568+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:54.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:21:54.571+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:54.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:54.594+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:21:54.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:54.618+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:21:54.629+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:21:54.629+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:21:54.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T09:22:24.805+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:24.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:22:24.809+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:24.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:24.828+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:24.851+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:24.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:22:24.864+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:24.864+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:22:24.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:22:55.833+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:55.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:22:55.835+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:55.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:55.857+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:22:55.881+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:55.881+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:22:55.892+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:22:55.892+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:22:55.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:23:26.902+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:26.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:23:26.905+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:26.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:26.917+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:26.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:26.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:23:26.949+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:26.949+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:23:26.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T09:23:57.403+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:57.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:23:57.405+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:57.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:57.422+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:23:57.442+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:57.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:23:57.453+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:23:57.453+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:23:57.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T09:24:27.725+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:27.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:24:27.731+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:27.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:27.906+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:27.927+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:27.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:24:27.939+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:27.939+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:24:27.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.232 seconds
[2025-07-15T09:24:58.014+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:58.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:24:58.017+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:58.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:58.028+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:24:58.047+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:58.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:24:58.058+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:24:58.058+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:24:58.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.063 seconds
[2025-07-15T09:25:28.333+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:28.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:25:28.335+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:28.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:28.360+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:28.384+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:28.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:25:28.394+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:28.394+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:25:28.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T09:25:58.606+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:58.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:25:58.609+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:58.609+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:58.625+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:25:58.648+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:58.647+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:25:58.658+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:25:58.658+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:25:58.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T09:26:28.822+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:26:28.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:26:28.825+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:26:28.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:26:28.843+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:26:28.866+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:26:28.866+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:26:28.878+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:26:28.878+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:26:28.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T09:27:04.384+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:04.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:27:04.389+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:04.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:04.413+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:04.475+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:04.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:27:04.487+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:04.487+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:27:04.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.130 seconds
[2025-07-15T09:27:34.793+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:34.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:27:34.795+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:34.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:34.809+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:27:34.830+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:34.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:27:34.841+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:27:34.841+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:27:34.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T09:28:05.776+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:05.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:28:05.778+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:05.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:05.795+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:05.833+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:05.832+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:28:05.846+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:05.846+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:28:05.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:28:36.777+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:36.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:28:36.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:36.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:36.803+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:28:36.827+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:36.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:28:36.839+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:28:36.839+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:28:36.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:29:07.882+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:07.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:29:07.887+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:07.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:07.908+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:07.932+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:07.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:29:07.943+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:07.943+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:29:07.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:29:38.047+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:38.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:29:38.050+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:38.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:38.062+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:29:38.082+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:38.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:29:38.092+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:29:38.092+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:29:38.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-15T09:30:08.222+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:08.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:30:08.225+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:08.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:08.246+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:08.273+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:08.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:30:08.286+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:08.286+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:30:08.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T09:30:39.275+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:39.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:30:39.278+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:39.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:39.310+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:30:39.340+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:39.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:30:39.352+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:30:39.352+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:30:39.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-15T09:31:09.564+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:09.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:31:09.567+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:09.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:09.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:09.642+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:09.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:31:09.655+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:09.655+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:31:09.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.118 seconds
[2025-07-15T09:31:39.754+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:39.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:31:39.757+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:39.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:39.774+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:31:39.797+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:39.796+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:31:39.808+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:31:39.807+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:31:39.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T09:32:10.050+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:10.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:32:10.052+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:10.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:10.077+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:10.100+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:10.100+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:32:10.110+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:10.110+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:32:10.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T09:32:41.118+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:41.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:32:41.120+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:41.120+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:41.139+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:32:41.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:41.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:32:41.171+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:32:41.171+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:32:41.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T09:33:12.128+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:12.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:33:12.131+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:12.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:12.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:12.169+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:12.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:33:12.182+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:12.181+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:33:12.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T09:33:43.161+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:43.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:33:43.164+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:43.164+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:43.178+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:33:43.201+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:43.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:33:43.212+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:33:43.212+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:33:43.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T09:34:14.274+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:14.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:34:14.277+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:14.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:14.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:14.328+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:14.328+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:34:14.338+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:14.338+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:34:14.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:34:45.208+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:45.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:34:45.212+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:45.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:45.230+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:34:45.250+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:45.250+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:34:45.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:34:45.261+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:34:45.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T09:35:16.212+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:16.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:35:16.215+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:16.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:16.233+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:16.255+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:16.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:35:16.267+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:16.266+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:35:16.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:35:46.662+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:46.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:35:46.665+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:46.664+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:46.698+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:35:46.731+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:46.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:35:46.745+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:35:46.745+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:35:46.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-07-15T09:36:17.639+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:17.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:36:17.641+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:17.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:17.660+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:17.683+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:17.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:36:17.696+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:17.696+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:36:17.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T09:36:48.702+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:48.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:36:48.707+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:48.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:48.741+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:36:48.763+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:48.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:36:48.776+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:36:48.775+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:36:48.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-15T09:37:18.912+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:18.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:37:18.917+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:18.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:18.930+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:18.952+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:18.951+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:37:18.963+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:18.963+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:37:18.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T09:37:50.056+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:50.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:37:50.058+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:50.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:50.073+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:37:50.093+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:50.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:37:50.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:37:50.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:37:50.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T09:38:20.175+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:20.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:38:20.177+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:20.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:20.189+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:20.210+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:20.210+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:38:20.221+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:20.221+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:38:20.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-15T09:38:50.360+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:50.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:38:50.364+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:50.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:50.384+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:38:50.405+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:50.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:38:50.415+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:38:50.415+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:38:50.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T09:39:21.247+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:21.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:39:21.250+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:21.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:21.277+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:21.304+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:21.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:39:21.317+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:21.317+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:39:21.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T09:39:52.106+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:52.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:39:52.109+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:52.108+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:52.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:39:52.154+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:52.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:39:52.165+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:39:52.165+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:39:52.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:40:22.242+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:22.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:40:22.245+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:22.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:22.271+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:22.295+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:22.294+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:40:22.306+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:22.306+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:40:22.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:40:52.397+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:52.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:40:52.400+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:52.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:52.435+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:40:52.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:52.459+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:40:52.472+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:40:52.472+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:40:52.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-07-15T09:41:22.583+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:22.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:41:22.585+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:22.585+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:22.602+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:22.625+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:22.625+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:41:22.635+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:22.635+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:41:22.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T09:41:53.436+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:53.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:41:53.439+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:53.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:53.465+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:41:53.492+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:53.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:41:53.503+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:41:53.503+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:41:53.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:42:23.963+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:23.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:42:23.966+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:23.966+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:23.984+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:24.009+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:24.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:42:24.022+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:24.022+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:42:24.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:42:54.903+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:54.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:42:54.908+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:54.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:54.929+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:42:54.955+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:54.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:42:54.967+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:42:54.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:42:54.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:43:25.858+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:25.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:43:25.861+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:25.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:25.879+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:25.902+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:25.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:43:25.914+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:25.914+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:43:25.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T09:43:56.720+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:56.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:43:56.727+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:56.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:56.741+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:43:56.764+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:56.764+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:43:56.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:43:56.780+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:43:56.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T09:44:27.610+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:27.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:44:27.616+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:27.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:27.630+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:27.652+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:27.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:44:27.664+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:27.664+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:44:27.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T09:44:58.461+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:58.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:44:58.468+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:58.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:58.499+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:44:58.525+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:58.525+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:44:58.538+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:44:58.538+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:44:58.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-07-15T09:45:29.489+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:45:29.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:45:29.492+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:45:29.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:45:29.513+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:45:29.536+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:45:29.536+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:45:29.548+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:45:29.547+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:45:29.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:46:00.493+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:00.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:46:00.496+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:00.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:00.523+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:00.546+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:00.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:46:00.557+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:00.557+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:46:00.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T09:46:31.433+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:31.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:46:31.436+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:31.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:31.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:46:31.480+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:31.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:46:31.491+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:46:31.491+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:46:31.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T09:47:02.210+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:02.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:47:02.213+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:02.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:02.242+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:02.266+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:02.266+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:47:02.277+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:02.277+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:47:02.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T09:47:32.408+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:32.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:47:32.411+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:32.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:32.438+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:47:32.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:32.458+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:47:32.469+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:47:32.469+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:47:32.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T09:48:02.668+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:02.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:48:02.672+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:02.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:02.728+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:02.749+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:02.749+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:48:02.760+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:02.760+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:48:02.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.120 seconds
[2025-07-15T09:48:33.730+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:33.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:48:33.732+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:33.732+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:33.749+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:48:33.769+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:33.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:48:33.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:48:33.779+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:48:33.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T09:49:04.651+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:04.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:49:04.653+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:04.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:04.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:04.691+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:04.691+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:49:04.702+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:04.702+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:49:04.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T09:49:35.613+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:35.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:49:35.615+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:35.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:35.637+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:49:35.657+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:35.657+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:49:35.668+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:49:35.668+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:49:35.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T09:50:06.509+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:06.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:50:06.513+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:06.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:06.526+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:06.549+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:06.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:50:06.560+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:06.560+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:50:06.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T09:50:37.513+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:37.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:50:37.517+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:37.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:37.546+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:50:37.569+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:37.569+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:50:37.581+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:50:37.581+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:50:37.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T09:51:08.482+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:08.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:51:08.485+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:08.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:08.512+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:08.534+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:08.534+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:51:08.545+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:08.545+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:51:08.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:51:39.555+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:39.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:51:39.558+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:39.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:39.578+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:51:39.604+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:39.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:51:39.615+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:51:39.615+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:51:39.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:52:09.935+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:09.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:52:09.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:09.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:09.975+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:09.998+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:09.998+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:52:10.009+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:10.008+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:52:10.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T09:52:40.078+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:40.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:52:40.081+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:40.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:40.099+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:52:40.119+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:40.119+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:52:40.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:52:40.130+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:52:40.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T09:53:10.573+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:10.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:53:10.576+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:10.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:10.603+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:10.627+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:10.627+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:53:10.638+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:10.637+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:53:10.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:53:41.577+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:41.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:53:41.580+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:41.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:41.607+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:53:41.631+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:41.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:53:41.641+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:53:41.641+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:53:41.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T09:54:12.610+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:54:12.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:54:12.612+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:54:12.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:54:12.636+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:54:12.659+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:54:12.658+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:54:12.669+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:54:12.669+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:54:12.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T09:55:52.041+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:55:52.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:55:52.045+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:55:52.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:55:52.082+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:55:52.129+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:55:52.129+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:55:52.144+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:55:52.144+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:55:52.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.128 seconds
[2025-07-15T09:56:22.389+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:22.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:56:22.392+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:22.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:22.417+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:22.441+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:22.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:56:22.452+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:22.452+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:56:22.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T09:56:52.548+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:52.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:56:52.551+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:52.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:52.565+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:56:52.590+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:52.590+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:56:52.602+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:56:52.602+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:56:52.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T09:57:23.589+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:23.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:57:23.593+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:23.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:23.612+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:23.637+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:23.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:57:23.650+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:23.649+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:57:23.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T09:57:54.622+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:54.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:57:54.625+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:54.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:54.655+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:57:54.682+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:54.682+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:57:54.694+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:57:54.694+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:57:54.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T09:58:24.828+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:24.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:58:24.831+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:24.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:24.850+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:24.889+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:24.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:58:24.903+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:24.903+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:58:24.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T09:58:55.000+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:55.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:58:55.003+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:55.002+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:55.023+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:58:55.045+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:55.045+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:58:55.057+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:58:55.056+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:58:55.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T09:59:25.368+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:25.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:59:25.372+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:25.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:25.393+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:25.416+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:25.416+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:59:25.428+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:25.428+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:59:25.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T09:59:55.726+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:55.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T09:59:55.728+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:55.728+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:55.745+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T09:59:55.768+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:55.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T09:59:55.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T09:59:55.780+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T09:59:55.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:00:25.960+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:25.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:00:25.962+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:25.962+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:25.976+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:25.999+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:25.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:00:26.013+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:26.013+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:00:26.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T10:00:56.988+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:56.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:00:56.990+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:56.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:57.013+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:00:57.034+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:57.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:00:57.045+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:00:57.045+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:00:57.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T10:01:27.204+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:27.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:01:27.207+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:27.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:27.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:27.241+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:27.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:01:27.252+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:27.252+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:01:27.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:01:57.323+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:57.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:01:57.325+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:57.325+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:57.338+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:01:57.359+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:57.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:01:57.370+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:01:57.370+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:01:57.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:02:27.712+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:27.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:02:27.716+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:27.716+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:27.738+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:27.769+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:27.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:02:27.781+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:27.781+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:02:27.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-15T10:02:57.996+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:57.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:02:57.999+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:57.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:58.011+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:02:58.031+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:58.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:02:58.041+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:02:58.041+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:02:58.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.065 seconds
[2025-07-15T10:03:28.109+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:28.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:03:28.112+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:28.112+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:28.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:28.151+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:28.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:03:28.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:28.160+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:03:28.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T10:03:58.261+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:58.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:03:58.276+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:58.275+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:58.294+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:03:58.316+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:58.316+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:03:58.327+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:03:58.327+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:03:58.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T10:04:28.455+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:28.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:04:28.468+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:28.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:28.487+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:28.508+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:28.507+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:04:28.518+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:28.518+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:04:28.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T10:04:58.678+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:58.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:04:58.680+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:58.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:58.702+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:04:58.724+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:58.724+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:04:58.735+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:04:58.735+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:04:58.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:05:28.834+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:28.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:05:28.837+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:28.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:28.853+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:28.876+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:28.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:05:28.887+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:28.887+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:05:28.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:05:58.988+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:58.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:05:58.992+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:58.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:59.015+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:05:59.040+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:59.040+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:05:59.051+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:05:59.051+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:05:59.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T10:06:29.152+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:29.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:06:29.154+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:29.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:29.169+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:29.192+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:29.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:06:29.203+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:29.203+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:06:29.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:06:59.527+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:59.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:06:59.530+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:59.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:59.561+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:06:59.583+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:59.583+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:06:59.595+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:06:59.595+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:06:59.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T10:07:29.739+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:29.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:07:29.741+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:29.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:29.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:29.779+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:29.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:07:29.791+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:29.790+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:07:29.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:07:59.893+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:59.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:07:59.896+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:59.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:59.911+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:07:59.940+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:59.940+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:07:59.951+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:07:59.951+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:07:59.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T10:08:30.094+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:08:30.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:08:30.096+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:08:30.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:08:30.109+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:08:30.131+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:08:30.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:08:30.141+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:08:30.141+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:08:30.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:09:00.200+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:00.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:09:00.202+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:00.202+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:00.224+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:00.246+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:00.245+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:09:00.256+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:00.256+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:09:00.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T10:09:30.353+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:30.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:09:30.356+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:30.355+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:30.375+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:09:30.399+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:30.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:09:30.410+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:09:30.410+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:09:30.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T10:10:00.593+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:00.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:10:00.596+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:00.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:00.630+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:00.684+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:00.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:10:00.701+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:00.701+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:10:00.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.142 seconds
[2025-07-15T10:10:30.812+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:30.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:10:30.815+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:30.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:30.846+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:10:30.869+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:30.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:10:30.880+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:10:30.879+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:10:30.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T10:11:01.025+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:01.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:11:01.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:01.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:01.051+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:01.079+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:01.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:11:01.091+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:01.091+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:11:01.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:11:31.427+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:31.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:11:31.430+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:31.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:31.442+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:11:31.462+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:31.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:11:31.474+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:11:31.474+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:11:31.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:12:02.524+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:02.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:12:02.527+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:02.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:02.554+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:02.577+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:02.577+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:12:02.590+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:02.589+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:12:02.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T10:12:32.725+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:32.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:12:32.727+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:32.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:32.748+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:12:32.770+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:32.770+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:12:32.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:12:32.780+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:12:32.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T10:13:03.737+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:03.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:13:03.741+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:03.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:03.758+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:03.782+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:03.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:13:03.794+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:03.794+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:13:03.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:13:33.860+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:33.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:13:33.862+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:33.862+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:33.876+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:13:33.898+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:33.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:13:33.909+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:13:33.909+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:13:33.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T10:14:04.094+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:04.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:14:04.097+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:04.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:04.135+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:04.157+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:04.156+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:14:04.168+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:04.167+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:14:04.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:14:35.197+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:35.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:14:35.203+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:35.202+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:35.215+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:14:35.237+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:35.237+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:14:35.250+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:14:35.250+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:14:35.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:15:06.239+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:06.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:15:06.241+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:06.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:06.258+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:06.281+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:06.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:15:06.293+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:06.293+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:15:06.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T10:15:36.558+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:36.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:15:36.561+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:36.560+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:36.575+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:15:36.596+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:36.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:15:36.607+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:15:36.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:15:36.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T10:16:06.744+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:06.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:16:06.746+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:06.746+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:06.760+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:06.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:06.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:16:06.790+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:06.790+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:16:06.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T10:16:36.966+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:36.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:16:36.969+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:36.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:36.989+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:16:37.011+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:37.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:16:37.023+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:16:37.023+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:16:37.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T10:17:07.408+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:07.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:17:07.411+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:07.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:07.423+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:07.444+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:07.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:17:07.455+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:07.455+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:17:07.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:17:37.528+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:37.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:17:37.531+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:37.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:37.545+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:17:37.566+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:37.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:17:37.577+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:17:37.577+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:17:37.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T10:18:07.707+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:07.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:18:07.709+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:07.709+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:07.723+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:07.746+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:07.746+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:18:07.756+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:07.756+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:18:07.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:18:38.139+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:38.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:18:38.145+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:38.145+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:38.187+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:18:38.216+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:38.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:18:38.228+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:18:38.228+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:18:38.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.116 seconds
[2025-07-15T10:19:09.257+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:09.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:19:09.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:09.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:09.275+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:09.301+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:09.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:19:09.312+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:09.312+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:19:09.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:19:39.417+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:39.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:19:39.420+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:39.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:39.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:19:39.477+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:39.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:19:39.489+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:19:39.489+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:19:39.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-15T10:20:09.966+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:09.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:20:09.969+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:09.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:09.993+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:10.014+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:10.014+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:20:10.024+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:10.024+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:20:10.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:20:40.154+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:40.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:20:40.157+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:40.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:40.173+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:20:40.198+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:40.198+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:20:40.210+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:20:40.210+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:20:40.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T10:21:10.442+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:10.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:21:10.446+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:10.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:10.472+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:10.493+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:10.493+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:21:10.504+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:10.503+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:21:10.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T10:21:40.567+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:40.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:21:40.570+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:40.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:40.592+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:21:40.614+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:40.614+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:21:40.624+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:21:40.624+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:21:40.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:22:10.989+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:10.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:22:10.992+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:10.992+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:11.031+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:11.069+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:11.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:22:11.081+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:11.081+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:22:11.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-15T10:22:41.346+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:41.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:22:41.352+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:41.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:41.399+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:22:41.448+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:41.448+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:22:41.464+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:22:41.464+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:22:41.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.152 seconds
[2025-07-15T10:23:11.588+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:11.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:23:11.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:11.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:11.618+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:11.646+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:11.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:23:11.661+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:11.660+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:23:11.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-15T10:23:41.833+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:41.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:23:41.835+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:41.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:41.866+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:23:41.887+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:41.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:23:41.899+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:23:41.899+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:23:41.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T10:24:11.970+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:11.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:24:11.973+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:11.972+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:11.985+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:12.006+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:12.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:24:12.017+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:12.017+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:24:12.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T10:24:42.431+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:42.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:24:42.434+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:42.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:42.468+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:24:42.495+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:42.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:24:42.507+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:24:42.507+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:24:42.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-07-15T10:25:12.609+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:12.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:25:12.612+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:12.611+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:12.630+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:12.651+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:12.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:25:12.661+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:12.661+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:25:12.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:25:42.778+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:42.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:25:42.781+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:42.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:42.796+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:25:42.816+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:42.815+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:25:42.826+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:25:42.826+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:25:42.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:26:13.282+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:13.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:26:13.284+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:13.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:13.296+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:13.318+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:13.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:26:13.329+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:13.329+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:26:13.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T10:26:43.427+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:43.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:26:43.430+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:43.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:43.448+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:26:43.468+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:43.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:26:43.481+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:26:43.481+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:26:43.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:27:13.830+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:13.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:27:13.835+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:13.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:13.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:13.932+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:13.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:27:13.943+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:13.943+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:27:13.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.136 seconds
[2025-07-15T10:27:44.235+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:44.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:27:44.237+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:44.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:44.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:27:44.276+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:44.276+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:27:44.287+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:27:44.286+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:27:44.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T10:28:15.296+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:15.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:28:15.301+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:15.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:15.334+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:15.356+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:15.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:28:15.366+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:15.366+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:28:15.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-15T10:28:45.702+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:45.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:28:45.704+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:45.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:45.728+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:28:45.750+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:45.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:28:45.762+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:28:45.762+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:28:45.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:29:15.893+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:15.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:29:15.897+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:15.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:15.918+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:15.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:15.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:29:15.947+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:15.947+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:29:15.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:29:46.800+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:46.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:29:46.802+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:46.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:46.817+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:29:46.838+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:46.838+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:29:46.848+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:29:46.848+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:29:46.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T10:30:16.954+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:16.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:30:16.956+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:16.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:16.968+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:16.990+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:16.990+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:30:17.001+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:17.001+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:30:17.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:30:47.961+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:47.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:30:47.963+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:47.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:47.979+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:30:48.000+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:48.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:30:48.011+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:30:48.011+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:30:48.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:31:18.374+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:18.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:31:18.379+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:18.379+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:18.424+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:18.447+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:18.447+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:31:18.460+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:18.460+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:31:18.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-07-15T10:31:49.512+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:49.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:31:49.516+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:49.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:49.577+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:31:49.599+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:49.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:31:49.609+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:31:49.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:31:49.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.122 seconds
[2025-07-15T10:32:19.683+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:19.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:32:19.685+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:19.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:19.700+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:19.725+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:19.725+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:32:19.738+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:19.737+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:32:19.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:32:50.093+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:50.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:32:50.099+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:50.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:50.120+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:32:50.142+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:50.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:32:50.152+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:32:50.152+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:32:50.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T10:33:21.059+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:21.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:33:21.062+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:21.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:21.083+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:21.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:21.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:33:21.113+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:21.113+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:33:21.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:33:52.083+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:52.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:33:52.085+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:52.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:52.102+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:33:52.128+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:52.128+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:33:52.139+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:33:52.139+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:33:52.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:34:22.982+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:22.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:34:22.984+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:22.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:23.001+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:23.021+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:23.021+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:34:23.031+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:23.031+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:34:23.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:34:53.979+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:53.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:34:53.982+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:53.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:54.007+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:34:54.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:54.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:34:54.039+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:34:54.039+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:34:54.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T10:35:24.333+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:24.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:35:24.337+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:24.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:24.375+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:24.398+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:24.398+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:35:24.408+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:24.408+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:35:24.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T10:35:54.639+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:54.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:35:54.643+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:54.643+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:54.776+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:35:54.801+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:54.801+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:35:54.813+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:35:54.813+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:35:54.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.209 seconds
[2025-07-15T10:36:25.114+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:25.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:36:25.116+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:25.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:25.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:25.152+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:25.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:36:25.163+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:25.162+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:36:25.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:36:56.217+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:56.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:36:56.220+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:56.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:56.243+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:36:56.266+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:56.266+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:36:56.276+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:36:56.276+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:36:56.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:37:26.440+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:26.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:37:26.443+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:26.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:26.468+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:26.489+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:26.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:37:26.499+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:26.499+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:37:26.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T10:37:57.529+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:57.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:37:57.531+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:57.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:57.565+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:37:57.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:57.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:37:57.601+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:37:57.601+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:37:57.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T10:38:27.719+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:27.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:38:27.722+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:27.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:27.737+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:27.761+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:27.761+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:38:27.772+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:27.772+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:38:27.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:38:58.887+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:58.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:38:58.889+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:58.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:58.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:38:58.937+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:58.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:38:58.948+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:38:58.948+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:38:58.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T10:39:29.008+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:29.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:39:29.011+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:29.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:29.030+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:29.053+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:29.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:39:29.063+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:29.063+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:39:29.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:39:59.341+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:59.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:39:59.344+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:59.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:59.362+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:39:59.384+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:59.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:39:59.396+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:39:59.396+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:39:59.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:40:30.411+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:40:30.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:40:30.413+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:40:30.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:40:30.432+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:40:30.452+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:40:30.452+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:40:30.463+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:40:30.462+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:40:30.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T10:41:01.415+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:01.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:41:01.417+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:01.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:01.456+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:01.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:01.479+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:41:01.489+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:01.489+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:41:01.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T10:41:31.570+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:31.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:41:31.572+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:31.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:31.587+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:41:31.609+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:31.608+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:41:31.622+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:41:31.622+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:41:31.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T10:42:02.028+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:02.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:42:02.031+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:02.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:02.052+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:02.074+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:02.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:42:02.085+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:02.084+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:42:02.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:42:32.272+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:32.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:42:32.275+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:32.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:32.310+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:42:32.332+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:32.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:42:32.342+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:42:32.342+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:42:32.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:43:02.648+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:02.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:43:02.651+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:02.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:02.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:02.691+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:02.691+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:43:02.702+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:02.702+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:43:02.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:43:32.800+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:32.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:43:32.803+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:32.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:32.820+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:43:32.842+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:32.841+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:43:32.853+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:43:32.852+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:43:32.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T10:44:03.828+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:03.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:44:03.833+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:03.833+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:03.851+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:03.873+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:03.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:44:03.883+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:03.883+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:44:03.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T10:44:34.054+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:34.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:44:34.056+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:34.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:34.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:44:34.090+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:34.090+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:44:34.100+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:44:34.100+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:44:34.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T10:45:04.159+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:04.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:45:04.163+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:04.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:04.176+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:04.197+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:04.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:45:04.207+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:04.207+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:45:04.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T10:45:34.291+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:34.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:45:34.296+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:34.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:34.448+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:45:34.472+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:34.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:45:34.484+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:45:34.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:45:34.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.229 seconds
[2025-07-15T10:46:04.791+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:04.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:46:04.793+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:04.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:04.814+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:04.837+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:04.837+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:46:04.847+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:04.847+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:46:04.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:46:34.950+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:34.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:46:34.953+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:34.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:34.975+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:46:34.998+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:34.998+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:46:35.009+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:46:35.009+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:46:35.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T10:47:05.182+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:05.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:47:05.184+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:05.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:05.201+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:05.222+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:05.222+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:47:05.232+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:05.232+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:47:05.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T10:47:36.236+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:36.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:47:36.238+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:36.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:36.257+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:47:36.279+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:36.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:47:36.290+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:47:36.290+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:47:36.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T10:48:06.592+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:06.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:48:06.595+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:06.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:06.618+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:06.639+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:06.639+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:48:06.650+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:06.650+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:48:06.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:48:37.660+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:37.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:48:37.662+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:37.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:37.680+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:48:37.703+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:37.702+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:48:37.714+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:48:37.714+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:48:37.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:49:08.624+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:08.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:49:08.627+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:08.627+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:08.659+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:08.682+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:08.682+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:49:08.696+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:08.695+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:49:08.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T10:49:38.784+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:38.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:49:38.787+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:38.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:38.815+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:49:38.837+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:38.836+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:49:38.847+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:49:38.847+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:49:38.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T10:50:09.085+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:09.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:50:09.088+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:09.088+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:09.119+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:09.142+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:09.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:50:09.152+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:09.152+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:50:09.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T10:50:39.271+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:39.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:50:39.273+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:39.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:39.298+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:50:39.319+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:39.319+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:50:39.330+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:50:39.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:50:39.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T10:51:09.567+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:09.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:51:09.570+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:09.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:09.594+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:09.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:09.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:51:09.629+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:09.629+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:51:09.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T10:51:39.812+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:39.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:51:39.815+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:39.815+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:39.847+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:51:39.871+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:39.871+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:51:39.885+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:51:39.885+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:51:39.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:52:09.977+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:09.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:52:09.980+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:09.980+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:09.996+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:10.020+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:10.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:52:10.030+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:10.030+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:52:10.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T10:52:40.935+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:40.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:52:40.937+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:40.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:40.953+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:52:40.973+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:40.973+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:52:40.983+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:52:40.983+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:52:40.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T10:53:12.036+0000] {processor.py:161} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:12.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:53:12.038+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:12.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:12.070+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:12.092+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:12.092+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:53:12.103+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:12.103+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:53:12.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T10:53:42.280+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:42.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:53:42.283+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:42.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:42.305+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:53:42.327+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:42.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:53:42.337+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:53:42.337+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:53:42.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T10:54:12.481+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:12.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:54:12.484+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:12.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:12.510+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:12.531+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:12.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:54:12.544+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:12.543+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:54:12.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T10:54:42.823+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:42.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:54:42.826+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:42.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:42.838+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:54:42.862+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:42.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:54:42.873+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:54:42.873+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:54:42.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T10:55:12.974+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:12.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:55:12.978+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:12.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:13.011+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:13.032+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:13.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:55:13.043+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:13.043+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:55:13.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:55:44.097+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:44.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:55:44.100+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:44.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:44.113+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:55:44.135+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:44.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:55:44.146+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:55:44.146+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:55:44.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T10:56:14.276+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:14.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:56:14.280+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:14.279+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:14.319+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:14.342+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:14.341+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:56:14.351+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:14.351+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:56:14.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T10:56:44.477+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:44.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:56:44.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:44.479+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:44.500+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:56:44.521+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:44.521+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:56:44.531+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:56:44.531+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:56:44.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T10:57:14.586+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:14.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:57:14.589+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:14.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:14.605+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:14.626+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:14.626+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:57:14.636+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:14.636+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:57:14.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T10:57:45.100+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:45.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:57:45.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:45.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:45.125+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:57:45.147+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:45.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:57:45.158+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:57:45.158+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:57:45.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T10:58:15.213+0000] {processor.py:161} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:15.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:58:15.217+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:15.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:15.246+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:15.268+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:15.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:58:15.280+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:15.280+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:58:15.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T10:58:45.663+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:45.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:58:45.666+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:45.666+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:45.692+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:58:45.715+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:45.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:58:45.725+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:58:45.725+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:58:45.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T10:59:15.933+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:15.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:59:15.939+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:15.938+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:15.954+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:15.974+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:15.974+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:59:15.985+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:15.984+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:59:16.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T10:59:46.229+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:46.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T10:59:46.233+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:46.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:46.245+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T10:59:46.269+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:46.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T10:59:46.281+0000] {logging_mixin.py:188} INFO - [2025-07-15T10:59:46.281+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T10:59:46.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:00:16.378+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:16.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:00:16.381+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:16.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:16.409+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:16.433+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:16.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:00:16.446+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:16.446+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:00:16.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T11:00:46.511+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:46.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:00:46.513+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:46.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:46.525+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:00:46.548+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:46.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:00:46.560+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:00:46.560+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:00:46.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T11:01:17.558+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:17.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:01:17.560+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:17.560+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:17.576+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:17.596+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:17.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:01:17.607+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:17.607+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:01:17.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T11:01:48.019+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:48.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:01:48.023+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:48.023+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:48.105+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:01:48.129+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:48.129+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:01:48.140+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:01:48.140+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:01:48.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.157 seconds
[2025-07-15T11:02:18.275+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:18.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:02:18.278+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:18.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:18.303+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:18.325+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:18.325+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:02:18.336+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:18.335+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:02:18.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T11:02:49.272+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:49.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:02:49.274+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:49.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:49.289+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:02:49.312+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:49.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:02:49.324+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:02:49.324+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:02:49.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:03:19.589+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:19.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:03:19.595+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:19.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:19.614+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:19.639+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:19.639+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:03:19.650+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:19.650+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:03:19.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T11:03:50.712+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:50.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:03:50.716+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:50.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:50.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:03:50.769+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:50.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:03:50.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:03:50.780+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:03:50.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T11:04:21.091+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:21.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:04:21.094+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:21.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:21.115+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:21.137+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:21.137+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:04:21.152+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:21.152+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:04:21.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T11:04:51.217+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:51.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:04:51.219+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:51.219+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:51.233+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:04:51.257+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:51.257+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:04:51.268+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:04:51.268+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:04:51.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:05:21.380+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:21.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:05:21.383+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:21.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:21.407+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:21.429+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:21.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:05:21.441+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:21.441+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:05:21.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T11:05:51.640+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:51.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:05:51.644+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:51.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:51.670+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:05:51.693+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:51.692+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:05:51.704+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:05:51.703+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:05:51.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T11:06:22.040+0000] {processor.py:161} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:22.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:06:22.042+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:22.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:22.055+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:22.082+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:22.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:06:22.093+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:22.093+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:06:22.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:06:52.242+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:52.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:06:52.245+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:52.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:52.263+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:06:52.287+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:52.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:06:52.298+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:06:52.298+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:06:52.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T11:07:22.461+0000] {processor.py:161} INFO - Started process (PID=1029) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:22.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:07:22.464+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:22.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:22.478+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:22.498+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:22.498+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:07:22.509+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:22.509+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:07:22.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T11:07:52.686+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:52.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:07:52.690+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:52.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:52.729+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:07:52.777+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:52.777+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:07:52.790+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:07:52.790+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:07:52.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.129 seconds
[2025-07-15T11:08:23.136+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:23.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:08:23.141+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:23.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:23.174+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:23.197+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:23.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:08:23.208+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:23.208+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:08:23.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T11:08:53.380+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:53.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:08:53.382+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:53.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:53.402+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:08:53.427+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:53.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:08:53.438+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:08:53.438+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:08:53.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T11:09:24.450+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:24.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:09:24.453+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:24.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:24.477+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:24.501+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:24.500+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:09:24.518+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:24.518+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:09:24.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T11:09:54.772+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:54.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:09:54.774+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:54.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:54.788+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:09:54.810+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:54.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:09:54.821+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:09:54.821+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:09:54.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T11:10:24.989+0000] {processor.py:161} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:24.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:10:24.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:24.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:25.008+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:25.029+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:25.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:10:25.040+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:25.040+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:10:25.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T11:10:55.278+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:55.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:10:55.281+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:55.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:55.304+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:10:55.326+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:55.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:10:55.336+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:10:55.336+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:10:55.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T11:11:25.452+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:25.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:11:25.455+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:25.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:25.475+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:25.495+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:25.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:11:25.506+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:25.506+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:11:25.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T11:11:55.747+0000] {processor.py:161} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:55.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:11:55.750+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:55.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:55.773+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:11:55.795+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:55.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:11:55.806+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:11:55.806+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:11:55.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T11:12:25.964+0000] {processor.py:161} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:25.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:12:25.966+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:25.966+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:25.985+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:26.006+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:26.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:12:26.017+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:26.017+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:12:26.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T11:12:56.360+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:56.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:12:56.362+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:56.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:56.380+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:12:56.402+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:56.402+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:12:56.413+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:12:56.413+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:12:56.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:13:27.358+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:27.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:13:27.361+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:27.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:27.375+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:27.396+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:27.396+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:13:27.409+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:27.409+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:13:27.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:13:57.469+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:57.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:13:57.472+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:57.472+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:57.500+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:13:57.522+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:57.522+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:13:57.533+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:13:57.533+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:13:57.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T11:14:27.657+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:27.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:14:27.660+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:27.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:27.674+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:27.694+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:27.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:14:27.705+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:27.704+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:14:27.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T11:14:57.793+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:57.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:14:57.796+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:57.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:57.811+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:14:57.832+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:57.832+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:14:57.843+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:14:57.843+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:14:57.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:15:27.990+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:27.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:15:27.993+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:27.992+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:28.005+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:28.026+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:28.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:15:28.038+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:28.038+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:15:28.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T11:15:58.164+0000] {processor.py:161} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:58.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:15:58.167+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:58.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:58.194+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:15:58.226+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:58.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:15:58.237+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:15:58.237+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:15:58.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-15T11:16:28.657+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:28.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:16:28.660+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:28.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:28.705+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:28.728+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:28.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:16:28.740+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:28.739+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:16:28.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-15T11:16:59.642+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:59.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:16:59.644+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:59.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:59.668+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:16:59.689+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:59.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:16:59.701+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:16:59.701+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:16:59.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T11:17:29.860+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:17:29.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:17:29.862+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:17:29.862+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:17:29.876+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:17:29.896+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:17:29.896+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:17:29.907+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:17:29.907+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:17:29.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T11:18:00.036+0000] {processor.py:161} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:00.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:18:00.040+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:00.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:00.069+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:00.095+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:00.095+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:18:00.109+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:00.108+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:18:00.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T11:18:30.394+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:30.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:18:30.397+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:30.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:30.421+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:18:30.446+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:30.446+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:18:30.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:18:30.459+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:18:30.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T11:19:01.451+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:01.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:19:01.453+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:01.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:01.469+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:01.489+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:01.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:19:01.499+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:01.499+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:19:01.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T11:19:31.939+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:31.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:19:31.941+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:31.941+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:31.962+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:19:31.983+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:31.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:19:31.994+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:19:31.994+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:19:32.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T11:20:02.114+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:02.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:20:02.117+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:02.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:02.132+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:02.152+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:02.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:20:02.163+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:02.163+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:20:02.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T11:20:32.397+0000] {processor.py:161} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:32.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:20:32.400+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:32.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:32.416+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:20:32.437+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:32.437+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:20:32.447+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:20:32.447+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:20:32.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T11:21:02.686+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:02.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:21:02.688+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:02.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:02.704+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:02.725+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:02.725+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:21:02.736+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:02.736+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:21:02.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:21:32.888+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:32.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:21:32.892+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:32.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:32.909+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:21:32.930+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:32.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:21:32.941+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:21:32.941+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:21:32.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T11:22:03.109+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:03.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:22:03.111+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:03.111+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:03.137+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:03.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:03.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:22:03.174+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:03.174+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:22:03.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T11:22:33.440+0000] {processor.py:161} INFO - Started process (PID=1238) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:33.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:22:33.447+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:33.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:33.488+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:22:33.522+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:33.522+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:22:33.537+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:22:33.537+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:22:33.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.126 seconds
[2025-07-15T11:23:03.684+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:03.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:23:03.688+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:03.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:03.718+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:03.739+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:03.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:23:03.750+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:03.749+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:23:03.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T11:23:33.865+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:33.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:23:33.868+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:33.867+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:33.898+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:23:33.921+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:33.921+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:23:33.932+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:23:33.931+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:23:33.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T11:24:04.961+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:04.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:24:04.963+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:04.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:04.977+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:04.999+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:04.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:24:05.010+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:05.009+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:24:05.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T11:24:35.080+0000] {processor.py:161} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:35.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:24:35.082+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:35.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:35.095+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:24:35.117+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:35.117+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:24:35.129+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:24:35.129+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:24:35.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:25:05.265+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:05.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:25:05.268+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:05.268+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:05.287+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:05.308+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:05.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:25:05.320+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:05.320+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:25:05.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:25:36.459+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:36.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:25:36.462+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:36.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:36.493+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:25:36.515+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:36.515+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:25:36.525+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:25:36.525+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:25:36.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T11:26:06.740+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:06.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:26:06.742+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:06.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:06.758+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:06.778+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:06.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:26:06.790+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:06.789+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:26:06.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T11:26:36.913+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:36.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:26:36.915+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:36.915+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:36.930+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:26:36.951+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:36.951+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:26:36.961+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:26:36.961+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:26:36.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T11:27:07.447+0000] {processor.py:161} INFO - Started process (PID=1301) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:07.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:27:07.450+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:07.449+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:07.470+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:07.493+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:07.493+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:27:07.504+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:07.504+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:27:07.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T11:27:37.581+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:37.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:27:37.584+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:37.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:37.611+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:27:37.634+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:37.633+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:27:37.644+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:27:37.644+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:27:37.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T11:28:07.871+0000] {processor.py:161} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:07.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:28:07.874+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:07.874+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:07.896+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:07.919+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:07.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:28:07.929+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:07.929+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:28:07.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T11:28:38.097+0000] {processor.py:161} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:38.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:28:38.100+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:38.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:38.115+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:28:38.134+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:38.134+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:28:38.145+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:28:38.145+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:28:38.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:29:09.054+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:09.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:29:09.062+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:09.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:09.077+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:09.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:09.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:29:09.115+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:09.115+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:29:09.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T11:29:39.942+0000] {processor.py:161} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:39.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:29:39.946+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:39.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:39.962+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:29:39.984+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:39.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:29:39.995+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:29:39.995+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:29:40.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T11:30:11.047+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:11.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:30:11.050+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:11.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:11.068+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:11.093+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:11.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:30:11.105+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:11.105+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:30:11.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T11:30:41.545+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:41.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:30:41.547+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:41.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:41.566+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:30:41.587+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:41.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:30:41.600+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:30:41.600+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:30:41.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T11:31:11.899+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:11.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:31:11.902+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:11.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:11.931+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:11.953+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:11.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:31:11.964+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:11.964+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:31:11.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T11:31:43.047+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:43.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:31:43.051+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:43.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:43.069+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:31:43.089+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:43.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:31:43.101+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:31:43.101+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:31:43.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:32:13.233+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:13.235+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:32:13.237+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:13.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:13.257+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:13.279+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:13.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:32:13.291+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:13.291+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:32:13.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T11:32:43.427+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:43.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:32:43.431+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:43.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:43.445+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:32:43.467+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:43.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:32:43.479+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:32:43.479+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:32:43.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T11:33:14.441+0000] {processor.py:161} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:14.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:33:14.444+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:14.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:14.457+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:14.478+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:14.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:33:14.488+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:14.488+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:33:14.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T11:33:45.398+0000] {processor.py:161} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:45.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:33:45.400+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:45.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:45.425+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:33:45.448+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:45.448+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:33:45.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:33:45.459+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:33:45.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T11:34:16.416+0000] {processor.py:161} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:16.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:34:16.419+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:16.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:16.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:16.473+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:16.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:34:16.484+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:16.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:34:16.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T11:34:46.651+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:46.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:34:46.653+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:46.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:46.672+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:34:46.693+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:46.693+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:34:46.703+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:34:46.703+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:34:46.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T11:35:17.854+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:17.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:35:17.860+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:17.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:17.991+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:18.016+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:18.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:35:18.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:18.028+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:35:18.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.206 seconds
[2025-07-15T11:35:48.444+0000] {processor.py:161} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:48.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:35:48.446+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:48.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:48.465+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:35:48.486+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:48.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:35:48.496+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:35:48.496+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:35:48.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T11:36:18.611+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:18.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:36:18.614+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:18.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:18.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:18.647+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:18.647+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:36:18.657+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:18.657+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:36:18.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T11:36:49.237+0000] {processor.py:161} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:49.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:36:49.240+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:49.240+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:49.254+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:36:49.276+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:49.276+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:36:49.288+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:36:49.287+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:36:49.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:37:20.229+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:20.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:37:20.231+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:20.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:20.245+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:20.266+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:20.266+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:37:20.277+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:20.276+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:37:20.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T11:37:51.197+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:51.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:37:51.204+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:51.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:51.227+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:37:51.252+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:51.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:37:51.264+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:37:51.264+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:37:51.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T11:38:21.354+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:21.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:38:21.357+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:21.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:21.381+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:21.403+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:21.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:38:21.414+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:21.414+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:38:21.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T11:38:51.858+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:51.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:38:51.864+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:51.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:51.962+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:38:51.988+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:51.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:38:52.014+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:38:52.014+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:38:52.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.178 seconds
[2025-07-15T11:39:23.000+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:23.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:39:23.003+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:23.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:23.016+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:23.039+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:23.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:39:23.051+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:23.051+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:39:23.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T11:39:53.147+0000] {processor.py:161} INFO - Started process (PID=1476) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:53.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:39:53.150+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:53.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:53.170+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:39:53.197+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:53.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:39:53.216+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:39:53.216+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:39:53.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T11:40:23.328+0000] {processor.py:161} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:23.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:40:23.332+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:23.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:23.345+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:23.365+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:23.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:40:23.375+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:23.374+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:40:23.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T11:40:53.607+0000] {processor.py:161} INFO - Started process (PID=1490) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:53.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:40:53.610+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:53.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:53.639+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:40:53.660+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:53.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:40:53.671+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:40:53.671+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:40:53.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T11:41:23.925+0000] {processor.py:161} INFO - Started process (PID=1497) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:23.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:41:23.928+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:23.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:23.951+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:23.972+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:23.972+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:41:23.983+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:23.983+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:41:24.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T11:41:54.245+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:54.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:41:54.249+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:54.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:54.275+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:41:54.296+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:54.296+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:41:54.307+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:41:54.307+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:41:54.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T11:42:24.437+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:24.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:42:24.439+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:24.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:24.454+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:24.475+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:24.475+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:42:24.485+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:24.485+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:42:24.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T11:42:54.596+0000] {processor.py:161} INFO - Started process (PID=1518) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:54.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:42:54.598+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:54.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:54.617+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:42:54.639+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:54.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:42:54.649+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:42:54.649+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:42:54.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:43:24.772+0000] {processor.py:161} INFO - Started process (PID=1525) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:24.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:43:24.776+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:24.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:24.807+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:24.832+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:24.831+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:43:24.843+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:24.843+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:43:24.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T11:43:55.185+0000] {processor.py:161} INFO - Started process (PID=1532) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:55.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:43:55.189+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:55.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:55.336+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:43:55.369+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:55.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:43:55.381+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:43:55.380+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:43:55.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.225 seconds
[2025-07-15T11:44:26.025+0000] {processor.py:161} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:26.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:44:26.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:26.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:26.040+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:26.062+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:26.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:44:26.073+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:26.072+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:44:26.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T11:44:56.177+0000] {processor.py:161} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:56.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:44:56.180+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:56.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:56.194+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:44:56.215+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:56.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:44:56.226+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:44:56.226+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:44:56.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T11:46:06.808+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:06.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:46:06.814+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:06.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:06.848+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:06.901+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:06.900+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:46:06.919+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:06.918+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:46:06.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.140 seconds
[2025-07-15T11:46:37.051+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:37.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:46:37.053+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:37.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:37.065+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:46:37.087+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:37.087+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:46:37.098+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:46:37.098+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:46:37.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:47:08.319+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:08.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:47:08.326+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:08.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:08.448+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:08.474+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:08.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:47:08.488+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:08.488+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:47:08.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.203 seconds
[2025-07-15T11:47:39.076+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:39.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:47:39.079+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:39.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:39.099+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:47:39.125+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:39.125+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:47:39.138+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:47:39.138+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:47:39.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T11:48:10.145+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:10.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:48:10.148+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:10.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:10.162+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:10.187+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:10.187+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:48:10.198+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:10.198+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:48:10.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:48:40.252+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:40.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:48:40.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:40.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:40.278+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:48:40.298+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:40.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:48:40.308+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:48:40.308+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:48:40.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:49:10.472+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:10.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:49:10.476+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:10.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:10.499+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:10.523+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:10.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:49:10.534+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:10.534+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:49:10.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T11:49:40.583+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:40.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:49:40.585+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:40.585+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:40.597+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:49:40.617+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:40.616+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:49:40.627+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:49:40.626+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:49:40.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-15T11:50:10.836+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:10.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:50:10.838+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:10.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:10.857+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:10.882+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:10.882+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:50:10.895+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:10.895+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:50:10.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T11:50:40.965+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:40.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:50:40.968+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:40.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:40.984+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:50:41.006+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:41.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:50:41.019+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:50:41.019+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:50:41.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T11:51:11.082+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:11.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:51:11.085+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:11.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:11.101+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:11.121+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:11.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:51:11.132+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:11.132+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:51:11.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:51:42.177+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:42.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:51:42.181+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:42.181+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:42.212+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:51:42.233+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:42.233+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:51:42.244+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:51:42.243+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:51:42.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T11:52:13.231+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:13.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:52:13.234+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:13.233+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:13.250+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:13.273+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:13.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:52:13.285+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:13.285+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:52:13.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T11:52:44.071+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:44.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:52:44.073+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:44.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:44.088+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:52:44.109+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:44.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:52:44.120+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:52:44.120+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:52:44.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:53:14.886+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:14.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:53:14.890+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:14.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:14.922+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:14.945+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:14.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:53:14.956+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:14.956+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:53:14.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T11:53:45.852+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:45.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:53:45.856+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:45.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:45.879+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:53:45.907+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:45.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:53:45.920+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:53:45.920+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:53:45.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T11:54:16.917+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:16.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:54:16.920+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:16.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:16.934+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:16.954+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:16.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:54:16.965+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:16.965+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:54:16.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T11:54:47.067+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:47.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:54:47.069+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:47.069+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:47.085+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:54:47.107+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:47.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:54:47.119+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:54:47.119+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:54:47.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T11:55:17.545+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:17.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:55:17.548+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:17.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:17.569+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:17.593+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:17.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:55:17.609+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:17.609+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:55:17.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T11:55:48.697+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:48.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:55:48.704+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:48.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:48.775+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:55:48.806+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:48.805+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:55:48.820+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:55:48.819+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:55:48.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.150 seconds
[2025-07-15T11:56:18.935+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:18.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:56:18.937+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:18.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:18.952+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:18.973+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:18.973+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:56:18.985+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:18.984+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:56:19.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T11:56:49.696+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:49.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:56:49.701+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:49.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:49.728+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:56:49.753+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:49.752+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:56:49.765+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:56:49.764+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:56:49.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-15T11:57:20.532+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:20.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:57:20.535+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:20.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:20.556+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:20.587+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:20.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:57:20.601+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:20.601+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:57:20.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-15T11:57:51.211+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:51.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:57:51.217+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:51.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:51.249+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:57:51.280+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:51.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:57:51.293+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:57:51.293+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:57:51.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-07-15T11:58:21.973+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:21.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:58:21.977+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:21.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:22.002+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:22.028+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:22.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:58:22.042+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:22.042+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:58:22.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T11:58:52.756+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:52.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:58:52.759+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:52.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:52.782+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:58:52.810+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:52.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:58:52.823+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:58:52.823+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:58:52.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T11:59:22.935+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:22.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:59:22.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:22.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:22.964+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:22.988+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:22.987+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:59:22.999+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:22.998+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:59:23.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T11:59:53.946+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:53.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T11:59:53.949+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:53.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:53.968+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T11:59:53.993+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:53.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T11:59:54.005+0000] {logging_mixin.py:188} INFO - [2025-07-15T11:59:54.005+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T11:59:54.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T12:00:24.093+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:24.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:00:24.095+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:24.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:24.108+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:24.129+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:24.129+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:00:24.140+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:24.140+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:00:24.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T12:00:54.245+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:54.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:00:54.248+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:54.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:54.269+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:00:54.298+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:54.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:00:54.311+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:00:54.311+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:00:54.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T12:01:24.369+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:24.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:01:24.371+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:24.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:24.391+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:24.414+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:24.414+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:01:24.426+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:24.426+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:01:24.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T12:01:55.056+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:55.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:01:55.059+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:55.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:55.078+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:01:55.099+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:55.099+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:01:55.109+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:01:55.109+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:01:55.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T12:02:25.217+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:25.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:02:25.220+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:25.219+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:25.235+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:25.256+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:25.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:02:25.272+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:25.272+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:02:25.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T12:02:55.405+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:55.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:02:55.408+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:55.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:55.427+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:02:55.450+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:55.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:02:55.461+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:02:55.461+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:02:55.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T12:03:25.723+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:25.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:03:25.727+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:25.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:25.758+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:25.782+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:25.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:03:25.793+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:25.793+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:03:25.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-15T12:03:55.988+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:55.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:03:55.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:55.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:56.020+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:03:56.043+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:56.043+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:03:56.054+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:03:56.054+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:03:56.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T12:04:27.064+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:27.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:04:27.066+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:27.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:27.087+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:27.108+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:27.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:04:27.120+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:27.119+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:04:27.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T12:04:57.391+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:57.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:04:57.393+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:57.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:57.408+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:04:57.427+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:57.427+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:04:57.438+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:04:57.438+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:04:57.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-15T12:05:28.160+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:28.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:05:28.164+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:28.163+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:28.189+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:28.213+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:28.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:05:28.224+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:28.224+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:05:28.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T12:05:59.052+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:59.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:05:59.054+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:59.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:59.071+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:05:59.094+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:59.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:05:59.106+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:05:59.105+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:05:59.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T12:06:29.988+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:06:29.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:06:29.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:06:29.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:06:30.004+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:06:30.033+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:06:30.033+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:06:30.045+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:06:30.045+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:06:30.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T12:07:01.027+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:01.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:07:01.030+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:01.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:01.045+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:01.065+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:01.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:07:01.075+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:01.075+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:07:01.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T12:07:31.955+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:31.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:07:31.958+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:31.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:31.972+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:07:31.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:31.991+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:07:32.005+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:07:32.004+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:07:32.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T12:08:02.151+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:02.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:08:02.154+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:02.153+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:02.171+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:02.195+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:02.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:08:02.206+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:02.206+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:08:02.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.076 seconds
[2025-07-15T12:08:33.103+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:33.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:08:33.106+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:33.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:33.119+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:08:33.140+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:33.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:08:33.150+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:08:33.150+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:08:33.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.065 seconds
[2025-07-15T12:09:04.076+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:04.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:09:04.079+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:04.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:04.093+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:04.112+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:04.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:09:04.123+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:04.123+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:09:04.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T12:09:34.969+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:34.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:09:34.971+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:34.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:34.988+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:09:35.010+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:35.010+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:09:35.022+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:09:35.022+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:09:35.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T12:10:05.790+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:05.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:10:05.793+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:05.792+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:05.807+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:05.828+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:05.828+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:10:05.840+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:05.840+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:10:05.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T12:10:36.605+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:36.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:10:36.608+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:36.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:36.629+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:10:36.651+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:36.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:10:36.662+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:10:36.662+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:10:36.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T12:11:07.445+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:07.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:11:07.448+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:07.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:07.471+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:07.492+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:07.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:11:07.503+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:07.503+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:11:07.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T12:11:37.609+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:37.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:11:37.611+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:37.611+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:37.642+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:11:37.665+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:37.665+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:11:37.676+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:11:37.676+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:11:37.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T12:12:08.624+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:08.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:12:08.626+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:08.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:08.637+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:08.658+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:08.658+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:12:08.669+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:08.669+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:12:08.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.063 seconds
[2025-07-15T12:12:39.542+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:39.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:12:39.544+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:39.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:39.558+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:12:39.581+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:39.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:12:39.592+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:12:39.592+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:12:39.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T12:13:10.613+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:10.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:13:10.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:10.618+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:10.722+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:10.746+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:10.745+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:13:10.757+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:10.756+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:13:10.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.166 seconds
[2025-07-15T12:13:40.898+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:40.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:13:40.901+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:40.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:40.917+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:13:40.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:40.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:13:40.948+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:13:40.948+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:13:40.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T12:14:11.908+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:11.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:14:11.911+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:11.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:11.935+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:11.957+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:11.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:14:11.967+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:11.967+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:14:11.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T12:14:42.633+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:42.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:14:42.635+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:42.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:42.653+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:14:42.676+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:42.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:14:42.688+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:14:42.688+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:14:42.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T12:15:12.800+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:12.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:15:12.802+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:12.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:12.817+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:12.838+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:12.837+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:15:12.848+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:12.848+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:15:12.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T12:15:42.996+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:42.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:15:42.999+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:42.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:43.016+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:15:43.042+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:43.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:15:43.054+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:15:43.054+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:15:43.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T12:16:13.121+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:13.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:16:13.124+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:13.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:13.137+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:13.157+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:13.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:16:13.167+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:13.167+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:16:13.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.064 seconds
[2025-07-15T12:16:43.474+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:43.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:16:43.476+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:43.476+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:43.491+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:16:43.511+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:43.511+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:16:43.521+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:16:43.521+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:16:43.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T12:17:14.547+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:14.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:17:14.550+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:14.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:14.564+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:14.583+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:14.583+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:17:14.594+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:14.594+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:17:14.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.066 seconds
[2025-07-15T12:17:45.618+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:45.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:17:45.622+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:45.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:45.644+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:17:45.665+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:45.665+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:17:45.676+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:17:45.676+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:17:45.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T12:18:15.821+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:15.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:18:15.824+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:15.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:15.851+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:15.871+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:15.871+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:18:15.882+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:15.882+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:18:15.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T12:18:46.023+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:46.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:18:46.026+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:46.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:46.055+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:18:46.088+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:46.088+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:18:46.101+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:18:46.100+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:18:46.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-15T12:19:17.027+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:17.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:19:17.029+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:17.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:17.056+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:17.076+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:17.075+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:19:17.086+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:17.086+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:19:17.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T12:19:48.079+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:48.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:19:48.082+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:48.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:48.123+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:19:48.149+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:48.149+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:19:48.162+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:19:48.161+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:19:48.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.106 seconds
[2025-07-15T12:20:19.046+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:19.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:20:19.049+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:19.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:19.073+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:19.103+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:19.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:20:19.116+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:19.115+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:20:19.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T12:20:49.977+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:49.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:20:49.980+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:49.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:50.003+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:20:50.026+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:50.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:20:50.037+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:20:50.037+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:20:50.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T12:21:21.091+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:21.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:21:21.094+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:21.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:21.121+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:21.144+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:21.144+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:21:21.155+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:21.155+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:21:21.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T12:21:52.183+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:52.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:21:52.186+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:52.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:52.216+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:21:52.243+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:52.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:21:52.256+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:21:52.256+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:21:52.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T12:22:23.183+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:23.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:22:23.187+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:23.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:23.220+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:23.256+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:23.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:22:23.268+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:23.268+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:22:23.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-15T12:22:54.171+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:54.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:22:54.174+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:54.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:54.198+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:22:54.225+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:54.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:22:54.241+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:22:54.241+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:22:54.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-07-15T12:23:25.210+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:25.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:23:25.213+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:25.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:25.241+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:25.264+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:25.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:23:25.275+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:25.275+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:23:25.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T12:23:56.225+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:56.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:23:56.229+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:56.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:56.258+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:23:56.280+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:56.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:23:56.291+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:23:56.291+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:23:56.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T12:24:27.263+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:27.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:24:27.266+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:27.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:27.292+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:27.321+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:27.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:24:27.334+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:27.334+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:24:27.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T12:24:58.220+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:58.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:24:58.223+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:58.223+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:58.239+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:24:58.264+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:58.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:24:58.276+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:24:58.276+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:24:58.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T12:25:29.191+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:25:29.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:25:29.194+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:25:29.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:25:29.222+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:25:29.247+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:25:29.247+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:25:29.258+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:25:29.258+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:25:29.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T12:26:00.183+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:00.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:26:00.187+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:00.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:00.212+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:00.242+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:00.242+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:26:00.258+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:00.257+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:26:00.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-15T12:26:30.344+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:30.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:26:30.346+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:30.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:30.365+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:26:30.389+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:30.389+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:26:30.407+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:26:30.406+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:26:30.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T12:53:14.840+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:14.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:53:14.843+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:14.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:14.872+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:14.922+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:14.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:53:14.935+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:14.935+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:53:14.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.121 seconds
[2025-07-15T12:53:45.052+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:45.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:53:45.055+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:45.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:45.079+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:53:45.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:45.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:53:45.117+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:53:45.117+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:53:45.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T12:54:15.168+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:15.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:54:15.170+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:15.170+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:15.184+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:15.205+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:15.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:54:15.217+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:15.217+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:54:15.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T12:54:45.298+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:45.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:54:45.301+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:45.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:45.316+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:54:45.335+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:45.335+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:54:45.346+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:54:45.345+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:54:45.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T12:55:15.553+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:15.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:55:15.555+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:15.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:15.568+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:15.591+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:15.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:55:15.602+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:15.602+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:55:15.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T12:55:45.777+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:45.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:55:45.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:45.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:45.803+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:55:45.825+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:45.825+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:55:45.836+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:55:45.836+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:55:45.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T12:56:15.964+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:15.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:56:15.968+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:15.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:16.050+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:16.070+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:16.070+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:56:16.082+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:16.082+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:56:16.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.139 seconds
[2025-07-15T12:56:46.169+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:46.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:56:46.172+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:46.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:46.194+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:56:46.218+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:46.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:56:46.229+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:56:46.229+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:56:46.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T12:57:28.049+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:28.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:57:28.053+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:28.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:28.082+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:28.127+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:28.127+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:57:28.141+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:28.141+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:57:28.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.125 seconds
[2025-07-15T12:57:58.296+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:58.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:57:58.300+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:58.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:58.316+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:57:58.339+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:58.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:57:58.351+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:57:58.351+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:57:58.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T12:58:28.630+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:28.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:58:28.636+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:28.636+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:28.674+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:28.706+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:28.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:58:28.718+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:28.718+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:58:28.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.114 seconds
[2025-07-15T12:58:59.023+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:59.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:58:59.025+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:59.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:59.037+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:58:59.060+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:59.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:58:59.072+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:58:59.072+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:58:59.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T12:59:29.367+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:29.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:59:29.370+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:29.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:29.384+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:29.404+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:29.404+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:59:29.416+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:29.416+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:59:29.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T12:59:59.526+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:59.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T12:59:59.528+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:59.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:59.542+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T12:59:59.562+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:59.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T12:59:59.573+0000] {logging_mixin.py:188} INFO - [2025-07-15T12:59:59.573+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T12:59:59.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T13:00:29.772+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:00:29.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:00:29.774+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:00:29.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:00:29.792+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:00:29.815+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:00:29.815+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:00:29.830+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:00:29.830+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:00:29.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:00:59.985+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:00:59.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:00:59.988+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:00:59.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:01:00.016+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:01:00.038+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:01:00.038+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:01:00.050+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:01:00.050+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:01:00.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T13:01:30.223+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:01:30.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:01:30.226+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:01:30.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:01:30.240+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:01:30.261+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:01:30.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:01:30.273+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:01:30.273+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:01:30.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:02:00.507+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:00.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:02:00.512+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:00.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:00.544+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:00.566+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:00.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:02:00.577+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:00.576+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:02:00.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T13:02:30.939+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:30.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:02:30.943+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:30.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:30.972+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:02:30.998+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:30.997+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:02:31.009+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:02:31.009+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:02:31.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T13:03:01.163+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:01.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:03:01.166+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:01.166+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:01.209+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:01.238+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:01.238+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:03:01.250+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:01.250+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:03:01.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.109 seconds
[2025-07-15T13:03:31.726+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:31.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:03:31.735+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:31.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:31.782+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:03:31.809+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:31.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:03:31.821+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:03:31.821+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:03:31.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.131 seconds
[2025-07-15T13:04:01.944+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:01.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:04:01.947+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:01.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:01.976+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:02.004+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:02.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:04:02.016+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:02.016+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:04:02.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-07-15T13:04:32.454+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:32.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:04:32.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:32.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:32.480+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:04:32.502+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:32.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:04:32.513+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:04:32.513+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:04:32.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:05:02.627+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:02.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:05:02.629+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:02.629+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:02.644+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:02.664+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:02.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:05:02.675+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:02.674+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:05:02.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T13:05:32.984+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:32.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:05:32.989+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:32.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:33.018+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:05:33.040+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:33.040+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:05:33.052+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:05:33.051+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:05:33.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.090 seconds
[2025-07-15T13:06:04.078+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:04.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:06:04.081+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:04.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:04.098+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:04.120+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:04.120+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:06:04.131+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:04.131+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:06:04.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T13:06:34.398+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:34.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:06:34.401+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:34.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:34.424+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:06:34.447+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:34.447+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:06:34.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:06:34.459+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:06:34.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:07:04.601+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:04.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:07:04.604+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:04.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:04.628+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:04.650+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:04.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:07:04.662+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:04.662+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:07:04.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T13:07:35.127+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:35.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:07:35.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:35.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:35.152+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:07:35.173+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:35.173+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:07:35.183+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:07:35.183+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:07:35.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T13:08:05.257+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:05.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:08:05.260+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:05.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:05.275+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:05.300+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:05.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:08:05.312+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:05.312+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:08:05.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T13:08:35.447+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:35.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:08:35.450+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:35.449+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:35.466+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:08:35.487+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:35.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:08:35.501+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:08:35.501+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:08:35.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T13:09:05.737+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:05.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:09:05.740+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:05.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:05.756+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:05.779+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:05.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:09:05.789+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:05.789+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:09:05.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T13:09:35.946+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:35.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:09:35.949+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:35.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:35.971+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:09:35.993+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:35.993+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:09:36.004+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:09:36.004+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:09:36.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T13:10:06.125+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:06.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:10:06.128+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:06.127+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:06.140+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:06.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:06.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:10:06.170+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:06.170+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:10:06.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:10:36.455+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:36.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:10:36.458+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:36.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:36.479+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:10:36.503+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:36.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:10:36.514+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:10:36.514+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:10:36.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T13:11:06.923+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:06.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:11:06.926+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:06.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:06.938+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:06.960+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:06.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:11:06.971+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:06.971+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:11:06.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T13:11:37.192+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:37.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:11:37.195+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:37.195+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:37.208+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:11:37.229+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:37.229+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:11:37.240+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:11:37.240+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:11:37.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T13:12:07.325+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:07.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:12:07.327+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:07.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:07.340+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:07.362+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:07.362+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:12:07.372+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:07.372+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:12:07.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T13:12:37.590+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:37.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:12:37.593+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:37.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:37.620+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:12:37.643+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:37.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:12:37.653+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:12:37.653+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:12:37.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T13:13:07.987+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:07.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:13:07.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:07.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:08.017+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:08.043+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:08.043+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:13:08.055+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:08.055+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:13:08.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.092 seconds
[2025-07-15T13:13:38.232+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:38.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:13:38.235+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:38.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:38.252+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:13:38.275+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:38.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:13:38.287+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:13:38.287+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:13:38.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T13:14:08.422+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:08.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:14:08.426+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:08.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:08.439+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:08.460+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:08.460+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:14:08.470+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:08.470+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:14:08.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:14:38.569+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:38.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:14:38.572+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:38.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:38.595+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:14:38.615+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:38.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:14:38.625+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:14:38.625+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:14:38.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T13:15:08.861+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:08.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:15:08.864+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:08.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:08.887+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:08.909+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:08.909+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:15:08.920+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:08.920+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:15:08.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:15:39.033+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:39.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:15:39.036+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:39.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:39.072+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:15:39.093+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:39.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:15:39.104+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:15:39.104+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:15:39.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T13:16:09.174+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:09.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:16:09.176+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:09.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:09.206+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:09.226+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:09.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:16:09.236+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:09.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:16:09.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:16:39.420+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:39.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:16:39.423+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:39.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:39.446+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:16:39.469+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:39.469+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:16:39.481+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:16:39.481+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:16:39.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:17:09.577+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:09.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:17:09.580+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:09.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:09.610+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:09.634+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:09.634+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:17:09.645+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:09.644+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:17:09.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T13:17:39.763+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:39.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:17:39.766+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:39.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:39.789+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:17:39.810+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:39.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:17:39.820+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:17:39.820+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:17:39.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T13:18:10.049+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:10.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:18:10.052+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:10.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:10.075+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:10.097+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:10.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:18:10.111+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:10.111+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:18:10.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-07-15T13:18:40.594+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:40.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:18:40.603+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:40.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:40.621+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:18:40.645+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:40.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:18:40.656+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:18:40.656+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:18:40.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:19:10.726+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:10.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:19:10.728+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:10.728+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:10.741+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:10.762+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:10.762+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:19:10.773+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:10.773+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:19:10.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:19:41.186+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:41.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:19:41.188+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:41.188+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:41.204+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:19:41.225+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:41.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:19:41.236+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:19:41.236+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:19:41.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:20:12.128+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:12.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:20:12.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:12.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:12.147+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:12.171+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:12.170+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:20:12.182+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:12.181+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:20:12.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T13:20:43.108+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:43.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:20:43.110+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:43.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:43.127+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:20:43.148+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:43.148+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:20:43.160+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:20:43.159+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:20:43.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T13:21:14.029+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:14.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:21:14.032+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:14.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:14.047+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:14.069+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:14.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:21:14.080+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:14.080+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:21:14.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:21:44.230+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:44.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:21:44.232+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:44.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:44.251+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:21:44.274+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:44.274+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:21:44.288+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:21:44.287+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:21:44.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T13:22:14.461+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:14.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:22:14.464+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:14.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:14.487+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:14.508+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:14.507+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:22:14.519+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:14.519+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:22:14.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:22:44.929+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:44.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:22:44.932+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:44.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:44.955+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:22:44.976+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:44.976+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:22:44.986+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:22:44.986+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:22:45.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T13:23:15.060+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:15.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:23:15.063+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:15.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:15.087+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:15.108+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:15.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:23:15.119+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:15.119+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:23:15.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T13:23:45.308+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:45.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:23:45.311+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:45.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:45.339+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:23:45.362+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:45.362+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:23:45.373+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:23:45.373+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:23:45.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.085 seconds
[2025-07-15T13:24:15.524+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:15.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:24:15.527+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:15.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:15.541+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:15.563+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:15.563+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:24:15.574+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:15.574+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:24:15.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:24:46.580+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:46.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:24:46.582+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:46.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:46.596+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:24:46.618+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:46.618+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:24:46.629+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:24:46.629+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:24:46.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T13:25:17.559+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:17.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:25:17.564+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:17.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:17.596+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:17.621+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:17.621+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:25:17.633+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:17.633+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:25:17.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T13:25:47.794+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:47.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:25:47.797+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:47.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:47.820+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:25:47.842+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:47.842+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:25:47.854+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:25:47.854+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:25:47.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T13:26:18.057+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:18.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:26:18.060+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:18.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:18.085+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:18.107+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:18.107+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:26:18.118+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:18.118+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:26:18.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:26:49.141+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:49.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:26:49.144+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:49.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:49.170+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:26:49.194+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:49.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:26:49.206+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:26:49.206+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:26:49.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T13:27:19.299+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:19.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:27:19.301+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:19.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:19.315+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:19.337+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:19.337+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:27:19.348+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:19.347+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:27:19.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.071 seconds
[2025-07-15T13:27:50.327+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:50.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:27:50.330+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:50.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:50.347+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:27:50.368+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:50.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:27:50.380+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:27:50.380+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:27:50.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T13:28:20.580+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:20.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:28:20.585+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:20.585+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:20.629+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:20.653+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:20.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:28:20.664+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:20.663+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:28:20.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-07-15T13:28:50.778+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:50.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:28:50.780+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:50.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:50.819+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:28:50.841+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:50.841+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:28:50.852+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:28:50.852+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:28:50.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T13:29:20.966+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:20.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:29:20.970+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:20.970+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:20.987+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:21.009+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:21.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:29:21.020+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:21.020+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:29:21.033+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:29:51.129+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:51.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:29:51.132+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:51.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:51.145+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:29:51.169+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:51.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:29:51.179+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:29:51.179+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:29:51.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:30:21.281+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:21.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:30:21.283+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:21.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:21.302+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:21.325+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:21.325+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:30:21.336+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:21.336+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:30:21.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.080 seconds
[2025-07-15T13:30:52.321+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:52.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:30:52.328+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:52.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:52.357+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:30:52.378+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:52.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:30:52.389+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:30:52.389+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:30:52.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-07-15T13:31:22.489+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:22.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:31:22.492+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:22.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:22.519+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:22.539+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:22.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:31:22.550+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:22.550+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:31:22.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T13:31:52.713+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:52.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:31:52.716+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:52.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:52.746+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:31:52.770+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:52.770+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:31:52.783+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:31:52.783+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:31:52.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.093 seconds
[2025-07-15T13:32:22.916+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:22.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:32:22.919+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:22.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:22.949+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:22.975+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:22.975+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:32:22.986+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:22.986+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:32:23.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T13:32:53.267+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:53.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:32:53.270+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:53.270+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:53.294+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:32:53.317+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:53.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:32:53.330+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:32:53.330+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:32:53.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.089 seconds
[2025-07-15T13:33:23.434+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:23.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:33:23.436+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:23.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:23.456+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:23.480+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:23.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:33:23.492+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:23.492+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:33:23.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:33:53.699+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:53.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:33:53.701+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:53.701+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:53.716+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:33:53.737+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:53.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:33:53.748+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:33:53.748+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:33:53.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:34:23.860+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:23.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:34:23.863+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:23.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:23.900+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:23.922+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:23.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:34:23.933+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:23.933+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:34:23.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T13:34:54.038+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:54.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:34:54.040+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:54.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:54.055+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:34:54.076+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:54.076+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:34:54.087+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:34:54.087+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:34:54.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T13:35:24.226+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:24.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:35:24.228+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:24.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:24.253+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:24.275+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:24.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:35:24.285+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:24.285+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:35:24.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.086 seconds
[2025-07-15T13:35:54.989+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:54.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:35:54.991+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:54.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:55.015+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:35:55.035+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:55.035+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:35:55.045+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:35:55.045+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:35:55.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T13:36:25.127+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:25.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:36:25.130+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:25.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:25.144+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:25.166+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:25.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:36:25.176+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:25.176+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:36:25.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.068 seconds
[2025-07-15T13:36:55.567+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:55.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:36:55.578+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:55.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:55.701+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:36:55.724+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:55.724+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:36:55.735+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:36:55.735+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:36:55.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.193 seconds
[2025-07-15T13:37:26.689+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:26.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:37:26.692+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:26.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:26.706+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:26.727+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:26.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:37:26.739+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:26.739+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:37:26.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T13:37:56.877+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:56.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:37:56.880+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:56.879+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:56.903+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:37:56.926+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:56.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:37:56.936+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:37:56.936+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:37:56.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
[2025-07-15T13:38:27.244+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:27.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:38:27.246+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:27.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:27.258+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:27.281+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:27.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:38:27.291+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:27.291+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:38:27.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T13:38:57.431+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:57.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:38:57.434+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:57.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:57.451+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:38:57.472+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:57.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:38:57.484+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:38:57.484+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:38:57.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-07-15T13:39:28.417+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:28.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:39:28.420+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:28.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:28.436+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:28.459+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:28.459+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:39:28.477+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:28.477+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:39:28.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.087 seconds
[2025-07-15T13:39:58.559+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:58.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:39:58.561+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:58.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:58.580+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:39:58.601+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:58.601+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:39:58.613+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:39:58.613+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:39:58.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T13:40:29.637+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:29.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:40:29.642+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:29.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:29.654+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:29.677+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:29.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:40:29.688+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:29.688+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:40:29.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:40:59.823+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:59.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:40:59.826+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:59.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:59.851+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:40:59.874+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:59.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:40:59.886+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:40:59.886+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:40:59.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.088 seconds
[2025-07-15T13:41:30.869+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:41:30.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:41:30.872+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:41:30.871+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:41:30.887+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:41:30.909+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:41:30.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:41:30.919+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:41:30.919+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:41:30.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.069 seconds
[2025-07-15T13:42:01.897+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:01.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:42:01.900+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:01.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:01.916+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:01.938+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:01.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:42:01.949+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:01.948+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:42:01.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T13:42:32.324+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:32.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:42:32.327+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:32.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:32.351+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:42:32.374+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:32.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:42:32.385+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:42:32.385+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:42:32.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:43:02.515+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:02.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:43:02.518+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:02.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:02.542+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:02.565+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:02.565+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:43:02.575+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:02.575+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:43:02.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:43:32.679+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:32.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:43:32.681+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:32.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:32.699+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:43:32.720+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:32.720+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:43:32.731+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:43:32.731+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:43:32.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.073 seconds
[2025-07-15T13:44:03.058+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:03.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:44:03.061+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:03.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:03.089+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:03.112+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:03.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:44:03.126+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:03.126+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:44:03.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T13:44:33.768+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:33.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:44:33.772+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:33.771+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:33.801+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:44:33.823+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:33.823+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:44:33.834+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:44:33.834+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:44:33.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.091 seconds
[2025-07-15T13:45:04.501+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:04.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:45:04.504+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:04.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:04.536+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:04.559+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:04.559+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:45:04.570+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:04.570+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:45:04.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-07-15T13:45:35.454+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:35.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:45:35.456+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:35.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:35.481+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:45:35.508+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:35.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:45:35.521+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:45:35.521+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:45:35.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-07-15T13:46:05.601+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:05.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:46:05.603+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:05.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:05.621+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:05.647+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:05.647+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:46:05.659+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:05.658+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:46:05.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T13:46:35.773+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:35.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:46:35.775+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:35.775+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:35.794+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:46:35.814+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:35.814+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:46:35.825+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:46:35.825+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:46:35.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:47:05.928+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:05.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:47:05.931+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:05.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:05.944+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:05.966+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:05.965+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:47:05.977+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:05.977+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:47:05.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.074 seconds
[2025-07-15T13:47:36.322+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:36.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:47:36.324+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:36.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:36.342+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:47:36.365+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:36.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:47:36.377+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:47:36.376+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:47:36.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.075 seconds
[2025-07-15T13:48:07.413+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:07.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:48:07.417+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:07.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:07.435+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:07.457+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:07.457+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:48:07.469+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:07.468+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:48:07.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.079 seconds
[2025-07-15T13:48:37.677+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:37.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:48:37.680+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:37.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:37.701+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:48:37.721+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:37.721+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:48:37.732+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:48:37.732+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:48:37.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.077 seconds
[2025-07-15T13:49:07.823+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:07.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:49:07.826+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:07.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:07.849+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:07.870+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:07.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:49:07.881+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:07.880+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:49:07.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.078 seconds
[2025-07-15T13:49:37.972+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:37.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:49:37.975+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:37.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:37.999+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:49:38.021+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:38.021+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:49:38.032+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:49:38.032+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:49:38.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-07-15T13:50:08.114+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:08.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:50:08.117+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:08.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:08.131+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:08.151+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:08.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:50:08.161+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:08.161+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:50:08.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.067 seconds
[2025-07-15T13:50:38.310+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:38.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:50:38.312+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:38.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:38.325+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:50:38.348+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:38.348+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:50:38.359+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:50:38.359+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:50:38.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.070 seconds
[2025-07-15T13:51:08.512+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:08.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:51:08.515+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:08.515+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:08.530+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:08.552+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:08.552+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:51:08.563+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:08.563+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:51:08.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.072 seconds
[2025-07-15T13:51:39.396+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:39.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:51:39.399+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:39.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:39.440+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:51:39.465+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:39.465+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:51:39.476+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:51:39.476+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:51:39.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-07-15T13:52:10.472+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:10.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:52:10.474+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:10.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:10.492+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:10.513+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:10.513+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:52:10.524+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:10.524+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:52:10.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.084 seconds
[2025-07-15T13:52:40.835+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:40.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:52:40.840+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:40.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:40.937+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:52:40.960+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:40.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:52:40.971+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:52:40.971+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:52:41.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.172 seconds
[2025-07-15T13:53:12.110+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:53:12.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-07-15T13:53:12.113+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:53:12.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:53:12.133+0000] {processor.py:840} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-07-15T13:53:12.157+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:53:12.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-07-15T13:53:12.169+0000] {logging_mixin.py:188} INFO - [2025-07-15T13:53:12.168+0000] {dag.py:3954} INFO - Setting next_dagrun for spark_etl_pipeline to None, run_after=None
[2025-07-15T13:53:12.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.082 seconds
