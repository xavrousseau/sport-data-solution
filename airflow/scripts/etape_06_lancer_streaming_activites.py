# ======================================================================================
# Script      : etape_06_lancer_streaming_activites.py
# Objectif    : Lancer manuellement le job Spark streaming Kafka ‚Üí Delta Lake
#               - Ex√©cute le script Spark dans le conteneur Spark
#               - Attend que Spark d√©marre correctement (mode bloquant)
# Auteur      : Xavier Rousseau | Version corrig√©e par ChatGPT, Juillet 2025
# ======================================================================================

import subprocess
import os
import time
from dotenv import load_dotenv
from loguru import logger

# ======================================================================================
# 1. Chargement des variables d‚Äôenvironnement (.env global mont√© dans Airflow)
# ======================================================================================

load_dotenv(dotenv_path="/opt/airflow/.env", override=True)

SPARK_CONTAINER_NAME = os.getenv("SPARK_CONTAINER_NAME", "sport-spark")
SPARK_STREAMING_SCRIPT = os.getenv("SPARK_SCRIPT_STREAMING_PATH", "/opt/airflow/jobs/bronze_streaming_activites.py")

# ======================================================================================
# 2. Fonction principale appel√©e par Airflow ou en local
# ======================================================================================

def main(**kwargs):
    """
    Lancement bloquant du job Spark Streaming (Kafka ‚Üí Delta Lake)
    --------------------------------------------------------------
    Ce job lit les messages Kafka contenant les activit√©s sportives (CDC Debezium),
    puis :
      - les parse et valide
      - √©crit les flux dans Delta Lake (MinIO)
      - envoie des messages ntfy enrichis

    Cette version bloque Airflow jusqu'√† d√©marrage effectif, avec un d√©lai de s√©curit√©.
    """
    logger.info("üöÄ D√©marrage du job Spark Streaming Kafka ‚Üí Delta Lake")

    cmd = [
        "docker", "exec", "-i", SPARK_CONTAINER_NAME,
        "spark-submit", SPARK_STREAMING_SCRIPT
    ]

    try:
        logger.info(f"üõ†Ô∏è Commande ex√©cut√©e : {' '.join(cmd)}")
        # Ex√©cution bloquante (attend d√©marrage du job Spark)
        subprocess.run(cmd, check=True)
        logger.success("‚úÖ Job Spark Streaming lanc√© avec succ√®s (mode bloquant)")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du lancement Spark Streaming : {e}")
        raise

    # Attente explicite pour laisser Spark initialiser le stream Kafka
    logger.info("‚è≥ Pause de s√©curit√© pour laisser Spark d√©marrer (10 secondes)...")
    time.sleep(10)
    logger.info("üü¢ Spark est suppos√© √™tre op√©rationnel. Suite du pipeline possible.")

# ======================================================================================
# 3. Point d‚Äôentr√©e direct (utilisation CLI possible)
# ======================================================================================

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale lors de l‚Äôex√©cution du script : {e}")
        raise
