# ==========================================================================================
# Script      : croiser_rh_sport_et_calculer_prime.py
# Objectif    : Croisement RH/Sport, calcul des bÃ©nÃ©ficiaires et montant de la prime
#               + attribution des journÃ©es bien-Ãªtre (â‰¥15 activitÃ©s)
#               + export (MinIO/PostgreSQL), validation Great Expectations
# Auteur      : Xavier Rousseau | Juillet 2025
# ==========================================================================================

import os
import io
import tempfile
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
from loguru import logger
from sqlalchemy import create_engine
from minio_helper import MinIOHelper
import requests
# ==========================================================================================
# 1. ParamÃ¨tres globaux et environnement
# ==========================================================================================

load_dotenv(dotenv_path=".env", override=True)

MINIO_RH_KEY = "raw/donnees_rh_cleaned.xlsx"
MINIO_SPORT_KEY = "raw/donnees_sportives_cleaned.xlsx"
MINIO_EXPORT_KEY = "final/beneficiaires_primes_sportives.xlsx"
MINIO_EXPORT_BE_KEY = "final/beneficiaires_journees_bien_etre.xlsx"
TMP_DIR = "/tmp"

POSTGRES_USER = os.getenv("POSTGRES_USER")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD")
POSTGRES_HOST = os.getenv("POSTGRES_HOST")
POSTGRES_PORT = os.getenv("POSTGRES_PORT")
POSTGRES_DB = os.getenv("POSTGRES_DB")
DB_CONN_STRING = (
    f"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@"
    f"{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
)

PRIME_MONTANT = 100

# ==========================================================================================
# 2. Fonction utilitaire : chargement depuis MinIO
# ==========================================================================================

def charger_fichier_minio(helper, key):
    with tempfile.NamedTemporaryFile(suffix=".xlsx", dir=TMP_DIR) as tmpfile:
        helper.client.download_file(Bucket=helper.bucket, Key=key, Filename=tmpfile.name)
        logger.success(f"ğŸ“¥ Fichier tÃ©lÃ©chargÃ© depuis MinIO : {key}")
        return pd.read_excel(tmpfile.name)

# ==========================================================================================
# 3. Pipeline principal : croisement, calcul, export, validation
# ==========================================================================================

def pipeline_croisement_prime():
    logger.info("=== DÃ‰MARRAGE DU PIPELINE : Prime + JournÃ©es Bien-ÃŠtre ===")
    helper = MinIOHelper()

    df_rh = charger_fichier_minio(helper, MINIO_RH_KEY)
    df_sport = charger_fichier_minio(helper, MINIO_SPORT_KEY)

    logger.info(f"ğŸ“Š SalariÃ©s RH Ã©ligibles        : {len(df_rh)}")
    logger.info(f"ğŸ“Š ActivitÃ©s sportives valides : {len(df_sport)}")

    # --- Jointure RH + ActivitÃ©s sportives
    df_joint = pd.merge(df_rh, df_sport, on="id_salarie", how="inner")
    logger.info(f"ğŸ”— BÃ©nÃ©ficiaires potentiels     : {len(df_joint)}")

    # --- AgrÃ©gation pour la prime
    grouped = df_joint.groupby(["id_salarie", "nom", "prenom"]).agg({
        "activite_clean": "count"
    }).reset_index().rename(columns={"activite_clean": "nb_activites"})

    grouped["prime_eligible"] = True
    grouped["prime_montant_eur"] = PRIME_MONTANT
    grouped["date_prime"] = datetime.today().strftime("%Y-%m-%d")

    logger.info("--- SynthÃ¨se Primes Sportives ---")
    logger.info(f"ğŸ¯ Nb bÃ©nÃ©ficiaires     : {len(grouped)}")
    logger.info(f"ğŸ’¶ Montant total primes : {grouped['prime_montant_eur'].sum():.2f} â‚¬")
    logger.info(f"ğŸ“ˆ ActivitÃ©s moyennes   : {grouped['nb_activites'].mean():.2f}")

    # ======================================================================================
    # 4. Export primes vers MinIO (.xlsx)
    # ======================================================================================

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        grouped.to_excel(writer, index=False)
    output.seek(0)

    try:
        helper.client.put_object(
            Bucket=helper.bucket,
            Key=MINIO_EXPORT_KEY,
            Body=output,
            ContentLength=output.getbuffer().nbytes,
        )
        logger.success(f"ğŸ“¤ ExportÃ© vers MinIO : {MINIO_EXPORT_KEY}")
    except Exception as e:
        logger.error(f"âŒ Erreur export MinIO : {e}")

    # ======================================================================================
    # 5. Insertion PostgreSQL (prime)
    # ======================================================================================

    try:
        engine = create_engine(DB_CONN_STRING)
        grouped.to_sql("beneficiaires_primes_sport", engine, if_exists="replace", index=False, schema="sportdata")
        logger.success("ğŸ—ƒï¸ Table PostgreSQL : sportdata.beneficiaires_primes_sport")
    except Exception as e:
        logger.error(f"âŒ Erreur PostgreSQL (prime) : {e}")

    # ======================================================================================
    # 6. Calcul des journÃ©es bien-Ãªtre (â‰¥15 activitÃ©s/an)
    # ======================================================================================

    logger.info("=== Calcul des bÃ©nÃ©ficiaires des journÃ©es bien-Ãªtre ===")

    df_nb_activites = df_sport.groupby("id_salarie").agg(
        nb_activites=('date_debut', 'count')
    ).reset_index()

    df_bien_etre = df_nb_activites[df_nb_activites["nb_activites"] >= 15].copy()
    df_bien_etre["nb_journees_bien_etre"] = 5

    logger.info(f"âœ… {len(df_bien_etre)} salariÃ©(s) Ã©ligible(s) aux journÃ©es bien-Ãªtre.")

    # --- Export PostgreSQL (bien-Ãªtre)
    try:
        df_bien_etre.to_sql("beneficiaires_journees_bien_etre", engine, if_exists="replace", index=False, schema="sportdata")
        logger.success("ğŸ—ƒï¸ Table PostgreSQL : sportdata.beneficiaires_journees_bien_etre")
    except Exception as e:
        logger.error(f"âŒ Erreur PostgreSQL (bien-Ãªtre) : {e}")

    # --- Export MinIO (bien-Ãªtre)
    output_be = io.BytesIO()
    with pd.ExcelWriter(output_be, engine="xlsxwriter") as writer:
        df_bien_etre.to_excel(writer, index=False)
    output_be.seek(0)

    try:
        helper.client.put_object(
            Bucket=helper.bucket,
            Key=MINIO_EXPORT_BE_KEY,
            Body=output_be,
            ContentLength=output_be.getbuffer().nbytes,
        )
        logger.success(f"ğŸ“¤ Export MinIO : {MINIO_EXPORT_BE_KEY}")
    except Exception as e:
        logger.error(f"âŒ Erreur export MinIO (bien-Ãªtre) : {e}")

    # ======================================================================================
    # 7. Validation Great Expectations sur les primes
    # ======================================================================================

    from great_expectations.dataset import PandasDataset
    from great_expectations.render.renderer import ValidationResultsPageRenderer
    from great_expectations.render.view import DefaultJinjaPageView

    ge_df = PandasDataset(grouped)
    ge_df.expect_column_values_to_not_be_null("id_salarie")
    ge_df.expect_column_values_to_not_be_null("nom")
    ge_df.expect_column_values_to_not_be_null("prenom")
    ge_df.expect_column_values_to_be_between("nb_activites", min_value=1)
    ge_df.expect_column_values_to_be_of_type("prime_montant_eur", "int64")
    ge_df.expect_column_values_to_be_between("prime_montant_eur", 1, 1000)

    checkpoint_result = ge_df.validate(result_format="SUMMARY")
    if not checkpoint_result.success:
        logger.error("âŒ Certaines expectations ont Ã©chouÃ©.")
        raise Exception("Ã‰chec de validation Great Expectations â€“ pipeline interrompu.")
    else:
        logger.success("âœ… Toutes les validations Great Expectations sont passÃ©es.")

    # --- GÃ©nÃ©ration rapport HTML
    rendered = ValidationResultsPageRenderer().render(checkpoint_result)
    html = DefaultJinjaPageView().render(rendered)

    report_name = f"validation_reports/rapport_GE_primes_{datetime.now().strftime('%Y%m%d')}.html"
    report_path = os.path.join(TMP_DIR, "rapport_GE.html")

    with open(report_path, "w", encoding="utf-8") as f:
        f.write(html)

    try:
        helper.client.upload_file(
            Filename=report_path,
            Bucket=helper.bucket,
            Key=report_name
        )
        logger.success(f"ğŸ“„ Rapport GE HTML exportÃ© dans MinIO : {report_name}")
    except Exception as e:
        logger.error(f"âŒ Erreur upload rapport GE : {e}")



    message = (
        f"ğŸ¯ Pipeline terminÃ© avec succÃ¨s !\n"
        f"ğŸ’¶ {len(grouped)} primes sportives attribuÃ©es\n"
        f"ğŸ§˜ {len(df_bien_etre)} journÃ©es bien-Ãªtre accordÃ©es\n"
        f"ğŸ—ƒï¸ DonnÃ©es disponibles dans MinIO et PostgreSQL"
    )

    try:
        ntfy_url = "http://ntfy:8080/avantages-sportifs"
        requests.post(ntfy_url, data=message.encode("utf-8"))
        logger.success("ğŸ”” Notification ntfy envoyÃ©e.")
    except Exception as e:
        logger.error(f"âŒ Erreur envoi notification ntfy : {e}")

    logger.info("âœ… Pipeline terminÃ© avec succÃ¨s.")

# ==========================================================================================
# 8. ExÃ©cution principale
# ==========================================================================================

if __name__ == "__main__":
    try:
        pipeline_croisement_prime()
    except Exception as e:
        logger.error(f"âŒ Pipeline interrompu : {e}")

        # ğŸ”” Notification ntfy en cas d'Ã©chec
        import requests
        try:
            message = (
                "ğŸš¨ Ã‰chec du pipeline avantages RH âŒ\n"
                f"â›” Erreur : {str(e)}\n"
                "ğŸ“‹ Consultez les logs Airflow pour plus de dÃ©tails."
            )
            ntfy_url = "http://ntfy:8080/avantages-sportifs"
            requests.post(ntfy_url, data=message.encode("utf-8"))
            logger.warning("ğŸ”” Notification ntfy (Ã©chec) envoyÃ©e.")
        except Exception as ne:
            logger.error(f"âš  Erreur envoi notification ntfy (Ã©chec) : {ne}")

        raise
