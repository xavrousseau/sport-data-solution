# ==========================================================================================
# Script      : controle_qualite_activites.py
# Objectif    : ContrÃ´les qualitÃ© simples sur les activitÃ©s sportives Delta (MinIO),
#               avec export des erreurs et notification ntfy.
# Auteur      : Xavier Rousseau | Juillet 2025
# ==========================================================================================

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import os
from dotenv import load_dotenv
import requests

# ==========================================================================================
# 1. Chargement .env et configuration S3 (MinIO)
# ==========================================================================================
load_dotenv(dotenv_path=".env")

MINIO_HOST = os.getenv("MINIO_HOST", "sport-minio")
MINIO_ENDPOINT = MINIO_HOST + ":9000"
MINIO_ACCESS_KEY = os.getenv("MINIO_ROOT_USER", "minio")
MINIO_SECRET_KEY = os.getenv("MINIO_ROOT_PASSWORD", "minio123")
DELTA_INPUT_PATH = "s3a://datalake/bronze/activites_sportives/"
NTFY_URL = os.getenv("NTFY_URL", f"http://localhost:8080/qualite")

spark = SparkSession.builder \
    .appName("ContrÃ´le QualitÃ© ActivitÃ©s Sportives") \
    .config("spark.hadoop.fs.s3a.endpoint", f"http://{MINIO_ENDPOINT}") \
    .config("spark.hadoop.fs.s3a.access.key", MINIO_ACCESS_KEY) \
    .config("spark.hadoop.fs.s3a.secret.key", MINIO_SECRET_KEY) \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

# ==========================================================================================
# 2. Chargement du fichier Delta
# ==========================================================================================
try:
    df = spark.read.format("delta").load(DELTA_INPUT_PATH)
    print("âœ… DonnÃ©es chargÃ©es depuis MinIO")
except Exception as e:
    print(f"âŒ Erreur lecture Delta : {e}")
    spark.stop()
    exit(1)

# ==========================================================================================
# 3. DÃ©finition des rÃ¨gles de qualitÃ©
# ==========================================================================================
regles = [
    ("distance_m > 0", col("distance_m") > 0),
    ("temps_s > 0", col("temps_s") > 0),
    ("sport_type NOT NULL", col("sport_type").isNotNull()),
    ("id_salarie NOT NULL", col("id_salarie").isNotNull())
]

# ==========================================================================================
# 4. Ã‰valuation des rÃ¨gles
# ==========================================================================================
df_valide = df
df_erreurs = spark.createDataFrame([], df.schema)

for nom_regle, condition in regles:
    violations = df_valide.filter(~condition)
    count = violations.count()
    if count > 0:
        print(f"âŒ {count} violation(s) : {nom_regle}")
        df_erreurs = df_erreurs.union(violations)
        df_valide = df_valide.filter(condition)
    else:
        print(f"âœ… RÃ¨gle validÃ©e : {nom_regle}")

nb_valides = df_valide.count()
nb_erreurs = df_erreurs.count()

# ==========================================================================================
# 5. RÃ©sumÃ© & export des erreurs dans MinIO
# ==========================================================================================
print("\nğŸ“Š RÃ©sumÃ© du contrÃ´le :")
print(f"âœ”ï¸  Lignes valides   : {nb_valides}")
print(f"âŒ Lignes en erreur : {nb_erreurs}")

if nb_erreurs > 0:
    print("ğŸ“¤ Export des erreurs en coursâ€¦")
    path_tmp = "/tmp/erreurs_qualite_activites.xlsx"
    df_erreurs.toPandas().to_excel(path_tmp, index=False)

    from minio import Minio
    client = Minio(
        MINIO_HOST,
        access_key=MINIO_ACCESS_KEY,
        secret_key=MINIO_SECRET_KEY,
        secure=False
    )
    client.fput_object(
        bucket_name="datalake",
        object_name="exports/erreurs_qualite_activites.xlsx",
        file_path=path_tmp
    )
    print("âœ… Fichier exportÃ© dans MinIO : exports/erreurs_qualite_activites.xlsx")

# ==========================================================================================
# 6. Notification ntfy automatique
# ==========================================================================================
try:
    if nb_erreurs > 0:
        msg = f"âŒ ContrÃ´le qualitÃ© : {nb_erreurs} erreur(s) dÃ©tectÃ©e(s) dans les activitÃ©s sportives."
    else:
        msg = f"âœ… ContrÃ´le qualitÃ© OK : {nb_valides} lignes valides."
    requests.post(NTFY_URL, data=msg.encode("utf-8"))
    print(f"ğŸ”” Message ntfy envoyÃ© : {msg}")
except Exception as e:
    print(f"âš ï¸ Erreur envoi ntfy : {e}")

print("\nğŸ” Exemples d'erreurs (max 10) :")
df_erreurs.show(10, truncate=False)

spark.stop()
