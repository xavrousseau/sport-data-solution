# ==========================================================================================
# Fichier    : docker-compose.yml (100% variables via .env)
# Objectif   : D√©ployer la stack Sport Data Solution de mani√®re param√©trable, s√©curis√©e
# Auteur     : Xavier Rousseau | Juin 2025
#
# Toutes les valeurs critiques (mots de passe, ports, users, cl√©s, etc.) sont 
# d√©plac√©es dans le fichier .env pour :
#   - S√©curit√© (rien de sensible en dur)
#   - Facilit√© d‚Äôadaptation par environnement (dev, test, prod, CI/CD‚Ä¶)
#   - Maintenabilit√© et √©volutivit√© maximale
# ==========================================================================================
 

# ------------------------------------------------------------------------------------------
# R√©seau partag√© (virtuel) entre tous les services :
# - Permet √† chaque conteneur d‚Äôappeler les autres par leur nom de service
# - Facilite la r√©solution DNS interne √† Docker
# - Isole la stack des autres stacks sur la m√™me machine
# ------------------------------------------------------------------------------------------
networks:
  sportdata_net:
    driver: bridge

# ------------------------------------------------------------------------------------------
# Volumes persistants pour tous les services n√©cessitant de la donn√©e durable :
# - Indispensable pour √©viter toute perte de donn√©es √† l‚Äôarr√™t/reboot d‚Äôun conteneur
# - Chaque volume a un nom clair, pour backup/migration/maintenance
# ------------------------------------------------------------------------------------------
volumes:
  sport-postgres_data:     # Donn√©es PostgreSQL (tables, index, etc.)
  sport-redpanda_data:     # Messages Redpanda (Kafka)
  sport-minio_data:        # Objets/dossiers stock√©s sur MinIO (Data Lake)
  sport-spark_warehouse:   # Tables et fichiers Delta Lake/Spark (Data Lakehouse)

# ------------------------------------------------------------------------------------------
# D√©finition des services de la stack : chaque bloc correspond √† un microservice cl√©
# ------------------------------------------------------------------------------------------
services:
 
  # ========================================================================================
  # 0. Redis ‚Äî Broker Celery/Airflow (messagerie temps r√©el)
  #    - Utilis√© par Airflow pour CeleryExecutor (t√¢ches distribu√©es)
  #    - Peut servir √† d'autres microservices si besoin de cache/messaging
  # ========================================================================================
  sport-redis:
    image: redis:7-alpine
    container_name: sport-redis
    restart: always
    ports:
      - "6379:6379"  # Expose Redis sur le port standard
    networks:
      - sportdata_net

  # ========================================================================================
  # 1. PostgreSQL ‚Äî Base de donn√©es relationnelle principale
  #    - Stocke toutes les tables m√©tiers (RH, activit√©s sportives, logs, etc.)
  #    - Donn√©es persistantes sur sport-postgres_data
  #    - Port configur√© via .env pour √©viter conflits (multi-projets, CI/CD‚Ä¶)
  # ========================================================================================
  sport-postgres:
    image: postgres:15
    container_name: sport-postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}             # Utilisateur principal (via .env)
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}     # Mot de passe
      POSTGRES_DB: ${POSTGRES_DB}                 # Nom de la base par d√©faut
    ports:
      - "${POSTGRES_PORT}:5432"                   # Redirige port conteneur ‚Üí h√¥te
    volumes:
      - sport-postgres_data:/var/lib/postgresql/data
    networks:
      - sportdata_net

  # ========================================================================================
  # 2. Redpanda ‚Äî Broker Kafka-compatible (streaming d'√©v√©nements)
  #    - Transport d‚Äô√©v√©nements entre microservices (CDC, data pipeline, logs‚Ä¶)
  #    - Mono-noeud optimis√© pour d√©veloppement, test ou POC (overprovisioned)
  #    - Ports et configuration pilot√©s par .env (adaptabilit√© totale)
  # ========================================================================================
  sport-redpanda:
    image: redpandadata/redpanda:v23.3.10                # Version stable de Redpanda (Kafka)
    container_name: sport-redpanda
    restart: always
    # Lancement optimis√© POC/dev : overprovisioned = bypass limites CPU/RAM pour faciliter le local
    # --smp 1         : 1 c≈ìur CPU
    # --memory 1G      : 1 Go de RAM maximum
    # --reserve-memory 0M : pas de m√©moire r√©serv√©e (optimisation dev)
    # --node-id 0      : ID du n≈ìud (unique en mono-noeud)
    # --check=false    : d√©sactive certains checks hardware
    command: redpanda start --overprovisioned --smp 1 --memory 1G --reserve-memory 0M --node-id 0 --check=false
    ports:
      - "${REDPANDA_BROKER_PORT}:9092"   # Port API Kafka (producteurs/consommateurs, scripts)
      - "${REDPANDA_ADMIN_PORT}:9644"    # Port API Admin (UI Redpanda, health, metrics)
    volumes:
      - sport-redpanda_data:/var/lib/redpanda/data       # Persistance messages Kafka
    networks:
      - sportdata_net                                    # Int√©gr√© au r√©seau partag√© Docker

  # ----------------------------------------------------------------------------------------
  # Redpanda Console ‚Äî UI web pour explorer les topics Kafka/Redpanda
  #    - Permet d‚Äôinspecter en live les topics, messages, sch√©mas, performances
  #    - Interface d‚Äôadmin simple pour debug, dev, formation ou monitoring
  #    - Ports personnalis√©s via .env
  #    - Peut √™tre d√©sactiv√©e en prod si besoin (mais tr√®s utile en dev !)
  # ----------------------------------------------------------------------------------------
  sport-redpanda-console:
    image: docker.redpanda.com/redpandadata/console:latest  # Image officielle console web
    container_name: sport-redpanda-console
    restart: always
    environment:
      - KAFKA_BROKERS=sport-redpanda:9092                  # Broker Kafka √† monitorer
      - REDPANDA_ADMIN_URL=http://sport-redpanda:9644      # Lien API admin Redpanda
    ports:
      - "${REDPANDA_CONSOLE_PORT}:8080"                    # UI web Redpanda Console (ex : 8085)
    networks:
      - sportdata_net
    depends_on:
      - sport-redpanda                                     # Attend que le broker soit d√©marr√©

  # ========================================================================================
  # 3. Debezium Connect ‚Äî Capture de Changement de Donn√©es (CDC)
  #    - Synchro en temps r√©el : PostgreSQL ‚Üí Kafka/Redpanda
  #    - Permet le ‚ÄúChange Data Capture‚Äù (data streaming, delta ingestion)
  #    - Toutes les connexions (brokers, topics, hostnames) pilot√©es via .env
  # ========================================================================================
  sport-connect:
    image: debezium/connect:2.4
    container_name: sport-connect
    restart: always
    depends_on:
      - sport-postgres
      - sport-redpanda
    ports:
      - "${DEBEZIUM_CONNECT_PORT}:8083"           # API REST Debezium (admin connecteurs)
    environment:
      BOOTSTRAP_SERVERS: ${DEBEZIUM_BOOTSTRAP_SERVERS}            # Adresse broker Redpanda
      GROUP_ID: ${DEBEZIUM_GROUP_ID}                              # ID de consumer group Kafka
      CONFIG_STORAGE_TOPIC: ${DEBEZIUM_CONFIG_STORAGE_TOPIC}      # Topics internes Debezium
      OFFSET_STORAGE_TOPIC: ${DEBEZIUM_OFFSET_STORAGE_TOPIC}
      STATUS_STORAGE_TOPIC: ${DEBEZIUM_STATUS_STORAGE_TOPIC}
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter   # Format JSON l√©ger (no AVRO)
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_REST_ADVERTISED_HOST_NAME: ${DEBEZIUM_CONNECT_REST_ADVERTISED_HOST_NAME}
      CONNECT_PLUGIN_PATH: /kafka/connect,/debezium
    networks:
      - sportdata_net

  # ========================================================================================
  # 4. MinIO ‚Äî Stockage objet compatible S3 (Data Lake interne)
  #    - Sauvegarde les fichiers bruts, exports, snapshots, historiques
  #    - Admin/minio root user/password, ports API et console via .env
  #    - Persistance sur sport-minio_data
  # ========================================================================================
  sport-minio:
    image: minio/minio
    container_name: sport-minio
    command: server /data --console-address ":${MINIO_CONSOLE_PORT}"  # Console admin sur port d√©di√©
    restart: always
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}           # Admin S3 (via .env)
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "${MINIO_PORT}:9000"            # API S3 compatible (Put, Get, etc.)
      - "${MINIO_CONSOLE_PORT}:9001"    # Console web d‚Äôadmin
    volumes:
      - sport-minio_data:/data
    networks:
      - sportdata_net

  # ========================================================================================
  # 5. Apache Spark ‚Äî Traitement batch & streaming (ETL, Data Lakehouse, Delta)
  #    - Lance le master Spark pour jobs ETL, calculs, ingestion, requ√™tes analytiques
  #    - Mode configurable (master/worker) via variable .env
  #    - Expose UI pour monitoring Spark
  #    - Jobs PySpark √† placer dans ./spark/jobs
  #    - Warehouse persistant pour Delta Lake (tables, logs, checkpoints‚Ä¶)
  # ========================================================================================
  sport-spark:
    image: bitnami/spark:3.5
    container_name: sport-spark
    restart: always
    environment:
      SPARK_MODE: ${SPARK_MODE}                         # master ou worker (voir .env)
    ports:
      - "${SPARK_CLUSTER_PORT}:7077"                    # Cluster manager Spark
      - "${SPARK_UI_PORT}:4040"                         # UI jobs Spark (web)
    volumes:
      - ./spark/jobs:/opt/spark/jobs                    # Monte les jobs dans le conteneur
      - sport-spark_warehouse:/opt/spark/warehouse      # Warehouse partag√© Delta Lake
    networks:
      - sportdata_net

  # ========================================================================================
  # 6. Ntfy ‚Äî Service notifications push/REST (alertes, monitoring, dev/ops)
  #    - Permet envoi de notifications (dev, CI, ops, Slack, incidents‚Ä¶)
  #    - Expose l‚ÄôAPI HTTP sur le port .env (NTFY_HTTP_PORT)
  # ========================================================================================
  sport-ntfy:
    image: binwiederhier/ntfy
    container_name: sport-ntfy
    restart: always
    command: serve
    ports:
      - "${NTFY_HTTP_PORT}:80"          # Expose l‚ÄôAPI REST pour notifications (doc ntfy.sh)
    networks:
      - sportdata_net

  # ========================================================================================
  # 9. Application Python custom (scripts, jobs, API, ETL‚Ä¶)
  #    - Build depuis le Dockerfile du projet
  #    - Code local mont√© dans le conteneur pour dev/it√©ration rapide
  #    - Utilis√© pour : ingestion, analyse, APIs, data quality, export, batch, etc.
  #    - Peut communiquer avec tout le reste de la stack (r√©seau partag√©)
  #    - D√©marrage apr√®s la DB pour garantir les migrations possibles
  # ========================================================================================
  sportdata-app:
    build:
      context: .                               # Racine projet
      dockerfile: Dockerfile                   # Dockerfile custom Python
    container_name: sportdata-app
    volumes:
      - .:/app                                # Monte tout le code local dans le conteneur
    networks:
      - sportdata_net
    depends_on:
      - sport-postgres


  # ========================================================================================
  # 10. sport-airflow-init
  #   üõ† Service d‚Äôinitialisation Airflow :
  #      - Installe les d√©pendances Python (requirements.txt)
  #      - Initialise la base (airflow db init)
  #      - Cr√©e le compte admin (admin user dans l‚ÄôUI)
  #   üîÅ Ne tourne qu‚Äôune fois au d√©marrage (restart: "no")
  #   ‚ö†Ô∏è Doit √™tre relanc√© apr√®s un reset complet de la DB
  # ========================================================================================
  sport-airflow-init:
    build:
      context: .
      dockerfile: Dockerfile     # Image custom bas√©e sur Airflow officiel
    image: sport-airflow:latest          # Nom de l‚Äôimage personnalis√©e
    container_name: sport-airflow-init
    depends_on:
      - sport-postgres                   # Attend la base de donn√©es
      - sport-redis                      # Attend le broker Celery
    restart: "no"
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://${REDIS_HOST}:${REDIS_PORT}/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/dbt:/opt/airflow/dbt
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - ./requirements.txt:/requirements.txt
    entrypoint:
      - bash
      - -c
      - |
        pip install -r /requirements.txt && \
        airflow db init && \
        airflow users create \
          --username ${AIRFLOW_ADMIN_USER} \
          --firstname ${AIRFLOW_ADMIN_FIRSTNAME} \
          --lastname ${AIRFLOW_ADMIN_LASTNAME} \
          --role Admin \
          --email ${AIRFLOW_ADMIN_EMAIL} \
          --password ${AIRFLOW_ADMIN_PASSWORD}
    networks:
      - sportdata_net

  # ========================================================================================
  # 11. sport-airflow-webserver
  #   üåê UI web principale (http://localhost:${AIRFLOW_WEB_PORT})
  #      - Visualise, lance, monitore les DAGs
  #      - Peut √™tre red√©marr√© √† chaud (restart: unless-stopped)
  #   ‚ö†Ô∏è  D√©pend de l‚Äôinit pour √™tre s√ªr que la DB/users Airflow existent d√©j√†
  # ========================================================================================
  sport-airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: sport-airflow:latest
    container_name: sport-airflow-webserver
    restart: unless-stopped
    depends_on:
      - sport-airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://${REDIS_HOST}:${REDIS_PORT}/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    ports:
      - "${AIRFLOW_WEB_PORT}:8080"           # Port externe pour acc√®s navigateur
    command: airflow webserver
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/dbt:/opt/airflow/dbt
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - ./requirements.txt:/requirements.txt
    networks:
      - sportdata_net

  # ========================================================================================
  # 12. sport-airflow-scheduler
  #   ‚è∞ Service planificateur :
  #      - D√©tecte quand d√©clencher/ex√©cuter les DAGs (selon leur schedule/trigger)
  #   ‚ö†Ô∏è  D√©marre apr√®s le webserver (s√©quencement optimal)
  #   ‚ö°Ô∏è  Peut √™tre scal√© si tr√®s grosse volum√©trie (rarement utile hors prod XXL)
  # ========================================================================================
  sport-airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: sport-airflow:latest
    container_name: sport-airflow-scheduler
    restart: unless-stopped
    depends_on:
      - sport-airflow-webserver
      - sport-redis
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://${REDIS_HOST}:${REDIS_PORT}/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    command: airflow scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/dbt:/opt/airflow/dbt
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - ./requirements.txt:/requirements.txt
    networks:
      - sportdata_net

  # ========================================================================================
  # 13. sport-airflow-worker
  #   ‚öôÔ∏è  Worker Celery pour ex√©cution distribu√©e des tasks
  #      - Peut √™tre multipli√© si besoin (scaling horizontal)
  #      - Peut √™tre monitor√© par Flower
  #   ‚ö†Ô∏è  D√©marre apr√®s le scheduler pour bonne synchronisation
  # ========================================================================================
  sport-airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: sport-airflow:latest
    container_name: sport-airflow-worker
    restart: unless-stopped
    depends_on:
      - sport-airflow-scheduler
      - sport-redis
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://${REDIS_HOST}:${REDIS_PORT}/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    command: airflow celery worker
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/dbt:/opt/airflow/dbt
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - ./requirements.txt:/requirements.txt
    networks:
      - sportdata_net

  # ========================================================================================
  # 14. sport-flower
  #   üìà Monitoring des workers Celery via Flower (http://localhost:${AIRFLOW_FLOWER_PORT})
  #      - Visualise l‚Äô√©tat des workers, tasks, files d‚Äôattente, stats d‚Äôex√©cution
  #      - Indispensable pour debug, monitoring ou scaling
  #      - Peut √™tre d√©sactiv√© si usage ultra-minimaliste
  #   ‚ö†Ô∏è  D√©marre apr√®s les workers pour collecter les stats
  # ========================================================================================
  sport-flower:
    build:
      context: .
      dockerfile: Dockerfile
    image: sport-airflow:latest
    container_name: sport-flower
    restart: unless-stopped
    depends_on:
      - sport-airflow-worker
      - sport-redis
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://${REDIS_HOST}:${REDIS_PORT}/0
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    command: airflow celery flower
    ports:
      - "${AIRFLOW_FLOWER_PORT}:5555"
    volumes:
      - ./requirements.txt:/requirements.txt
    networks:
      - sportdata_net
 