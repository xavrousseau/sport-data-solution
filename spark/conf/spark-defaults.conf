# ================================================================================
# Fichier     : spark-defaults.conf
# Objectif    : Configuration Spark pour accès S3A (MinIO) + compatibilité Delta Lake
# Auteur      : Xavier Rousseau — Juillet 2025
# ================================================================================

# === Configuration S3A (MinIO) ===
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.s3a.S3A
spark.hadoop.fs.s3a.endpoint=http://sport-minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.access.key=minio
spark.hadoop.fs.s3a.secret.key=minio123
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# === Désactivation de la validation des certificats SSL (utile en dev sans HTTPS) ===
spark.driver.extraJavaOptions=-Dcom.amazonaws.sdk.disableCertChecking=true
spark.executor.extraJavaOptions=-Dcom.amazonaws.sdk.disableCertChecking=true

# === Extensions Delta Lake ===
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# === Partitionnement automatique Delta (utile dans certains cas) ===
spark.databricks.delta.schema.autoMerge.enabled=true
