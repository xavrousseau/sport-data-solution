# -----------------------------------------------------------------------------
# VARIABLES POUR LA BASE DE DONNÉES POSTGRESQL (locale, interne au projet Airflow)
# -----------------------------------------------------------------------------
POSTGRES_USER=airflow                            # Nom d'utilisateur utilisé par Airflow pour se connecter à PostgreSQL
POSTGRES_PASSWORD=airflow                        # Mot de passe associé à l'utilisateur airflow
POSTGRES_DB=airflow                              # Nom de la base de données utilisée uniquement par Airflow
POSTGRES_PORT=5432                               # Port standard PostgreSQL (interne au conteneur)
POSTGRES_HOST=postgres                           # Hôte du service PostgreSQL défini dans docker-compose (interne)

# -----------------------------------------------------------------------------
# VARIABLES POUR AIRFLOW
# -----------------------------------------------------------------------------
AIRFLOW__CORE__EXECUTOR=LocalExecutor            # Airflow s'exécute localement (mono-thread, sans Celery)
AIRFLOW__CORE__FERNET_KEY=dE8X5GSWzf_fyWVtmZGWYR_9JCV8FdKpM3avfQrZjEM=  # Clé pour chiffrer les connexions sensibles dans la DB
AIRFLOW__WEBSERVER__SECRET_KEY=ivMY0WsBGRC4ld2BY0HEci7wq3T8S20vm_ky1hl5MWQ  # Clé pour les sessions et CSRF dans l'interface Web

# -----------------------------------------------------------------------------
# CHEMINS INTERNE AIRFLOW
# -----------------------------------------------------------------------------
AIRFLOW_HOME=/opt/airflow                        # Répertoire principal d’Airflow dans le conteneur
DAGS_FOLDER=/opt/airflow/dags                    # Dossier contenant les fichiers de DAG à exécuter

# -----------------------------------------------------------------------------
# CLÉ API GOOGLE MAPS (POUR VÉRIFIER LES DISTANCES DOMICILE -> ENTREPRISE)
# -----------------------------------------------------------------------------
GOOGLE_API_KEY=AIzaSyBrFmxqO9gaqIGYx3IgrVcqdbHqawajosQ   # Clé d’API Google utilisée dans les scripts de géolocalisation

# -----------------------------------------------------------------------------
# PARAMÈTRES POUR LA SIMULATION DE DONNÉES SPORTIVES
# -----------------------------------------------------------------------------
SIMULATION_MONTHS=12                             # Nombre de mois à simuler
SIMULATION_MIN_ACTIVITIES=10                     # Nombre minimum d’activités par salarié
SIMULATION_MAX_ACTIVITIES=100                    # Nombre maximum d’activités par salarié

# -----------------------------------------------------------------------------
# CHEMINS COMPLÉMENTAIRES POUR LES DONNÉES ET LES SCRIPTS
# -----------------------------------------------------------------------------
INPUT_DATA_PATH=/opt/airflow/data/inputs         # Dossier où seront téléchargées les données sources
OUTPUT_DATA_PATH=/opt/airflow/data/outputs       # Dossier de sortie pour les résultats intermédiaires
EXPORT_DATA_PATH=/opt/airflow/data/exports       # Dossier pour les fichiers exportés finaux
SCRIPTS_PATH=/opt/airflow/scripts                # Dossier contenant les scripts Python associés aux DAGs

# -----------------------------------------------------------------------------
# CONFIGURATION DE TEST ET VALIDATION
# -----------------------------------------------------------------------------
ENABLE_QUALITY_CHECKS=True                       # Active les contrôles de qualité (doublons, champs vides, etc.)
RAISE_ON_DISTANCE_ERROR=False                    # N’interrompt pas le pipeline si des distances incohérentes sont détectées

# -----------------------------------------------------------------------------
# EXPORT POUR POWER BI (CSV OU POSTGRES)
# -----------------------------------------------------------------------------
EXPORT_FORMAT=csv                                # Format d’export des résultats (CSV par défaut)
POWERBI_EXPORT_TABLE=avantages_sportifs_export   # Nom du fichier ou table pour export vers Power BI
